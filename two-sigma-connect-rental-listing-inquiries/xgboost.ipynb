{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import quadkey\n",
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import quadkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"input/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n",
       "      <td>2016-04-17 03:26:41</td>\n",
       "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
       "      <td>W 13 Street</td>\n",
       "      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>\n",
       "      <td>high</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>6887163</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>d9039c43983f6e564b1482b273bd7b01</td>\n",
       "      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>\n",
       "      <td>2850</td>\n",
       "      <td>241 W 13 Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n",
       "      <td>2016-04-18 02:22:02</td>\n",
       "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
       "      <td>East 49th Street</td>\n",
       "      <td>[Hardwood Floors, No Fee]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>6888711</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>1067e078446a7897d2da493d2f741316</td>\n",
       "      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>\n",
       "      <td>3275</td>\n",
       "      <td>333 East 49th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-28 01:32:41</td>\n",
       "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
       "      <td>West 143rd Street</td>\n",
       "      <td>[Pre-War]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>6934781</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>98e13ad4b495b9613cef886d79a6291f</td>\n",
       "      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>\n",
       "      <td>3350</td>\n",
       "      <td>500 West 143rd Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   \n",
       "100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   \n",
       "100013        1.0         4                                 0   \n",
       "\n",
       "                    created  \\\n",
       "10      2016-06-24 07:54:24   \n",
       "10000   2016-06-12 12:19:27   \n",
       "100004  2016-04-17 03:26:41   \n",
       "100007  2016-04-18 02:22:02   \n",
       "100013  2016-04-28 01:32:41   \n",
       "\n",
       "                                              description  \\\n",
       "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000                                                       \n",
       "100004  Top Top West Village location, beautiful Pre-w...   \n",
       "100007  Building Amenities - Garage - Garden - fitness...   \n",
       "100013  Beautifully renovated 3 bedroom flex 4 bedroom...   \n",
       "\n",
       "            display_address  \\\n",
       "10      Metropolitan Avenue   \n",
       "10000       Columbus Avenue   \n",
       "100004          W 13 Street   \n",
       "100007     East 49th Street   \n",
       "100013    West 143rd Street   \n",
       "\n",
       "                                                 features interest_level  \\\n",
       "10                                                     []         medium   \n",
       "10000   [Doorman, Elevator, Fitness Center, Cats Allow...            low   \n",
       "100004  [Laundry In Building, Dishwasher, Hardwood Flo...           high   \n",
       "100007                          [Hardwood Floors, No Fee]            low   \n",
       "100013                                          [Pre-War]            low   \n",
       "\n",
       "        latitude  listing_id  longitude                        manager_id  \\\n",
       "10       40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000    40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "100004   40.7388     6887163   -74.0018  d9039c43983f6e564b1482b273bd7b01   \n",
       "100007   40.7539     6888711   -73.9677  1067e078446a7897d2da493d2f741316   \n",
       "100013   40.8241     6934781   -73.9493  98e13ad4b495b9613cef886d79a6291f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   \n",
       "100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   \n",
       "100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350   \n",
       "\n",
       "                 street_address  \n",
       "10      792 Metropolitan Avenue  \n",
       "10000       808 Columbus Avenue  \n",
       "100004          241 W 13 Street  \n",
       "100007     333 East 49th Street  \n",
       "100013    500 West 143rd Street  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer( sparse = False )\n",
    "vec_x_cat_train = pd.get_dummies(train_df['manager_id'])\n",
    "#vec_x_cat_test = vectorizer.transform( train_df['interest_level'] ) \n",
    "#train_df['interest_level'].map({'high':0, 'medium':1, 'low':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'bathrooms', u'bedrooms', u'building_id', u'created', u'description',\n",
       "       u'display_address', u'features', u'interest_level', u'latitude',\n",
       "       u'listing_id', u'longitude', u'manager_id', u'photos', u'price',\n",
       "       u'street_address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_preprocessing(df, if_train=True):\n",
    "    \n",
    "    target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "    features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\",  \"price\" ,\n",
    "                        \"diff_price\",'diff_bathrooms','diff_bedrooms',\n",
    "                        'ratio_price',\n",
    "                       'building_price','building_bathrooms', 'building_bedrooms',\n",
    "                       'diff_mean_of_price', 'diff_mean_of_bedrooms', 'diff_mean_of_bathrooms',\n",
    "                       'diff_bathrooms_quadkey_15', 'diff_bedrooms_quadkey_15', 'diff_price_quadkey_15',\n",
    "                        'ratio_price_quadkey_15',\n",
    "                       'diff_bathrooms_quadkey_13', 'diff_bedrooms_quadkey_13', 'diff_price_quadkey_13',\n",
    "                       'ratio_price_quadkey_13',\n",
    "                       'price_per_bed', 'price_per_bath','price_per_room',\n",
    "                       'building_price_per_room', 'diff_price_per_rooms',\n",
    "                        'total_room','diff_room','ratio_room']\n",
    "    \n",
    "    df = df[df.columns]\n",
    "    # datetime\n",
    "    df['ts'] = pd.to_datetime(df['created'])\n",
    "    df['created_year'] = df['ts'].dt.year\n",
    "    df['created_month'] = df['ts'].dt.month\n",
    "    df['created_day'] = df['ts'].dt.day\n",
    "    df['created_hour'] = df['ts'].dt.hour\n",
    "    \n",
    "    #room\n",
    "    df['total_room'] = df['bathrooms'] + df['bedrooms'] \n",
    "    df['diff_room'] = df['bathrooms'] - df['bedrooms'] \n",
    "    df['ratio_room'] = df['bathrooms'] / df['bedrooms']\n",
    "    \n",
    "    \n",
    "    #len\n",
    "    df['features_cnt'] = df['features'].apply(len)\n",
    "    df['photos_cnt'] = df['photos'].apply(len)\n",
    "    df['desc_cnt'] = df['description'].apply(len)\n",
    "    df['address_cnt'] = df['display_address'].apply(len)\n",
    "    df['street_address_cnt'] = df['street_address'].apply(len)\n",
    "    \n",
    "    #price per \n",
    "    \n",
    "    df['price_per_bed']  = df['price'] / df['bedrooms']    \n",
    "    df['price_per_bath'] = df['price'] / df['bathrooms']\n",
    "    df['price_per_room'] = df['price'] / (df['bathrooms'] + df['bedrooms'] )\n",
    "    \n",
    "    # group by building id\n",
    "    mean_of_building = df.groupby('building_id')['bathrooms','bedrooms','price'].mean()\n",
    "    mean_of_building.columns = ['building_bathrooms','building_bedrooms','building_price']\n",
    "    df = pd.merge(df, mean_of_building, left_on = df.building_id, right_index=True, how='left')\n",
    "    df['building_price'].fillna(df['price'])\n",
    "    df['building_bedrooms'].fillna(df['bedrooms'])    \n",
    "    df['building_bathrooms'].fillna(df['bathrooms'])\n",
    "    \n",
    "    df['building_price_per_room'] = df['building_price']/(df['building_bedrooms']+df['building_bathrooms'])\n",
    "    \n",
    "    df['diff_bathrooms'] = df['bathrooms'] - df['building_bathrooms']\n",
    "    df['diff_bedrooms'] = df['bedrooms'] - df['building_bedrooms']\n",
    "    df['diff_price'] = df['price'] - df['building_price']\n",
    "    df['diff_price_per_rooms'] = df['price_per_room'] - df['building_price_per_room']\n",
    "    \n",
    "    df['ratio_price'] = df['price'] / df['building_price']\n",
    "    \n",
    "    #avg price\n",
    "    df['diff_mean_of_price'] = df['price'] - df['price'].mean()\n",
    "    df['diff_mean_of_bedrooms'] = df['bedrooms'] - df['bedrooms'].mean()\n",
    "    df['diff_mean_of_bathrooms'] = df['bathrooms'] - df['bathrooms'].mean()\n",
    "    \n",
    "    #return df\n",
    "    \n",
    "    # add quadkey \n",
    "    #df['quadkey_15'] = quadkey.from_geo((df['latitude'], df['longitude']), 15)\n",
    "    #df['quadkey_14'] = quadkey.from_geo((df['latitude'], df['longitude']), 14)\n",
    "    #df['quadkey_13'] = quadkey.from_geo((df['latitude'], df['longitude']), 13)\n",
    "    \n",
    "    df['quadkey_15'] = df.apply(lambda x: quadkey.from_geo((x['latitude'], x['longitude']), 15).key, axis=1)\n",
    "    #df['quadkey_14'] = df.apply(lambda x: quadkey.from_geo((x['latitude'], x['longitude']), 14),axis=1)\n",
    "    df['quadkey_13'] = df.apply(lambda x: quadkey.from_geo((x['latitude'], x['longitude']), 13).key,axis=1)\n",
    "    \n",
    "    \n",
    "    #group by quadkey\n",
    "    mean_of_quadkey_15 = df.groupby('quadkey_15')['bathrooms','bedrooms','price'].mean()\n",
    "    mean_of_quadkey_15.columns = ['quadkey_15_bathrooms','quadkey_15_bedrooms','quadkey_15_price']\n",
    "    print mean_of_quadkey_15.head()\n",
    "    df = pd.merge(df, mean_of_quadkey_15, left_on = df.quadkey_15, right_index=True, how='left')\n",
    "    df['quadkey_15_price'].fillna(df['price'])\n",
    "    df['quadkey_15_bedrooms'].fillna(df['bedrooms'])    \n",
    "    df['quadkey_15_bathrooms'].fillna(df['bathrooms'])\n",
    "    \n",
    "    df['diff_bathrooms_quadkey_15'] = df['bathrooms'] - df['quadkey_15_bathrooms']\n",
    "    df['diff_bedrooms_quadkey_15'] = df['bedrooms'] - df['quadkey_15_bedrooms']\n",
    "    df['diff_price_quadkey_15'] = df['price'] - df['quadkey_15_price']\n",
    "    df['ratio_price_quadkey_15'] = df['price'] / df['quadkey_15_price']\n",
    "    \n",
    "    \n",
    "    mean_of_quadkey_13 = df.groupby('quadkey_13')['bathrooms','bedrooms','price'].mean()\n",
    "    mean_of_quadkey_13.columns = ['quadkey_13_bathrooms','quadkey_13_bedrooms','quadkey_13_price']\n",
    "    df = pd.merge(df, mean_of_quadkey_13, left_on = df.quadkey_13, right_index=True, how='left')\n",
    "    df['quadkey_13_price'].fillna(df['price'])\n",
    "    df['quadkey_13_bedrooms'].fillna(df['bedrooms'])    \n",
    "    df['quadkey_13_bathrooms'].fillna(df['bathrooms'])\n",
    "    \n",
    "    df['diff_bathrooms_quadkey_13'] = df['bathrooms'] - df['quadkey_13_bathrooms']\n",
    "    df['diff_bedrooms_quadkey_13'] = df['bedrooms'] - df['quadkey_13_bedrooms']\n",
    "    df['diff_price_quadkey_13'] = df['price'] - df['quadkey_13_price']\n",
    "    \n",
    "    df['ratio_price_quadkey_13'] = df['price'] / df['quadkey_13_price']\n",
    "    \n",
    "    #return df\n",
    "    \n",
    "    #features\n",
    "    df['features'] = df[\"features\"].apply(lambda x: 'Ringcentral ' + \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "    df['features'] = df['features'].str.replace(\"garden/patio\",\"garden\")\n",
    "    df['features'] = df['features'].str.replace(\"patio\",\"garden\")\n",
    "    df['features'] = df['features'].str.replace(\"residents_garden\",\"garden\")\n",
    "    df['features'] = df['features'].str.replace(\"common_garden\",\"garden\")\n",
    "    df['features'] = df['features'].str.replace(\"wifi_access\",\"wifi\")\n",
    "    df['features'] = df['features'].str.replace(\"24/7\",\"24\")\n",
    "    df['features'] = df['features'].str.replace(\"24-hour\",\"24\")\n",
    "    df['features'] = df['features'].str.replace(\"24hr\",\"24\")\n",
    "    df['features'] = df['features'].str.replace(\"concierge\",\"doorman\")\n",
    "    df['features'] = df['features'].str.replace(\"ft_doorman\",\"doorman\")\n",
    "    df['features'] = df['features'].str.replace(\"24_doorman\",\"doorman\")\n",
    "    df['features'] = df['features'].str.replace(\"24_hr_doorman\",\"doorman\")\n",
    "    df['features'] = df['features'].str.replace(\"doorman_service\",\"doorman\")\n",
    "    df['features'] = df['features'].str.replace(\"full-time_doorman\",\"doorman\")\n",
    "    \n",
    "    tfidf = CountVectorizer(stop_words='english' , max_features=100, min_df=1)\n",
    "    tr_sparse = tfidf.fit_transform(df[\"features\"])\n",
    "    print 'tr_sparse' + str(tr_sparse.shape)\n",
    "    \n",
    "    #description\n",
    "    tr_sparse_desc = tfidf.fit_transform(df[\"description\"])\n",
    "    print 'tr_sparse_desc' + str(tr_sparse_desc.shape)\n",
    "    \n",
    "    features_to_use.extend(['created_year', 'created_month', 'created_day', 'created_hour','features_cnt','photos_cnt','desc_cnt'])\n",
    "    train_x = df[features_to_use]\n",
    "    print 'cloumns: {0}'.format(train_x.columns)\n",
    "    \n",
    "    #manager id \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_x = sparse.hstack([train_x, tr_sparse, tr_sparse_desc]).tocsr()\n",
    "    #train_x = sparse.csr_matrix(train_x.values)\n",
    "\n",
    "    if if_train:\n",
    "        train_y = pd.DataFrame(df['interest_level'])\n",
    "        train_y = np.array(train_y['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "        print 'train_x: %s; train_y %s' % (str(train_x.shape), str(train_y.shape))\n",
    "        return train_x, train_y\n",
    "    else:\n",
    "        print 'train_x: %s' % (str(train_x.shape))\n",
    "        return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(test_df, model):\n",
    "    target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "    test_df_1 = feature_preprocessing(test_df, False)\n",
    "    preds, model = runXGB(train_X, train_y, test_X, num_rounds=400)\n",
    "    out_df = pd.DataFrame(preds)\n",
    "    out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "    out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_submit_result( submit_result, cv_scores, score):\n",
    "    submit_result[str(reduce(lambda x,y: x + y, cv_scores)/len(cv_scores))] = score\n",
    "    return  submit_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 quadkey_15_bathrooms  quadkey_15_bedrooms  quadkey_15_price\n",
      "quadkey_15                                                                  \n",
      "021333011032130                   3.0                  3.0           13875.0\n",
      "023012311310010                   1.0                  1.0            2425.0\n",
      "030222231211021                   1.0                  0.0            2000.0\n",
      "030232101222321                   1.0                  0.0            1350.0\n",
      "030232211000200                   1.0                  2.0            3300.0\n",
      "tr_sparse(49352, 100)\n",
      "tr_sparse_desc(49352, 100)\n",
      "cloumns: Index([                u'bathrooms',                  u'bedrooms',\n",
      "                        u'latitude',                 u'longitude',\n",
      "                           u'price',                u'diff_price',\n",
      "                  u'diff_bathrooms',             u'diff_bedrooms',\n",
      "                     u'ratio_price',            u'building_price',\n",
      "              u'building_bathrooms',         u'building_bedrooms',\n",
      "              u'diff_mean_of_price',     u'diff_mean_of_bedrooms',\n",
      "          u'diff_mean_of_bathrooms', u'diff_bathrooms_quadkey_15',\n",
      "        u'diff_bedrooms_quadkey_15',     u'diff_price_quadkey_15',\n",
      "          u'ratio_price_quadkey_15', u'diff_bathrooms_quadkey_13',\n",
      "        u'diff_bedrooms_quadkey_13',     u'diff_price_quadkey_13',\n",
      "          u'ratio_price_quadkey_13',             u'price_per_bed',\n",
      "                  u'price_per_bath',            u'price_per_room',\n",
      "         u'building_price_per_room',      u'diff_price_per_rooms',\n",
      "                      u'total_room',                 u'diff_room',\n",
      "                      u'ratio_room',              u'created_year',\n",
      "                   u'created_month',               u'created_day',\n",
      "                    u'created_hour',              u'features_cnt',\n",
      "                      u'photos_cnt',                  u'desc_cnt'],\n",
      "      dtype='object')\n",
      "train_x: (49352, 238); train_y (49352,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = feature_preprocessing(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(param, train_X, train_y, test_X, test_y=None, feature_names=None, num_rounds=2000):\n",
    "    num_rounds = num_rounds\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20, verbose_eval=100)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, verbose_eval=100)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.03481\ttest-mlogloss:1.03666\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.481314\ttest-mlogloss:0.566267\n",
      "[200]\ttrain-mlogloss:0.429064\ttest-mlogloss:0.555033\n",
      "[300]\ttrain-mlogloss:0.389567\ttest-mlogloss:0.550174\n",
      "[400]\ttrain-mlogloss:0.354959\ttest-mlogloss:0.54862\n",
      "Stopping. Best iteration:\n",
      "[400]\ttrain-mlogloss:0.354959\ttest-mlogloss:0.54862\n",
      "\n",
      "[0.54872436555021809]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.035\ttest-mlogloss:1.03636\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.481144\ttest-mlogloss:0.567363\n",
      "[200]\ttrain-mlogloss:0.427791\ttest-mlogloss:0.554664\n",
      "[300]\ttrain-mlogloss:0.390271\ttest-mlogloss:0.55089\n",
      "Stopping. Best iteration:\n",
      "[346]\ttrain-mlogloss:0.373722\ttest-mlogloss:0.549773\n",
      "\n",
      "[0.54872436555021809, 0.55013305069567464]\n",
      "Fold: 2\n",
      "[0]\ttrain-mlogloss:1.03387\ttest-mlogloss:1.03586\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.481129\ttest-mlogloss:0.568867\n",
      "[200]\ttrain-mlogloss:0.427957\ttest-mlogloss:0.556666\n",
      "[300]\ttrain-mlogloss:0.389292\ttest-mlogloss:0.552613\n",
      "[400]\ttrain-mlogloss:0.356578\ttest-mlogloss:0.55019\n",
      "Stopping. Best iteration:\n",
      "[405]\ttrain-mlogloss:0.354782\ttest-mlogloss:0.550039\n",
      "\n",
      "[0.54872436555021809, 0.55013305069567464, 0.5502693824099979]\n",
      "Fold: 3\n",
      "[0]\ttrain-mlogloss:1.03513\ttest-mlogloss:1.037\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.484865\ttest-mlogloss:0.558768\n",
      "[200]\ttrain-mlogloss:0.432793\ttest-mlogloss:0.546714\n",
      "[300]\ttrain-mlogloss:0.39231\ttest-mlogloss:0.54118\n",
      "Stopping. Best iteration:\n",
      "[348]\ttrain-mlogloss:0.375244\ttest-mlogloss:0.539729\n",
      "\n",
      "[0.54872436555021809, 0.55013305069567464, 0.5502693824099979, 0.54004980623073506]\n",
      "Fold: 4\n",
      "[0]\ttrain-mlogloss:1.03436\ttest-mlogloss:1.03471\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.482505\ttest-mlogloss:0.560133\n",
      "[200]\ttrain-mlogloss:0.430119\ttest-mlogloss:0.546775\n",
      "[300]\ttrain-mlogloss:0.392043\ttest-mlogloss:0.541262\n",
      "Stopping. Best iteration:\n",
      "[368]\ttrain-mlogloss:0.368885\ttest-mlogloss:0.539606\n",
      "\n",
      "[0.54872436555021809, 0.55013305069567464, 0.5502693824099979, 0.54004980623073506, 0.53987076075679141]\n"
     ]
    }
   ],
   "source": [
    "# one time\n",
    "\n",
    "param = {}\n",
    "    # fixed parems\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eval_metric'] = \"mlogloss\"\n",
    "param['seed'] = 0\n",
    "param['silent'] = 1 \n",
    "param['num_class'] = 3\n",
    "    \n",
    "    # random\n",
    "param['eta'] = 0.1   #[0,1]\n",
    "param['max_depth'] = 6                      #[1,]\n",
    "param['min_child_weight'] = 0                    #[0,]\n",
    "param['subsample'] = 0.7                 #(0,1]\n",
    "param['colsample_bytree'] = 0.7          #(0,1]\n",
    "    \n",
    "cv_scores = []\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "fold = 0 \n",
    "for dev_index, val_index in kf.split(range(train_x.shape[0])):\n",
    "        print \"Fold: %s\" % fold\n",
    "        dev_x, val_x = train_x[dev_index,:], train_x[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "        # Xbgoost parameter \n",
    "        val_y_pred, model = runXGB(param, dev_x, dev_y, val_x, val_y)\n",
    "        cv_scores.append(log_loss(val_y, val_y_pred))\n",
    "\n",
    "        print(cv_scores)\n",
    "        fold += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 0\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 0, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 3}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09285\ttest-mlogloss:1.09292\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.782535\ttest-mlogloss:0.786932\n",
      "[200]\ttrain-mlogloss:0.686137\ttest-mlogloss:0.694426\n",
      "[300]\ttrain-mlogloss:0.645378\ttest-mlogloss:0.657036\n",
      "[400]\ttrain-mlogloss:0.623482\ttest-mlogloss:0.638247\n",
      "[500]\ttrain-mlogloss:0.608823\ttest-mlogloss:0.626335\n",
      "[600]\ttrain-mlogloss:0.597636\ttest-mlogloss:0.617753\n",
      "[700]\ttrain-mlogloss:0.588842\ttest-mlogloss:0.611415\n",
      "[800]\ttrain-mlogloss:0.581397\ttest-mlogloss:0.606418\n",
      "[900]\ttrain-mlogloss:0.574705\ttest-mlogloss:0.601972\n",
      "[1000]\ttrain-mlogloss:0.568832\ttest-mlogloss:0.598337\n",
      "[1100]\ttrain-mlogloss:0.563553\ttest-mlogloss:0.595289\n",
      "[1200]\ttrain-mlogloss:0.558775\ttest-mlogloss:0.592759\n",
      "[1300]\ttrain-mlogloss:0.554196\ttest-mlogloss:0.590484\n",
      "[1400]\ttrain-mlogloss:0.549992\ttest-mlogloss:0.58841\n",
      "[1500]\ttrain-mlogloss:0.546039\ttest-mlogloss:0.586548\n",
      "[1600]\ttrain-mlogloss:0.542326\ttest-mlogloss:0.584964\n",
      "[1700]\ttrain-mlogloss:0.538827\ttest-mlogloss:0.583604\n",
      "[1800]\ttrain-mlogloss:0.535398\ttest-mlogloss:0.582383\n",
      "[1900]\ttrain-mlogloss:0.53219\ttest-mlogloss:0.581253\n",
      "[1999]\ttrain-mlogloss:0.529117\ttest-mlogloss:0.580237\n",
      "[0.58023689471856332]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.09283\ttest-mlogloss:1.09284\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.786041\ttest-mlogloss:0.787756\n",
      "[200]\ttrain-mlogloss:0.691045\ttest-mlogloss:0.694303\n",
      "[300]\ttrain-mlogloss:0.651014\ttest-mlogloss:0.655991\n",
      "[400]\ttrain-mlogloss:0.629243\ttest-mlogloss:0.636239\n",
      "[500]\ttrain-mlogloss:0.614714\ttest-mlogloss:0.6239\n",
      "[600]\ttrain-mlogloss:0.603468\ttest-mlogloss:0.614882\n",
      "[700]\ttrain-mlogloss:0.594422\ttest-mlogloss:0.608163\n",
      "[800]\ttrain-mlogloss:0.586851\ttest-mlogloss:0.602867\n",
      "[900]\ttrain-mlogloss:0.580159\ttest-mlogloss:0.598566\n",
      "[1000]\ttrain-mlogloss:0.574277\ttest-mlogloss:0.594826\n",
      "[1100]\ttrain-mlogloss:0.569067\ttest-mlogloss:0.591848\n",
      "[1200]\ttrain-mlogloss:0.564286\ttest-mlogloss:0.589336\n",
      "[1300]\ttrain-mlogloss:0.559865\ttest-mlogloss:0.587072\n",
      "[1400]\ttrain-mlogloss:0.555777\ttest-mlogloss:0.585224\n",
      "[1500]\ttrain-mlogloss:0.55191\ttest-mlogloss:0.583327\n",
      "[1600]\ttrain-mlogloss:0.548159\ttest-mlogloss:0.581741\n",
      "[1700]\ttrain-mlogloss:0.544636\ttest-mlogloss:0.580306\n",
      "[1800]\ttrain-mlogloss:0.541348\ttest-mlogloss:0.579009\n",
      "[1900]\ttrain-mlogloss:0.538192\ttest-mlogloss:0.57787\n",
      "[1999]\ttrain-mlogloss:0.535088\ttest-mlogloss:0.576731\n",
      "[0.58023689471856332, 0.57673109759658936]\n",
      "round: 1\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 5, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.662328\ttest-mlogloss:0.727759\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2]\ttrain-mlogloss:0.526539\ttest-mlogloss:0.666166\n",
      "\n",
      "[0.89458552206647057]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.668271\ttest-mlogloss:0.722463\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2]\ttrain-mlogloss:0.528774\ttest-mlogloss:0.659668\n",
      "\n",
      "[0.89458552206647057, 0.8651771809619978]\n",
      "round: 2\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.0615\ttest-mlogloss:1.06564\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.374208\ttest-mlogloss:0.577207\n",
      "[200]\ttrain-mlogloss:0.274998\ttest-mlogloss:0.571308\n",
      "Stopping. Best iteration:\n",
      "[183]\ttrain-mlogloss:0.288271\ttest-mlogloss:0.570864\n",
      "\n",
      "[0.57136182294408133]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.0617\ttest-mlogloss:1.06566\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.376079\ttest-mlogloss:0.572355\n",
      "[200]\ttrain-mlogloss:0.280003\ttest-mlogloss:0.565187\n",
      "Stopping. Best iteration:\n",
      "[190]\ttrain-mlogloss:0.288045\ttest-mlogloss:0.564733\n",
      "\n",
      "[0.57136182294408133, 0.56560959364477448]\n",
      "round: 3\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 5, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 6}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06654\ttest-mlogloss:1.06757\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.516583\ttest-mlogloss:0.590717\n",
      "[200]\ttrain-mlogloss:0.451431\ttest-mlogloss:0.573126\n",
      "[300]\ttrain-mlogloss:0.408611\ttest-mlogloss:0.567632\n",
      "[400]\ttrain-mlogloss:0.373086\ttest-mlogloss:0.566573\n",
      "Stopping. Best iteration:\n",
      "[385]\ttrain-mlogloss:0.37787\ttest-mlogloss:0.566535\n",
      "\n",
      "[0.56662916403314545]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06636\ttest-mlogloss:1.06727\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.52016\ttest-mlogloss:0.586279\n",
      "[200]\ttrain-mlogloss:0.455685\ttest-mlogloss:0.567769\n",
      "[300]\ttrain-mlogloss:0.411121\ttest-mlogloss:0.561821\n",
      "[400]\ttrain-mlogloss:0.376202\ttest-mlogloss:0.559768\n",
      "Stopping. Best iteration:\n",
      "[451]\ttrain-mlogloss:0.359845\ttest-mlogloss:0.559282\n",
      "\n",
      "[0.56662916403314545, 0.55947181618900887]\n",
      "round: 4\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 2, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 3}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.737469\ttest-mlogloss:0.743562\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-mlogloss:0.518976\ttest-mlogloss:0.599935\n",
      "\n",
      "[0.60587091288007311]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.740384\ttest-mlogloss:0.741272\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[22]\ttrain-mlogloss:0.543084\ttest-mlogloss:0.597669\n",
      "\n",
      "[0.60587091288007311, 0.60257904669087647]\n",
      "round: 5\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 2}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.07172\ttest-mlogloss:1.07193\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.641687\ttest-mlogloss:0.65176\n",
      "[200]\ttrain-mlogloss:0.6049\ttest-mlogloss:0.620732\n",
      "[300]\ttrain-mlogloss:0.586411\ttest-mlogloss:0.607085\n",
      "[400]\ttrain-mlogloss:0.573671\ttest-mlogloss:0.598792\n",
      "[500]\ttrain-mlogloss:0.563636\ttest-mlogloss:0.592827\n",
      "[600]\ttrain-mlogloss:0.555622\ttest-mlogloss:0.58894\n",
      "[700]\ttrain-mlogloss:0.548133\ttest-mlogloss:0.585526\n",
      "[800]\ttrain-mlogloss:0.542007\ttest-mlogloss:0.583394\n",
      "[900]\ttrain-mlogloss:0.536336\ttest-mlogloss:0.58166\n",
      "[1000]\ttrain-mlogloss:0.530968\ttest-mlogloss:0.579906\n",
      "[1100]\ttrain-mlogloss:0.526026\ttest-mlogloss:0.578741\n",
      "[1200]\ttrain-mlogloss:0.521427\ttest-mlogloss:0.577623\n",
      "[1300]\ttrain-mlogloss:0.517013\ttest-mlogloss:0.576674\n",
      "[1400]\ttrain-mlogloss:0.512842\ttest-mlogloss:0.575956\n",
      "[1500]\ttrain-mlogloss:0.508975\ttest-mlogloss:0.575058\n",
      "[1600]\ttrain-mlogloss:0.505074\ttest-mlogloss:0.574224\n",
      "[1700]\ttrain-mlogloss:0.501486\ttest-mlogloss:0.573737\n",
      "Stopping. Best iteration:\n",
      "[1724]\ttrain-mlogloss:0.500673\ttest-mlogloss:0.573512\n",
      "\n",
      "[0.57356795213203116]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.07182\ttest-mlogloss:1.07181\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.647279\ttest-mlogloss:0.650337\n",
      "[200]\ttrain-mlogloss:0.610812\ttest-mlogloss:0.618861\n",
      "[300]\ttrain-mlogloss:0.591885\ttest-mlogloss:0.604165\n",
      "[400]\ttrain-mlogloss:0.579185\ttest-mlogloss:0.595981\n",
      "[500]\ttrain-mlogloss:0.569313\ttest-mlogloss:0.590381\n",
      "[600]\ttrain-mlogloss:0.56139\ttest-mlogloss:0.586066\n",
      "[700]\ttrain-mlogloss:0.554472\ttest-mlogloss:0.582619\n",
      "[800]\ttrain-mlogloss:0.548428\ttest-mlogloss:0.580061\n",
      "[900]\ttrain-mlogloss:0.542851\ttest-mlogloss:0.578054\n",
      "[1000]\ttrain-mlogloss:0.537631\ttest-mlogloss:0.576276\n",
      "[1100]\ttrain-mlogloss:0.532747\ttest-mlogloss:0.574654\n",
      "[1200]\ttrain-mlogloss:0.528309\ttest-mlogloss:0.573489\n",
      "[1300]\ttrain-mlogloss:0.524187\ttest-mlogloss:0.572605\n",
      "[1400]\ttrain-mlogloss:0.520155\ttest-mlogloss:0.571552\n",
      "[1500]\ttrain-mlogloss:0.516298\ttest-mlogloss:0.570712\n",
      "[1600]\ttrain-mlogloss:0.51238\ttest-mlogloss:0.570018\n",
      "[1700]\ttrain-mlogloss:0.508721\ttest-mlogloss:0.569467\n",
      "[1800]\ttrain-mlogloss:0.505102\ttest-mlogloss:0.568897\n",
      "[1900]\ttrain-mlogloss:0.50178\ttest-mlogloss:0.568453\n",
      "Stopping. Best iteration:\n",
      "[1973]\ttrain-mlogloss:0.499437\ttest-mlogloss:0.568217\n",
      "\n",
      "[0.57356795213203116, 0.56823254328360306]\n",
      "round: 6\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.803289\ttest-mlogloss:0.836969\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[8]\ttrain-mlogloss:0.420561\ttest-mlogloss:0.607732\n",
      "\n",
      "[0.6334194058008995]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.802315\ttest-mlogloss:0.836017\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[12]\ttrain-mlogloss:0.363014\ttest-mlogloss:0.599784\n",
      "\n",
      "[0.6334194058008995, 0.6268217225024294]\n",
      "round: 7\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 5, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09186\ttest-mlogloss:1.09219\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.716844\ttest-mlogloss:0.748259\n",
      "[200]\ttrain-mlogloss:0.590881\ttest-mlogloss:0.646716\n",
      "[300]\ttrain-mlogloss:0.534364\ttest-mlogloss:0.609196\n",
      "[400]\ttrain-mlogloss:0.500198\ttest-mlogloss:0.592217\n",
      "[500]\ttrain-mlogloss:0.475829\ttest-mlogloss:0.583054\n",
      "[600]\ttrain-mlogloss:0.457089\ttest-mlogloss:0.577558\n",
      "[700]\ttrain-mlogloss:0.440433\ttest-mlogloss:0.573822\n",
      "[800]\ttrain-mlogloss:0.425833\ttest-mlogloss:0.571237\n",
      "[900]\ttrain-mlogloss:0.41246\ttest-mlogloss:0.569318\n",
      "[1000]\ttrain-mlogloss:0.400093\ttest-mlogloss:0.567859\n",
      "[1100]\ttrain-mlogloss:0.389163\ttest-mlogloss:0.566839\n",
      "[1200]\ttrain-mlogloss:0.378507\ttest-mlogloss:0.566043\n",
      "[1300]\ttrain-mlogloss:0.368481\ttest-mlogloss:0.565465\n",
      "[1400]\ttrain-mlogloss:0.358897\ttest-mlogloss:0.565018\n",
      "[1500]\ttrain-mlogloss:0.349588\ttest-mlogloss:0.564728\n",
      "[1600]\ttrain-mlogloss:0.340322\ttest-mlogloss:0.564597\n",
      "Stopping. Best iteration:\n",
      "[1621]\ttrain-mlogloss:0.33859\ttest-mlogloss:0.56457\n",
      "\n",
      "[0.56464106352552246]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.0918\ttest-mlogloss:1.09212\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.72031\ttest-mlogloss:0.748278\n",
      "[200]\ttrain-mlogloss:0.595427\ttest-mlogloss:0.645271\n",
      "[300]\ttrain-mlogloss:0.538377\ttest-mlogloss:0.606256\n",
      "[400]\ttrain-mlogloss:0.505082\ttest-mlogloss:0.588706\n",
      "[500]\ttrain-mlogloss:0.480377\ttest-mlogloss:0.579118\n",
      "[600]\ttrain-mlogloss:0.460269\ttest-mlogloss:0.573009\n",
      "[700]\ttrain-mlogloss:0.443903\ttest-mlogloss:0.569144\n",
      "[800]\ttrain-mlogloss:0.428941\ttest-mlogloss:0.56624\n",
      "[900]\ttrain-mlogloss:0.415472\ttest-mlogloss:0.564109\n",
      "[1000]\ttrain-mlogloss:0.403462\ttest-mlogloss:0.562539\n",
      "[1100]\ttrain-mlogloss:0.391904\ttest-mlogloss:0.561182\n",
      "[1200]\ttrain-mlogloss:0.381652\ttest-mlogloss:0.560411\n",
      "[1300]\ttrain-mlogloss:0.371741\ttest-mlogloss:0.559777\n",
      "[1400]\ttrain-mlogloss:0.36182\ttest-mlogloss:0.559173\n",
      "[1500]\ttrain-mlogloss:0.352978\ttest-mlogloss:0.55884\n",
      "[1600]\ttrain-mlogloss:0.344581\ttest-mlogloss:0.558734\n",
      "Stopping. Best iteration:\n",
      "[1592]\ttrain-mlogloss:0.345171\ttest-mlogloss:0.558719\n",
      "\n",
      "[0.56464106352552246, 0.55875209729728847]\n",
      "round: 8\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09105\ttest-mlogloss:1.09197\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.659074\ttest-mlogloss:0.738639\n",
      "[200]\ttrain-mlogloss:0.499881\ttest-mlogloss:0.633756\n",
      "[300]\ttrain-mlogloss:0.422112\ttest-mlogloss:0.596755\n",
      "[400]\ttrain-mlogloss:0.373825\ttest-mlogloss:0.582606\n",
      "[500]\ttrain-mlogloss:0.338299\ttest-mlogloss:0.576397\n",
      "[600]\ttrain-mlogloss:0.308861\ttest-mlogloss:0.573479\n",
      "[700]\ttrain-mlogloss:0.284027\ttest-mlogloss:0.57284\n",
      "Stopping. Best iteration:\n",
      "[702]\ttrain-mlogloss:0.283556\ttest-mlogloss:0.572802\n",
      "\n",
      "[0.57286287923722412]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.0911\ttest-mlogloss:1.09203\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.662751\ttest-mlogloss:0.738023\n",
      "[200]\ttrain-mlogloss:0.50388\ttest-mlogloss:0.63198\n",
      "[300]\ttrain-mlogloss:0.425975\ttest-mlogloss:0.593962\n",
      "[400]\ttrain-mlogloss:0.378232\ttest-mlogloss:0.578673\n",
      "[500]\ttrain-mlogloss:0.342047\ttest-mlogloss:0.57186\n",
      "[600]\ttrain-mlogloss:0.312558\ttest-mlogloss:0.568978\n",
      "[700]\ttrain-mlogloss:0.288068\ttest-mlogloss:0.567981\n",
      "Stopping. Best iteration:\n",
      "[768]\ttrain-mlogloss:0.272726\ttest-mlogloss:0.56785\n",
      "\n",
      "[0.57286287923722412, 0.56793686674713073]\n",
      "round: 9\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 4, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 2}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.07132\ttest-mlogloss:1.07156\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.63936\ttest-mlogloss:0.650472\n",
      "[200]\ttrain-mlogloss:0.602732\ttest-mlogloss:0.61964\n",
      "[300]\ttrain-mlogloss:0.584054\ttest-mlogloss:0.605792\n",
      "[400]\ttrain-mlogloss:0.571163\ttest-mlogloss:0.597692\n",
      "[500]\ttrain-mlogloss:0.560856\ttest-mlogloss:0.591806\n",
      "[600]\ttrain-mlogloss:0.552624\ttest-mlogloss:0.587749\n",
      "[700]\ttrain-mlogloss:0.545159\ttest-mlogloss:0.584721\n",
      "[800]\ttrain-mlogloss:0.538699\ttest-mlogloss:0.582195\n",
      "[900]\ttrain-mlogloss:0.532888\ttest-mlogloss:0.580251\n",
      "[1000]\ttrain-mlogloss:0.527219\ttest-mlogloss:0.578426\n",
      "[1100]\ttrain-mlogloss:0.522157\ttest-mlogloss:0.577282\n",
      "[1200]\ttrain-mlogloss:0.517442\ttest-mlogloss:0.576247\n",
      "[1300]\ttrain-mlogloss:0.512996\ttest-mlogloss:0.575374\n",
      "[1400]\ttrain-mlogloss:0.508769\ttest-mlogloss:0.574591\n",
      "[1500]\ttrain-mlogloss:0.504636\ttest-mlogloss:0.57398\n",
      "[1600]\ttrain-mlogloss:0.500678\ttest-mlogloss:0.573386\n",
      "Stopping. Best iteration:\n",
      "[1597]\ttrain-mlogloss:0.50078\ttest-mlogloss:0.573367\n",
      "\n",
      "[0.57343867988276187]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.07149\ttest-mlogloss:1.0714\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.645061\ttest-mlogloss:0.648315\n",
      "[200]\ttrain-mlogloss:0.609555\ttest-mlogloss:0.618096\n",
      "[300]\ttrain-mlogloss:0.590246\ttest-mlogloss:0.603407\n",
      "[400]\ttrain-mlogloss:0.577165\ttest-mlogloss:0.595058\n",
      "[500]\ttrain-mlogloss:0.566931\ttest-mlogloss:0.589082\n",
      "[600]\ttrain-mlogloss:0.558565\ttest-mlogloss:0.584581\n",
      "[700]\ttrain-mlogloss:0.551499\ttest-mlogloss:0.581411\n",
      "[800]\ttrain-mlogloss:0.545258\ttest-mlogloss:0.578805\n",
      "[900]\ttrain-mlogloss:0.539444\ttest-mlogloss:0.57687\n",
      "[1000]\ttrain-mlogloss:0.534146\ttest-mlogloss:0.575112\n",
      "[1100]\ttrain-mlogloss:0.52916\ttest-mlogloss:0.573468\n",
      "[1200]\ttrain-mlogloss:0.524625\ttest-mlogloss:0.572318\n",
      "[1300]\ttrain-mlogloss:0.520308\ttest-mlogloss:0.571373\n",
      "[1400]\ttrain-mlogloss:0.516093\ttest-mlogloss:0.570564\n",
      "[1500]\ttrain-mlogloss:0.511966\ttest-mlogloss:0.569834\n",
      "[1600]\ttrain-mlogloss:0.50806\ttest-mlogloss:0.569364\n",
      "[1700]\ttrain-mlogloss:0.504287\ttest-mlogloss:0.568762\n",
      "[1800]\ttrain-mlogloss:0.500594\ttest-mlogloss:0.568388\n",
      "[1900]\ttrain-mlogloss:0.497105\ttest-mlogloss:0.567991\n",
      "[1999]\ttrain-mlogloss:0.493754\ttest-mlogloss:0.567624\n",
      "[0.57343867988276187, 0.56762394555153828]\n",
      "round: 10\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.814706\ttest-mlogloss:0.837958\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-mlogloss:0.431305\ttest-mlogloss:0.597441\n",
      "\n",
      "[0.60880794198496591]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.815115\ttest-mlogloss:0.839201\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\ttrain-mlogloss:0.397905\ttest-mlogloss:0.590366\n",
      "\n",
      "[0.60880794198496591, 0.60362108574702789]\n",
      "round: 11\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 4, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 4}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.852785\ttest-mlogloss:0.856666\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[37]\ttrain-mlogloss:0.501669\ttest-mlogloss:0.585629\n",
      "\n",
      "[0.5877924229297774]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.854636\ttest-mlogloss:0.85549\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[43]\ttrain-mlogloss:0.49622\ttest-mlogloss:0.583552\n",
      "\n",
      "[0.5877924229297774, 0.58576151463617032]\n",
      "round: 12\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 1, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09228\ttest-mlogloss:1.09241\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.74996\ttest-mlogloss:0.762548\n",
      "[200]\ttrain-mlogloss:0.641033\ttest-mlogloss:0.664474\n",
      "[300]\ttrain-mlogloss:0.594231\ttest-mlogloss:0.626862\n",
      "[400]\ttrain-mlogloss:0.567176\ttest-mlogloss:0.608845\n",
      "[500]\ttrain-mlogloss:0.547993\ttest-mlogloss:0.598313\n",
      "[600]\ttrain-mlogloss:0.533017\ttest-mlogloss:0.591184\n",
      "[700]\ttrain-mlogloss:0.52023\ttest-mlogloss:0.585965\n",
      "[800]\ttrain-mlogloss:0.508955\ttest-mlogloss:0.582055\n",
      "[900]\ttrain-mlogloss:0.498759\ttest-mlogloss:0.578768\n",
      "[1000]\ttrain-mlogloss:0.489173\ttest-mlogloss:0.576301\n",
      "[1100]\ttrain-mlogloss:0.480236\ttest-mlogloss:0.574249\n",
      "[1200]\ttrain-mlogloss:0.471869\ttest-mlogloss:0.572493\n",
      "[1300]\ttrain-mlogloss:0.464206\ttest-mlogloss:0.571099\n",
      "[1400]\ttrain-mlogloss:0.456612\ttest-mlogloss:0.569887\n",
      "[1500]\ttrain-mlogloss:0.449535\ttest-mlogloss:0.56887\n",
      "[1600]\ttrain-mlogloss:0.442559\ttest-mlogloss:0.568005\n",
      "[1700]\ttrain-mlogloss:0.435844\ttest-mlogloss:0.567224\n",
      "[1800]\ttrain-mlogloss:0.429516\ttest-mlogloss:0.566525\n",
      "[1900]\ttrain-mlogloss:0.423469\ttest-mlogloss:0.566011\n",
      "[1999]\ttrain-mlogloss:0.417367\ttest-mlogloss:0.565556\n",
      "[0.56555630309292271]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.09233\ttest-mlogloss:1.09244\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.753588\ttest-mlogloss:0.762938\n",
      "[200]\ttrain-mlogloss:0.64607\ttest-mlogloss:0.663648\n",
      "[300]\ttrain-mlogloss:0.599157\ttest-mlogloss:0.624786\n",
      "[400]\ttrain-mlogloss:0.572223\ttest-mlogloss:0.606071\n",
      "[500]\ttrain-mlogloss:0.552721\ttest-mlogloss:0.594895\n",
      "[600]\ttrain-mlogloss:0.53706\ttest-mlogloss:0.587224\n",
      "[700]\ttrain-mlogloss:0.524049\ttest-mlogloss:0.58196\n",
      "[800]\ttrain-mlogloss:0.512798\ttest-mlogloss:0.578035\n",
      "[900]\ttrain-mlogloss:0.502517\ttest-mlogloss:0.574811\n",
      "[1000]\ttrain-mlogloss:0.492671\ttest-mlogloss:0.572096\n",
      "[1100]\ttrain-mlogloss:0.483851\ttest-mlogloss:0.569907\n",
      "[1200]\ttrain-mlogloss:0.475737\ttest-mlogloss:0.568241\n",
      "[1300]\ttrain-mlogloss:0.468237\ttest-mlogloss:0.566843\n",
      "[1400]\ttrain-mlogloss:0.460775\ttest-mlogloss:0.565487\n",
      "[1500]\ttrain-mlogloss:0.453798\ttest-mlogloss:0.564354\n",
      "[1600]\ttrain-mlogloss:0.447011\ttest-mlogloss:0.563361\n",
      "[1700]\ttrain-mlogloss:0.440344\ttest-mlogloss:0.562548\n",
      "[1800]\ttrain-mlogloss:0.433882\ttest-mlogloss:0.561904\n",
      "[1900]\ttrain-mlogloss:0.427863\ttest-mlogloss:0.561278\n",
      "[1999]\ttrain-mlogloss:0.422148\ttest-mlogloss:0.56075\n",
      "[0.56555630309292271, 0.56075045992215411]\n",
      "round: 13\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.03798\ttest-mlogloss:1.03912\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.489198\ttest-mlogloss:0.579828\n",
      "[200]\ttrain-mlogloss:0.416382\ttest-mlogloss:0.570655\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-mlogloss:0.408834\ttest-mlogloss:0.570261\n",
      "\n",
      "[0.57043123583245525]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.03799\ttest-mlogloss:1.03889\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.494841\ttest-mlogloss:0.574348\n",
      "[200]\ttrain-mlogloss:0.421923\ttest-mlogloss:0.565843\n",
      "Stopping. Best iteration:\n",
      "[270]\ttrain-mlogloss:0.382714\ttest-mlogloss:0.563514\n",
      "\n",
      "[0.57043123583245525, 0.56409022093701788]\n",
      "round: 14\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 1, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 4}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.718987\ttest-mlogloss:0.72847\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-mlogloss:0.546931\ttest-mlogloss:0.605666\n",
      "\n",
      "[0.61402081708169132]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.722319\ttest-mlogloss:0.724467\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mlogloss:0.518206\ttest-mlogloss:0.594081\n",
      "\n",
      "[0.61402081708169132, 0.60599143505888564]\n",
      "round: 15\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.02782\ttest-mlogloss:1.03486\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.281292\ttest-mlogloss:0.574635\n",
      "Stopping. Best iteration:\n",
      "[88]\ttrain-mlogloss:0.298081\ttest-mlogloss:0.574336\n",
      "\n",
      "[0.5753393786655423]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.02796\ttest-mlogloss:1.03533\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.286985\ttest-mlogloss:0.568902\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-mlogloss:0.300793\ttest-mlogloss:0.568432\n",
      "\n",
      "[0.5753393786655423, 0.5695474077338093]\n",
      "round: 16\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 4, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.685072\ttest-mlogloss:0.711726\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[5]\ttrain-mlogloss:0.488098\ttest-mlogloss:0.621028\n",
      "\n",
      "[0.68289637178871287]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.685092\ttest-mlogloss:0.711432\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[4]\ttrain-mlogloss:0.508489\ttest-mlogloss:0.613115\n",
      "\n",
      "[0.68289637178871287, 0.66388687910397792]\n",
      "round: 17\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 0, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06479\ttest-mlogloss:1.06678\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.464616\ttest-mlogloss:0.584847\n",
      "[200]\ttrain-mlogloss:0.373136\ttest-mlogloss:0.573152\n",
      "Stopping. Best iteration:\n",
      "[240]\ttrain-mlogloss:0.345331\ttest-mlogloss:0.5724\n",
      "\n",
      "[0.57319892619937352]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06499\ttest-mlogloss:1.06668\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.470002\ttest-mlogloss:0.580281\n",
      "[200]\ttrain-mlogloss:0.378663\ttest-mlogloss:0.567181\n",
      "Stopping. Best iteration:\n",
      "[242]\ttrain-mlogloss:0.350461\ttest-mlogloss:0.566151\n",
      "\n",
      "[0.57319892619937352, 0.5665939026266269]\n",
      "round: 18\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 3, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09117\ttest-mlogloss:1.09202\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.663022\ttest-mlogloss:0.739868\n",
      "[200]\ttrain-mlogloss:0.505704\ttest-mlogloss:0.635582\n",
      "[300]\ttrain-mlogloss:0.42853\ttest-mlogloss:0.598062\n",
      "[400]\ttrain-mlogloss:0.382483\ttest-mlogloss:0.582959\n",
      "[500]\ttrain-mlogloss:0.349476\ttest-mlogloss:0.57582\n",
      "[600]\ttrain-mlogloss:0.323041\ttest-mlogloss:0.572272\n",
      "[700]\ttrain-mlogloss:0.300882\ttest-mlogloss:0.57064\n",
      "Stopping. Best iteration:\n",
      "[779]\ttrain-mlogloss:0.285044\ttest-mlogloss:0.570084\n",
      "\n",
      "[0.57014200393921066]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.09105\ttest-mlogloss:1.09196\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.66665\ttest-mlogloss:0.739512\n",
      "[200]\ttrain-mlogloss:0.510068\ttest-mlogloss:0.633653\n",
      "[300]\ttrain-mlogloss:0.43348\ttest-mlogloss:0.594761\n",
      "[400]\ttrain-mlogloss:0.388393\ttest-mlogloss:0.578905\n",
      "[500]\ttrain-mlogloss:0.355347\ttest-mlogloss:0.571412\n",
      "[600]\ttrain-mlogloss:0.328871\ttest-mlogloss:0.567535\n",
      "[700]\ttrain-mlogloss:0.306797\ttest-mlogloss:0.565733\n",
      "[800]\ttrain-mlogloss:0.286912\ttest-mlogloss:0.564928\n",
      "Stopping. Best iteration:\n",
      "[845]\ttrain-mlogloss:0.278724\ttest-mlogloss:0.564888\n",
      "\n",
      "[0.57014200393921066, 0.56493742326764496]\n",
      "round: 19\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 1, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.0386\ttest-mlogloss:1.03954\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.495893\ttest-mlogloss:0.579411\n",
      "[200]\ttrain-mlogloss:0.427116\ttest-mlogloss:0.570271\n",
      "Stopping. Best iteration:\n",
      "[255]\ttrain-mlogloss:0.398811\ttest-mlogloss:0.568949\n",
      "\n",
      "[0.56917350773903175]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.03852\ttest-mlogloss:1.03942\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.501162\ttest-mlogloss:0.575968\n",
      "[200]\ttrain-mlogloss:0.434159\ttest-mlogloss:0.564871\n",
      "Stopping. Best iteration:\n",
      "[270]\ttrain-mlogloss:0.397622\ttest-mlogloss:0.562685\n",
      "\n",
      "[0.56917350773903175, 0.56308043456418777]\n",
      "round: 20\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.02951\ttest-mlogloss:1.03556\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.307405\ttest-mlogloss:0.57443\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-mlogloss:0.311969\ttest-mlogloss:0.574275\n",
      "\n",
      "[0.57510124355807724]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.02893\ttest-mlogloss:1.0352\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.302549\ttest-mlogloss:0.569059\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mlogloss:0.318031\ttest-mlogloss:0.568792\n",
      "\n",
      "[0.57510124355807724, 0.5689848501381124]\n",
      "round: 21\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 5, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 2}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.07166\ttest-mlogloss:1.0718\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.63901\ttest-mlogloss:0.649799\n",
      "[200]\ttrain-mlogloss:0.602443\ttest-mlogloss:0.619368\n",
      "[300]\ttrain-mlogloss:0.583484\ttest-mlogloss:0.605256\n",
      "[400]\ttrain-mlogloss:0.570378\ttest-mlogloss:0.597208\n",
      "[500]\ttrain-mlogloss:0.560273\ttest-mlogloss:0.591159\n",
      "[600]\ttrain-mlogloss:0.551897\ttest-mlogloss:0.587077\n",
      "[700]\ttrain-mlogloss:0.544437\ttest-mlogloss:0.5837\n",
      "[800]\ttrain-mlogloss:0.538114\ttest-mlogloss:0.5816\n",
      "[900]\ttrain-mlogloss:0.532479\ttest-mlogloss:0.579664\n",
      "[1000]\ttrain-mlogloss:0.527056\ttest-mlogloss:0.578289\n",
      "[1100]\ttrain-mlogloss:0.522069\ttest-mlogloss:0.577064\n",
      "[1200]\ttrain-mlogloss:0.517357\ttest-mlogloss:0.576121\n",
      "[1300]\ttrain-mlogloss:0.512842\ttest-mlogloss:0.575214\n",
      "[1400]\ttrain-mlogloss:0.508627\ttest-mlogloss:0.574504\n",
      "[1500]\ttrain-mlogloss:0.504559\ttest-mlogloss:0.573797\n",
      "[1600]\ttrain-mlogloss:0.500844\ttest-mlogloss:0.5734\n",
      "[1700]\ttrain-mlogloss:0.497108\ttest-mlogloss:0.57293\n",
      "[1800]\ttrain-mlogloss:0.493495\ttest-mlogloss:0.572346\n",
      "Stopping. Best iteration:\n",
      "[1869]\ttrain-mlogloss:0.490985\ttest-mlogloss:0.572091\n",
      "\n",
      "[0.57210556144413749]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.0715\ttest-mlogloss:1.07152\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.645004\ttest-mlogloss:0.648329\n",
      "[200]\ttrain-mlogloss:0.608851\ttest-mlogloss:0.617261\n",
      "[300]\ttrain-mlogloss:0.589658\ttest-mlogloss:0.602697\n",
      "[400]\ttrain-mlogloss:0.576697\ttest-mlogloss:0.594528\n",
      "[500]\ttrain-mlogloss:0.566507\ttest-mlogloss:0.588654\n",
      "[600]\ttrain-mlogloss:0.55837\ttest-mlogloss:0.5846\n",
      "[700]\ttrain-mlogloss:0.551231\ttest-mlogloss:0.581628\n",
      "[800]\ttrain-mlogloss:0.545154\ttest-mlogloss:0.579333\n",
      "[900]\ttrain-mlogloss:0.539574\ttest-mlogloss:0.577345\n",
      "[1000]\ttrain-mlogloss:0.534403\ttest-mlogloss:0.575519\n",
      "[1100]\ttrain-mlogloss:0.529413\ttest-mlogloss:0.573955\n",
      "[1200]\ttrain-mlogloss:0.52481\ttest-mlogloss:0.572948\n",
      "[1300]\ttrain-mlogloss:0.520476\ttest-mlogloss:0.571899\n",
      "[1400]\ttrain-mlogloss:0.51627\ttest-mlogloss:0.57111\n",
      "[1500]\ttrain-mlogloss:0.512454\ttest-mlogloss:0.570437\n",
      "[1600]\ttrain-mlogloss:0.508531\ttest-mlogloss:0.569775\n",
      "Stopping. Best iteration:\n",
      "[1669]\ttrain-mlogloss:0.505874\ttest-mlogloss:0.56928\n",
      "\n",
      "[0.57210556144413749, 0.56928454326275557]\n",
      "round: 22\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 4, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.701224\ttest-mlogloss:0.714553\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[10]\ttrain-mlogloss:0.49613\ttest-mlogloss:0.603115\n",
      "\n",
      "[0.6199293848567109]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.703892\ttest-mlogloss:0.713557\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-mlogloss:0.494424\ttest-mlogloss:0.596967\n",
      "\n",
      "[0.6199293848567109, 0.61624843633400195]\n",
      "round: 23\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 2, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.830834\ttest-mlogloss:0.845736\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mlogloss:0.445325\ttest-mlogloss:0.601179\n",
      "\n",
      "[0.62059670379243892]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.831415\ttest-mlogloss:0.844614\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[13]\ttrain-mlogloss:0.45369\ttest-mlogloss:0.597673\n",
      "\n",
      "[0.62059670379243892, 0.60981795650514847]\n",
      "round: 24\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 5, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09123\ttest-mlogloss:1.09199\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.66707\ttest-mlogloss:0.739708\n",
      "[200]\ttrain-mlogloss:0.512695\ttest-mlogloss:0.635489\n",
      "[300]\ttrain-mlogloss:0.437934\ttest-mlogloss:0.598011\n",
      "[400]\ttrain-mlogloss:0.393816\ttest-mlogloss:0.582583\n",
      "[500]\ttrain-mlogloss:0.362761\ttest-mlogloss:0.575154\n",
      "[600]\ttrain-mlogloss:0.337668\ttest-mlogloss:0.571497\n",
      "[700]\ttrain-mlogloss:0.31648\ttest-mlogloss:0.56951\n",
      "[800]\ttrain-mlogloss:0.29785\ttest-mlogloss:0.56872\n",
      "[900]\ttrain-mlogloss:0.281615\ttest-mlogloss:0.568313\n",
      "Stopping. Best iteration:\n",
      "[926]\ttrain-mlogloss:0.277627\ttest-mlogloss:0.568252\n",
      "\n",
      "[0.56832948347302736]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.09125\ttest-mlogloss:1.092\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.670639\ttest-mlogloss:0.739057\n",
      "[200]\ttrain-mlogloss:0.516354\ttest-mlogloss:0.633565\n",
      "[300]\ttrain-mlogloss:0.441864\ttest-mlogloss:0.594985\n",
      "[400]\ttrain-mlogloss:0.398216\ttest-mlogloss:0.57896\n",
      "[500]\ttrain-mlogloss:0.367091\ttest-mlogloss:0.571057\n",
      "[600]\ttrain-mlogloss:0.341368\ttest-mlogloss:0.566923\n",
      "[700]\ttrain-mlogloss:0.319942\ttest-mlogloss:0.564537\n",
      "[800]\ttrain-mlogloss:0.301785\ttest-mlogloss:0.563481\n",
      "[900]\ttrain-mlogloss:0.285257\ttest-mlogloss:0.562956\n",
      "Stopping. Best iteration:\n",
      "[955]\ttrain-mlogloss:0.276766\ttest-mlogloss:0.562845\n",
      "\n",
      "[0.56832948347302736, 0.56289350515997882]\n",
      "round: 25\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 0, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06756\ttest-mlogloss:1.06822\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.547599\ttest-mlogloss:0.59835\n",
      "[200]\ttrain-mlogloss:0.487947\ttest-mlogloss:0.577199\n",
      "[300]\ttrain-mlogloss:0.449048\ttest-mlogloss:0.569889\n",
      "[400]\ttrain-mlogloss:0.416569\ttest-mlogloss:0.566631\n",
      "[500]\ttrain-mlogloss:0.389721\ttest-mlogloss:0.565533\n",
      "Stopping. Best iteration:\n",
      "[513]\ttrain-mlogloss:0.386379\ttest-mlogloss:0.565424\n",
      "\n",
      "[0.56546223135535567]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06757\ttest-mlogloss:1.06801\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.551639\ttest-mlogloss:0.594878\n",
      "[200]\ttrain-mlogloss:0.492686\ttest-mlogloss:0.573265\n",
      "[300]\ttrain-mlogloss:0.451978\ttest-mlogloss:0.565544\n",
      "[400]\ttrain-mlogloss:0.420785\ttest-mlogloss:0.562295\n",
      "[500]\ttrain-mlogloss:0.393547\ttest-mlogloss:0.560541\n",
      "[600]\ttrain-mlogloss:0.369017\ttest-mlogloss:0.560006\n",
      "Stopping. Best iteration:\n",
      "[620]\ttrain-mlogloss:0.364447\ttest-mlogloss:0.559819\n",
      "\n",
      "[0.56546223135535567, 0.55990372995058268]\n",
      "round: 26\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 2}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.757944\ttest-mlogloss:0.76306\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[54]\ttrain-mlogloss:0.530139\ttest-mlogloss:0.59503\n",
      "\n",
      "[0.5972628745975076]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.757783\ttest-mlogloss:0.75729\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[53]\ttrain-mlogloss:0.53856\ttest-mlogloss:0.586929\n",
      "\n",
      "[0.5972628745975076, 0.58796907953234034]\n",
      "round: 27\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 6}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.03534\ttest-mlogloss:1.03752\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.44044\ttest-mlogloss:0.577547\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-mlogloss:0.394816\ttest-mlogloss:0.57486\n",
      "\n",
      "[0.5755188594006212]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.03569\ttest-mlogloss:1.03765\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.445819\ttest-mlogloss:0.570614\n",
      "Stopping. Best iteration:\n",
      "[163]\ttrain-mlogloss:0.383953\ttest-mlogloss:0.567338\n",
      "\n",
      "[0.5755188594006212, 0.5675376946659122]\n",
      "round: 28\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 2, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 4}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.717398\ttest-mlogloss:0.726959\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-mlogloss:0.551844\ttest-mlogloss:0.608426\n",
      "\n",
      "[0.6216721038371098]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.722853\ttest-mlogloss:0.725878\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[16]\ttrain-mlogloss:0.519242\ttest-mlogloss:0.602094\n",
      "\n",
      "[0.6216721038371098, 0.61739042935519539]\n",
      "round: 29\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 4, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06337\ttest-mlogloss:1.06596\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.427621\ttest-mlogloss:0.579605\n",
      "[200]\ttrain-mlogloss:0.33886\ttest-mlogloss:0.568704\n",
      "Stopping. Best iteration:\n",
      "[238]\ttrain-mlogloss:0.315189\ttest-mlogloss:0.568112\n",
      "\n",
      "[0.56831961326776048]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06363\ttest-mlogloss:1.06612\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.42789\ttest-mlogloss:0.574778\n",
      "[200]\ttrain-mlogloss:0.341529\ttest-mlogloss:0.56357\n",
      "Stopping. Best iteration:\n",
      "[243]\ttrain-mlogloss:0.313655\ttest-mlogloss:0.562641\n",
      "\n",
      "[0.56831961326776048, 0.56267902004770776]\n",
      "round: 30\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 3, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 6}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.0666\ttest-mlogloss:1.06753\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.516538\ttest-mlogloss:0.590233\n",
      "[200]\ttrain-mlogloss:0.450091\ttest-mlogloss:0.572647\n",
      "[300]\ttrain-mlogloss:0.402478\ttest-mlogloss:0.56782\n",
      "Stopping. Best iteration:\n",
      "[353]\ttrain-mlogloss:0.381308\ttest-mlogloss:0.566707\n",
      "\n",
      "[0.56674687573204185]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06662\ttest-mlogloss:1.06741\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.521294\ttest-mlogloss:0.586018\n",
      "[200]\ttrain-mlogloss:0.454047\ttest-mlogloss:0.567907\n",
      "[300]\ttrain-mlogloss:0.40496\ttest-mlogloss:0.562777\n",
      "Stopping. Best iteration:\n",
      "[343]\ttrain-mlogloss:0.387981\ttest-mlogloss:0.561507\n",
      "\n",
      "[0.56674687573204185, 0.56172719273549954]\n",
      "round: 31\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.845792\ttest-mlogloss:0.851373\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[38]\ttrain-mlogloss:0.451336\ttest-mlogloss:0.581522\n",
      "\n",
      "[0.58517143158726725]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.846726\ttest-mlogloss:0.850023\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[31]\ttrain-mlogloss:0.469526\ttest-mlogloss:0.576665\n",
      "\n",
      "[0.58517143158726725, 0.5778388696391894]\n",
      "round: 32\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 5, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06462\ttest-mlogloss:1.06663\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.456208\ttest-mlogloss:0.582367\n",
      "[200]\ttrain-mlogloss:0.37266\ttest-mlogloss:0.572337\n",
      "Stopping. Best iteration:\n",
      "[214]\ttrain-mlogloss:0.364036\ttest-mlogloss:0.571902\n",
      "\n",
      "[0.57206982394642514]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06468\ttest-mlogloss:1.06679\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.460565\ttest-mlogloss:0.577612\n",
      "[200]\ttrain-mlogloss:0.377004\ttest-mlogloss:0.565174\n",
      "Stopping. Best iteration:\n",
      "[240]\ttrain-mlogloss:0.353022\ttest-mlogloss:0.56396\n",
      "\n",
      "[0.57206982394642514, 0.56421249473985824]\n",
      "round: 33\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 4, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 3}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.07008\ttest-mlogloss:1.07037\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.60906\ttest-mlogloss:0.627417\n",
      "[200]\ttrain-mlogloss:0.56943\ttest-mlogloss:0.599418\n",
      "[300]\ttrain-mlogloss:0.547193\ttest-mlogloss:0.587995\n",
      "[400]\ttrain-mlogloss:0.530317\ttest-mlogloss:0.581432\n",
      "[500]\ttrain-mlogloss:0.516503\ttest-mlogloss:0.577184\n",
      "[600]\ttrain-mlogloss:0.504748\ttest-mlogloss:0.5743\n",
      "[700]\ttrain-mlogloss:0.493759\ttest-mlogloss:0.572051\n",
      "[800]\ttrain-mlogloss:0.483906\ttest-mlogloss:0.570758\n",
      "[900]\ttrain-mlogloss:0.47499\ttest-mlogloss:0.569649\n",
      "[1000]\ttrain-mlogloss:0.466229\ttest-mlogloss:0.568862\n",
      "[1100]\ttrain-mlogloss:0.458319\ttest-mlogloss:0.568347\n",
      "Stopping. Best iteration:\n",
      "[1099]\ttrain-mlogloss:0.458371\ttest-mlogloss:0.568327\n",
      "\n",
      "[0.56835993806484941]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.07021\ttest-mlogloss:1.07027\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.614507\ttest-mlogloss:0.624599\n",
      "[200]\ttrain-mlogloss:0.574753\ttest-mlogloss:0.596556\n",
      "[300]\ttrain-mlogloss:0.552324\ttest-mlogloss:0.584485\n",
      "[400]\ttrain-mlogloss:0.535757\ttest-mlogloss:0.577777\n",
      "[500]\ttrain-mlogloss:0.52247\ttest-mlogloss:0.573336\n",
      "[600]\ttrain-mlogloss:0.510708\ttest-mlogloss:0.570239\n",
      "[700]\ttrain-mlogloss:0.499988\ttest-mlogloss:0.568001\n",
      "[800]\ttrain-mlogloss:0.490565\ttest-mlogloss:0.566163\n",
      "[900]\ttrain-mlogloss:0.481325\ttest-mlogloss:0.564931\n",
      "[1000]\ttrain-mlogloss:0.472884\ttest-mlogloss:0.563816\n",
      "[1100]\ttrain-mlogloss:0.464715\ttest-mlogloss:0.562894\n",
      "[1200]\ttrain-mlogloss:0.457024\ttest-mlogloss:0.562496\n",
      "[1300]\ttrain-mlogloss:0.449747\ttest-mlogloss:0.561899\n",
      "Stopping. Best iteration:\n",
      "[1318]\ttrain-mlogloss:0.448454\ttest-mlogloss:0.561728\n",
      "\n",
      "[0.56835993806484941, 0.5617657698419688]\n",
      "round: 34\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 3, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 6}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09202\ttest-mlogloss:1.09227\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.732509\ttest-mlogloss:0.753372\n",
      "[200]\ttrain-mlogloss:0.616144\ttest-mlogloss:0.653305\n",
      "[300]\ttrain-mlogloss:0.56501\ttest-mlogloss:0.615918\n",
      "[400]\ttrain-mlogloss:0.534458\ttest-mlogloss:0.598499\n",
      "[500]\ttrain-mlogloss:0.512624\ttest-mlogloss:0.588688\n",
      "[600]\ttrain-mlogloss:0.495313\ttest-mlogloss:0.582477\n",
      "[700]\ttrain-mlogloss:0.480507\ttest-mlogloss:0.57827\n",
      "[800]\ttrain-mlogloss:0.466835\ttest-mlogloss:0.574999\n",
      "[900]\ttrain-mlogloss:0.454974\ttest-mlogloss:0.572554\n",
      "[1000]\ttrain-mlogloss:0.443587\ttest-mlogloss:0.570514\n",
      "[1100]\ttrain-mlogloss:0.43257\ttest-mlogloss:0.569053\n",
      "[1200]\ttrain-mlogloss:0.422374\ttest-mlogloss:0.567824\n",
      "[1300]\ttrain-mlogloss:0.41278\ttest-mlogloss:0.566914\n",
      "[1400]\ttrain-mlogloss:0.403341\ttest-mlogloss:0.566058\n",
      "[1500]\ttrain-mlogloss:0.394593\ttest-mlogloss:0.565482\n",
      "[1600]\ttrain-mlogloss:0.386162\ttest-mlogloss:0.564998\n",
      "Stopping. Best iteration:\n",
      "[1678]\ttrain-mlogloss:0.379844\ttest-mlogloss:0.564774\n",
      "\n",
      "[0.56479383582665543]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.09203\ttest-mlogloss:1.09222\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.736088\ttest-mlogloss:0.753765\n",
      "[200]\ttrain-mlogloss:0.620306\ttest-mlogloss:0.652128\n",
      "[300]\ttrain-mlogloss:0.568695\ttest-mlogloss:0.61344\n",
      "[400]\ttrain-mlogloss:0.538981\ttest-mlogloss:0.595329\n",
      "[500]\ttrain-mlogloss:0.516441\ttest-mlogloss:0.584943\n",
      "[600]\ttrain-mlogloss:0.498682\ttest-mlogloss:0.578269\n",
      "[700]\ttrain-mlogloss:0.483675\ttest-mlogloss:0.57369\n",
      "[800]\ttrain-mlogloss:0.470349\ttest-mlogloss:0.57047\n",
      "[900]\ttrain-mlogloss:0.45832\ttest-mlogloss:0.567949\n",
      "[1000]\ttrain-mlogloss:0.446802\ttest-mlogloss:0.565905\n",
      "[1100]\ttrain-mlogloss:0.436272\ttest-mlogloss:0.564266\n",
      "[1200]\ttrain-mlogloss:0.426638\ttest-mlogloss:0.563074\n",
      "[1300]\ttrain-mlogloss:0.417175\ttest-mlogloss:0.562122\n",
      "[1400]\ttrain-mlogloss:0.407968\ttest-mlogloss:0.561306\n",
      "[1500]\ttrain-mlogloss:0.399315\ttest-mlogloss:0.560489\n",
      "[1600]\ttrain-mlogloss:0.390838\ttest-mlogloss:0.55996\n",
      "[1700]\ttrain-mlogloss:0.382526\ttest-mlogloss:0.559674\n",
      "Stopping. Best iteration:\n",
      "[1698]\ttrain-mlogloss:0.382694\ttest-mlogloss:0.559656\n",
      "\n",
      "[0.56479383582665543, 0.55971602764852457]\n",
      "round: 35\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 1, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06274\ttest-mlogloss:1.0659\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.407405\ttest-mlogloss:0.579982\n",
      "[200]\ttrain-mlogloss:0.306003\ttest-mlogloss:0.571737\n",
      "Stopping. Best iteration:\n",
      "[192]\ttrain-mlogloss:0.313063\ttest-mlogloss:0.571537\n",
      "\n",
      "[0.57223872939073051]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06287\ttest-mlogloss:1.06586\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.409068\ttest-mlogloss:0.573973\n",
      "[200]\ttrain-mlogloss:0.309414\ttest-mlogloss:0.564459\n",
      "Stopping. Best iteration:\n",
      "[190]\ttrain-mlogloss:0.3173\ttest-mlogloss:0.564213\n",
      "\n",
      "[0.57223872939073051, 0.56438298592380531]\n",
      "round: 36\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 1, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 3}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.863745\ttest-mlogloss:0.866477\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.471401\ttest-mlogloss:0.58218\n",
      "Stopping. Best iteration:\n",
      "[88]\ttrain-mlogloss:0.479888\ttest-mlogloss:0.580739\n",
      "\n",
      "[0.58174239542398631]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.86369\ttest-mlogloss:0.86381\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.476023\ttest-mlogloss:0.574496\n",
      "Stopping. Best iteration:\n",
      "[116]\ttrain-mlogloss:0.463972\ttest-mlogloss:0.573522\n",
      "\n",
      "[0.58174239542398631, 0.57512944091526919]\n",
      "round: 37\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 4, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.02873\ttest-mlogloss:1.03621\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[74]\ttrain-mlogloss:0.323739\ttest-mlogloss:0.57937\n",
      "\n",
      "[0.58038853282217473]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.02853\ttest-mlogloss:1.0354\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.283614\ttest-mlogloss:0.572021\n",
      "Stopping. Best iteration:\n",
      "[83]\ttrain-mlogloss:0.312076\ttest-mlogloss:0.571332\n",
      "\n",
      "[0.58038853282217473, 0.57247153526365147]\n",
      "round: 38\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 4}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.04026\ttest-mlogloss:1.04097\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.533794\ttest-mlogloss:0.587036\n",
      "[200]\ttrain-mlogloss:0.480015\ttest-mlogloss:0.575047\n",
      "[300]\ttrain-mlogloss:0.441564\ttest-mlogloss:0.572482\n",
      "Stopping. Best iteration:\n",
      "[313]\ttrain-mlogloss:0.437056\ttest-mlogloss:0.572278\n",
      "\n",
      "[0.57275655957140381]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.04014\ttest-mlogloss:1.04058\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.538992\ttest-mlogloss:0.582971\n",
      "[200]\ttrain-mlogloss:0.485582\ttest-mlogloss:0.570329\n",
      "Stopping. Best iteration:\n",
      "[262]\ttrain-mlogloss:0.461387\ttest-mlogloss:0.567134\n",
      "\n",
      "[0.57275655957140381, 0.56722472538017399]\n",
      "round: 39\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 0, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 2}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.07126\ttest-mlogloss:1.07149\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.639728\ttest-mlogloss:0.650689\n",
      "[200]\ttrain-mlogloss:0.603334\ttest-mlogloss:0.620008\n",
      "[300]\ttrain-mlogloss:0.584566\ttest-mlogloss:0.606442\n",
      "[400]\ttrain-mlogloss:0.571531\ttest-mlogloss:0.598083\n",
      "[500]\ttrain-mlogloss:0.561131\ttest-mlogloss:0.592161\n",
      "[600]\ttrain-mlogloss:0.5527\ttest-mlogloss:0.588194\n",
      "[700]\ttrain-mlogloss:0.545444\ttest-mlogloss:0.585142\n",
      "[800]\ttrain-mlogloss:0.538984\ttest-mlogloss:0.58284\n",
      "[900]\ttrain-mlogloss:0.533102\ttest-mlogloss:0.580839\n",
      "[1000]\ttrain-mlogloss:0.527646\ttest-mlogloss:0.579055\n",
      "[1100]\ttrain-mlogloss:0.522588\ttest-mlogloss:0.577989\n",
      "[1200]\ttrain-mlogloss:0.51791\ttest-mlogloss:0.577218\n",
      "[1300]\ttrain-mlogloss:0.513228\ttest-mlogloss:0.576118\n",
      "[1400]\ttrain-mlogloss:0.508842\ttest-mlogloss:0.575129\n",
      "[1500]\ttrain-mlogloss:0.504629\ttest-mlogloss:0.574473\n",
      "[1600]\ttrain-mlogloss:0.500543\ttest-mlogloss:0.573786\n",
      "Stopping. Best iteration:\n",
      "[1599]\ttrain-mlogloss:0.500574\ttest-mlogloss:0.573771\n",
      "\n",
      "[0.57377213414868433]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.07148\ttest-mlogloss:1.0714\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.645745\ttest-mlogloss:0.648979\n",
      "[200]\ttrain-mlogloss:0.609751\ttest-mlogloss:0.618245\n",
      "[300]\ttrain-mlogloss:0.590463\ttest-mlogloss:0.603591\n",
      "[400]\ttrain-mlogloss:0.577279\ttest-mlogloss:0.595272\n",
      "[500]\ttrain-mlogloss:0.566996\ttest-mlogloss:0.589322\n",
      "[600]\ttrain-mlogloss:0.558778\ttest-mlogloss:0.585159\n",
      "[700]\ttrain-mlogloss:0.551526\ttest-mlogloss:0.581988\n",
      "[800]\ttrain-mlogloss:0.545281\ttest-mlogloss:0.579363\n",
      "[900]\ttrain-mlogloss:0.539396\ttest-mlogloss:0.577304\n",
      "[1000]\ttrain-mlogloss:0.53405\ttest-mlogloss:0.575448\n",
      "[1100]\ttrain-mlogloss:0.529099\ttest-mlogloss:0.573863\n",
      "[1200]\ttrain-mlogloss:0.524445\ttest-mlogloss:0.572508\n",
      "[1300]\ttrain-mlogloss:0.520129\ttest-mlogloss:0.571611\n",
      "[1400]\ttrain-mlogloss:0.515891\ttest-mlogloss:0.570908\n",
      "[1500]\ttrain-mlogloss:0.511768\ttest-mlogloss:0.570084\n",
      "[1600]\ttrain-mlogloss:0.507847\ttest-mlogloss:0.569323\n",
      "[1700]\ttrain-mlogloss:0.504195\ttest-mlogloss:0.568849\n",
      "[1800]\ttrain-mlogloss:0.500574\ttest-mlogloss:0.568472\n",
      "[1900]\ttrain-mlogloss:0.497038\ttest-mlogloss:0.56802\n",
      "Stopping. Best iteration:\n",
      "[1931]\ttrain-mlogloss:0.495934\ttest-mlogloss:0.567898\n",
      "\n",
      "[0.57377213414868433, 0.56790909808695289]\n",
      "round: 40\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.803656\ttest-mlogloss:0.835172\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[10]\ttrain-mlogloss:0.405224\ttest-mlogloss:0.603566\n",
      "\n",
      "[0.63017137734283069]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.805534\ttest-mlogloss:0.834678\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-mlogloss:0.394554\ttest-mlogloss:0.598477\n",
      "\n",
      "[0.63017137734283069, 0.62527122683351721]\n",
      "round: 41\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 4, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 6}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.68289\ttest-mlogloss:0.70664\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[8]\ttrain-mlogloss:0.471668\ttest-mlogloss:0.610974\n",
      "\n",
      "[0.64434781138034436]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.686998\ttest-mlogloss:0.706219\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[6]\ttrain-mlogloss:0.498027\ttest-mlogloss:0.605758\n",
      "\n",
      "[0.64434781138034436, 0.63483821810367846]\n",
      "round: 42\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.822831\ttest-mlogloss:0.840925\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-mlogloss:0.443619\ttest-mlogloss:0.598936\n",
      "\n",
      "[0.61319710723546272]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.822011\ttest-mlogloss:0.842023\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mlogloss:0.411628\ttest-mlogloss:0.592491\n",
      "\n",
      "[0.61319710723546272, 0.60694930267051239]\n",
      "round: 43\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 0, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06512\ttest-mlogloss:1.06699\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.46341\ttest-mlogloss:0.584716\n",
      "[200]\ttrain-mlogloss:0.374627\ttest-mlogloss:0.570156\n",
      "Stopping. Best iteration:\n",
      "[256]\ttrain-mlogloss:0.339702\ttest-mlogloss:0.568652\n",
      "\n",
      "[0.56894478736076415]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06543\ttest-mlogloss:1.06706\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.466822\ttest-mlogloss:0.580052\n",
      "[200]\ttrain-mlogloss:0.380447\ttest-mlogloss:0.564432\n",
      "Stopping. Best iteration:\n",
      "[279]\ttrain-mlogloss:0.331609\ttest-mlogloss:0.562123\n",
      "\n",
      "[0.56894478736076415, 0.56236580952380111]\n",
      "round: 44\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.824711\ttest-mlogloss:0.842298\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[12]\ttrain-mlogloss:0.469987\ttest-mlogloss:0.605121\n",
      "\n",
      "[0.62124935427183214]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.826185\ttest-mlogloss:0.841839\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[13]\ttrain-mlogloss:0.455342\ttest-mlogloss:0.5951\n",
      "\n",
      "[0.62124935427183214, 0.61257037878528042]\n",
      "round: 45\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 5, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06377\ttest-mlogloss:1.06649\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.415839\ttest-mlogloss:0.578683\n",
      "[200]\ttrain-mlogloss:0.323361\ttest-mlogloss:0.570394\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.333757\ttest-mlogloss:0.570203\n",
      "\n",
      "[0.5704507371809]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06358\ttest-mlogloss:1.06628\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.418682\ttest-mlogloss:0.574811\n",
      "[200]\ttrain-mlogloss:0.32991\ttest-mlogloss:0.564772\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.341265\ttest-mlogloss:0.564444\n",
      "\n",
      "[0.5704507371809, 0.56470876745489962]\n",
      "round: 46\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 3}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.04295\ttest-mlogloss:1.04356\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.569713\ttest-mlogloss:0.599915\n",
      "[200]\ttrain-mlogloss:0.530616\ttest-mlogloss:0.583866\n",
      "[300]\ttrain-mlogloss:0.504617\ttest-mlogloss:0.577487\n",
      "[400]\ttrain-mlogloss:0.484054\ttest-mlogloss:0.574682\n",
      "Stopping. Best iteration:\n",
      "[428]\ttrain-mlogloss:0.478886\ttest-mlogloss:0.573875\n",
      "\n",
      "[0.57393751716174746]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.0427\ttest-mlogloss:1.04288\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.575373\ttest-mlogloss:0.596017\n",
      "[200]\ttrain-mlogloss:0.536179\ttest-mlogloss:0.578643\n",
      "[300]\ttrain-mlogloss:0.510526\ttest-mlogloss:0.572028\n",
      "[400]\ttrain-mlogloss:0.49043\ttest-mlogloss:0.569318\n",
      "[500]\ttrain-mlogloss:0.472596\ttest-mlogloss:0.567533\n",
      "Stopping. Best iteration:\n",
      "[543]\ttrain-mlogloss:0.465567\ttest-mlogloss:0.56717\n",
      "\n",
      "[0.57393751716174746, 0.5675751852901092]\n",
      "round: 47\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06748\ttest-mlogloss:1.06814\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.551061\ttest-mlogloss:0.599026\n",
      "[200]\ttrain-mlogloss:0.494674\ttest-mlogloss:0.577605\n",
      "[300]\ttrain-mlogloss:0.458197\ttest-mlogloss:0.570142\n",
      "[400]\ttrain-mlogloss:0.42744\ttest-mlogloss:0.56707\n",
      "[500]\ttrain-mlogloss:0.402474\ttest-mlogloss:0.565266\n",
      "Stopping. Best iteration:\n",
      "[565]\ttrain-mlogloss:0.387941\ttest-mlogloss:0.564646\n",
      "\n",
      "[0.56485097827066266]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06787\ttest-mlogloss:1.06828\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.555921\ttest-mlogloss:0.595445\n",
      "[200]\ttrain-mlogloss:0.50015\ttest-mlogloss:0.574247\n",
      "[300]\ttrain-mlogloss:0.4623\ttest-mlogloss:0.566095\n",
      "[400]\ttrain-mlogloss:0.432685\ttest-mlogloss:0.562816\n",
      "[500]\ttrain-mlogloss:0.407003\ttest-mlogloss:0.560859\n",
      "[600]\ttrain-mlogloss:0.384637\ttest-mlogloss:0.559791\n",
      "Stopping. Best iteration:\n",
      "[615]\ttrain-mlogloss:0.381731\ttest-mlogloss:0.559626\n",
      "\n",
      "[0.56485097827066266, 0.5597200221289419]\n",
      "round: 48\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 4, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 4}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.0688\ttest-mlogloss:1.06911\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.580758\ttest-mlogloss:0.609857\n",
      "[200]\ttrain-mlogloss:0.535222\ttest-mlogloss:0.586198\n",
      "[300]\ttrain-mlogloss:0.506437\ttest-mlogloss:0.576765\n",
      "[400]\ttrain-mlogloss:0.483884\ttest-mlogloss:0.571997\n",
      "[500]\ttrain-mlogloss:0.46523\ttest-mlogloss:0.569951\n",
      "[600]\ttrain-mlogloss:0.448316\ttest-mlogloss:0.568235\n",
      "Stopping. Best iteration:\n",
      "[655]\ttrain-mlogloss:0.439866\ttest-mlogloss:0.5677\n",
      "\n",
      "[0.56780853451096003]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06889\ttest-mlogloss:1.06897\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.585817\ttest-mlogloss:0.606635\n",
      "[200]\ttrain-mlogloss:0.540345\ttest-mlogloss:0.582047\n",
      "[300]\ttrain-mlogloss:0.510979\ttest-mlogloss:0.572223\n",
      "[400]\ttrain-mlogloss:0.489791\ttest-mlogloss:0.567313\n",
      "[500]\ttrain-mlogloss:0.470938\ttest-mlogloss:0.564621\n",
      "[600]\ttrain-mlogloss:0.454294\ttest-mlogloss:0.562898\n",
      "[700]\ttrain-mlogloss:0.438548\ttest-mlogloss:0.561801\n",
      "Stopping. Best iteration:\n",
      "[701]\ttrain-mlogloss:0.438405\ttest-mlogloss:0.561771\n",
      "\n",
      "[0.56780853451096003, 0.56177580610536548]\n",
      "round: 49\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 1, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.0254\ttest-mlogloss:1.03569\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[64]\ttrain-mlogloss:0.266122\ttest-mlogloss:0.582016\n",
      "\n",
      "[0.58374147657498954]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.02482\ttest-mlogloss:1.03524\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[71]\ttrain-mlogloss:0.253999\ttest-mlogloss:0.573768\n",
      "\n",
      "[0.58374147657498954, 0.57634439593577769]\n",
      "round: 50\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 5, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.03762\ttest-mlogloss:1.03896\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.497817\ttest-mlogloss:0.579288\n",
      "[200]\ttrain-mlogloss:0.433195\ttest-mlogloss:0.570745\n",
      "Stopping. Best iteration:\n",
      "[235]\ttrain-mlogloss:0.414669\ttest-mlogloss:0.569642\n",
      "\n",
      "[0.5702160607169392]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.03806\ttest-mlogloss:1.0393\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.500778\ttest-mlogloss:0.573588\n",
      "[200]\ttrain-mlogloss:0.436793\ttest-mlogloss:0.564654\n",
      "Stopping. Best iteration:\n",
      "[248]\ttrain-mlogloss:0.411756\ttest-mlogloss:0.563699\n",
      "\n",
      "[0.5702160607169392, 0.56373951786883159]\n",
      "round: 51\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 8}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.028\ttest-mlogloss:1.03458\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.294023\ttest-mlogloss:0.575369\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-mlogloss:0.31333\ttest-mlogloss:0.574982\n",
      "\n",
      "[0.57583173877506022]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.02818\ttest-mlogloss:1.03446\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.298949\ttest-mlogloss:0.567617\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-mlogloss:0.310013\ttest-mlogloss:0.567469\n",
      "\n",
      "[0.57583173877506022, 0.56812171530430844]\n",
      "round: 52\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 1, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 10}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06065\ttest-mlogloss:1.06595\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.320789\ttest-mlogloss:0.579119\n",
      "Stopping. Best iteration:\n",
      "[125]\ttrain-mlogloss:0.2858\ttest-mlogloss:0.577383\n",
      "\n",
      "[0.57804138161614937]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06061\ttest-mlogloss:1.06539\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.32294\ttest-mlogloss:0.574014\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-mlogloss:0.285082\ttest-mlogloss:0.572077\n",
      "\n",
      "[0.57804138161614937, 0.5725731239063131]\n",
      "round: 53\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09108\ttest-mlogloss:1.09191\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.667802\ttest-mlogloss:0.737937\n",
      "[200]\ttrain-mlogloss:0.517061\ttest-mlogloss:0.634277\n",
      "[300]\ttrain-mlogloss:0.445879\ttest-mlogloss:0.5974\n",
      "[400]\ttrain-mlogloss:0.403084\ttest-mlogloss:0.582142\n",
      "[500]\ttrain-mlogloss:0.372455\ttest-mlogloss:0.575137\n",
      "[600]\ttrain-mlogloss:0.347068\ttest-mlogloss:0.571548\n",
      "[700]\ttrain-mlogloss:0.325188\ttest-mlogloss:0.569743\n",
      "[800]\ttrain-mlogloss:0.305552\ttest-mlogloss:0.568794\n",
      "[900]\ttrain-mlogloss:0.287914\ttest-mlogloss:0.568456\n",
      "Stopping. Best iteration:\n",
      "[903]\ttrain-mlogloss:0.287394\ttest-mlogloss:0.568443\n",
      "\n",
      "[0.56848469827601211]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.09112\ttest-mlogloss:1.09191\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.671093\ttest-mlogloss:0.737431\n",
      "[200]\ttrain-mlogloss:0.520491\ttest-mlogloss:0.63245\n",
      "[300]\ttrain-mlogloss:0.449068\ttest-mlogloss:0.594276\n",
      "[400]\ttrain-mlogloss:0.407284\ttest-mlogloss:0.578716\n",
      "[500]\ttrain-mlogloss:0.375603\ttest-mlogloss:0.571054\n",
      "[600]\ttrain-mlogloss:0.349685\ttest-mlogloss:0.567045\n",
      "[700]\ttrain-mlogloss:0.328133\ttest-mlogloss:0.564876\n",
      "[800]\ttrain-mlogloss:0.309333\ttest-mlogloss:0.564005\n",
      "[900]\ttrain-mlogloss:0.292128\ttest-mlogloss:0.563469\n",
      "[1000]\ttrain-mlogloss:0.276322\ttest-mlogloss:0.563433\n",
      "Stopping. Best iteration:\n",
      "[984]\ttrain-mlogloss:0.278971\ttest-mlogloss:0.563296\n",
      "\n",
      "[0.56848469827601211, 0.56340762857159454]\n",
      "round: 54\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.787842\ttest-mlogloss:0.833042\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[13]\ttrain-mlogloss:0.325576\ttest-mlogloss:0.601442\n",
      "\n",
      "[0.62656743807239867]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.791281\ttest-mlogloss:0.830479\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-mlogloss:0.351685\ttest-mlogloss:0.593921\n",
      "\n",
      "[0.62656743807239867, 0.61511040866576361]\n",
      "round: 55\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 3, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06573\ttest-mlogloss:1.06728\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.480879\ttest-mlogloss:0.586298\n",
      "[200]\ttrain-mlogloss:0.402716\ttest-mlogloss:0.572069\n",
      "Stopping. Best iteration:\n",
      "[266]\ttrain-mlogloss:0.364531\ttest-mlogloss:0.570445\n",
      "\n",
      "[0.57070192894399829]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06574\ttest-mlogloss:1.06697\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.484997\ttest-mlogloss:0.580492\n",
      "[200]\ttrain-mlogloss:0.406064\ttest-mlogloss:0.565402\n",
      "Stopping. Best iteration:\n",
      "[270]\ttrain-mlogloss:0.366029\ttest-mlogloss:0.562503\n",
      "\n",
      "[0.57070192894399829, 0.56266239116572481]\n",
      "round: 56\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 2, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 6}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.03678\ttest-mlogloss:1.03834\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.450776\ttest-mlogloss:0.574444\n",
      "[200]\ttrain-mlogloss:0.365093\ttest-mlogloss:0.569149\n",
      "Stopping. Best iteration:\n",
      "[192]\ttrain-mlogloss:0.370774\ttest-mlogloss:0.569004\n",
      "\n",
      "[0.56907966903724516]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.03642\ttest-mlogloss:1.03817\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.455468\ttest-mlogloss:0.570454\n",
      "[200]\ttrain-mlogloss:0.372202\ttest-mlogloss:0.564647\n",
      "Stopping. Best iteration:\n",
      "[183]\ttrain-mlogloss:0.383579\ttest-mlogloss:0.564258\n",
      "\n",
      "[0.56907966903724516, 0.5646329666100256]\n",
      "round: 57\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 4}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:0.851665\ttest-mlogloss:0.856489\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[46]\ttrain-mlogloss:0.483197\ttest-mlogloss:0.585273\n",
      "\n",
      "[0.58616135053212537]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:0.85352\ttest-mlogloss:0.854202\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[51]\ttrain-mlogloss:0.480675\ttest-mlogloss:0.577265\n",
      "\n",
      "[0.58616135053212537, 0.57872095399376244]\n",
      "round: 58\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 1, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 3}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.04294\ttest-mlogloss:1.04344\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.569602\ttest-mlogloss:0.600165\n",
      "[200]\ttrain-mlogloss:0.530839\ttest-mlogloss:0.582412\n",
      "[300]\ttrain-mlogloss:0.504622\ttest-mlogloss:0.575243\n",
      "[400]\ttrain-mlogloss:0.483545\ttest-mlogloss:0.5725\n",
      "[500]\ttrain-mlogloss:0.465029\ttest-mlogloss:0.570281\n",
      "Stopping. Best iteration:\n",
      "[561]\ttrain-mlogloss:0.454864\ttest-mlogloss:0.569503\n",
      "\n",
      "[0.56960511643135681]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.04253\ttest-mlogloss:1.0427\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.575685\ttest-mlogloss:0.596505\n",
      "[200]\ttrain-mlogloss:0.537258\ttest-mlogloss:0.578498\n",
      "[300]\ttrain-mlogloss:0.511585\ttest-mlogloss:0.570986\n",
      "[400]\ttrain-mlogloss:0.491072\ttest-mlogloss:0.567311\n",
      "[500]\ttrain-mlogloss:0.472751\ttest-mlogloss:0.565506\n",
      "Stopping. Best iteration:\n",
      "[539]\ttrain-mlogloss:0.46612\ttest-mlogloss:0.564824\n",
      "\n",
      "[0.56960511643135681, 0.56490317265832679]\n",
      "round: 59\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 0, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.06763\ttest-mlogloss:1.06824\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.550006\ttest-mlogloss:0.599954\n",
      "[200]\ttrain-mlogloss:0.490728\ttest-mlogloss:0.577937\n",
      "[300]\ttrain-mlogloss:0.451093\ttest-mlogloss:0.570329\n",
      "[400]\ttrain-mlogloss:0.417931\ttest-mlogloss:0.56788\n",
      "[500]\ttrain-mlogloss:0.390577\ttest-mlogloss:0.566773\n",
      "Stopping. Best iteration:\n",
      "[488]\ttrain-mlogloss:0.393495\ttest-mlogloss:0.566656\n",
      "\n",
      "[0.56673880888998085]\n",
      "Fold: 1\n",
      "[0]\ttrain-mlogloss:1.06777\ttest-mlogloss:1.06812\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.554147\ttest-mlogloss:0.595496\n",
      "[200]\ttrain-mlogloss:0.494614\ttest-mlogloss:0.573253\n",
      "[300]\ttrain-mlogloss:0.455003\ttest-mlogloss:0.56545\n",
      "[400]\ttrain-mlogloss:0.423978\ttest-mlogloss:0.561775\n",
      "[500]\ttrain-mlogloss:0.395313\ttest-mlogloss:0.560118\n",
      "Stopping. Best iteration:\n",
      "[507]\ttrain-mlogloss:0.393553\ttest-mlogloss:0.560076\n",
      "\n",
      "[0.56673880888998085, 0.5601859643775623]\n",
      "round: 60\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 2, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 9}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.09126\ttest-mlogloss:1.092\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.679425\ttest-mlogloss:0.740454\n",
      "[200]\ttrain-mlogloss:0.533615\ttest-mlogloss:0.636609\n",
      "[300]\ttrain-mlogloss:0.464471\ttest-mlogloss:0.598998\n",
      "[400]\ttrain-mlogloss:0.421478\ttest-mlogloss:0.583607\n",
      "[500]\ttrain-mlogloss:0.390285\ttest-mlogloss:0.576124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4814462ee27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Xbgoost parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mval_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ce13a094d31d>\u001b[0m in \u001b[0;36mrunXGB\u001b[0;34m(param, train_X, train_y, test_X, test_y, feature_names, num_rounds)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "training_result = {}\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    print 'round: %s' % i\n",
    "    param = {}\n",
    "    # fixed parems\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['seed'] = 0\n",
    "    param['silent'] = 1 \n",
    "    param['num_class'] = 3\n",
    "    \n",
    "    # random\n",
    "    param['eta'] = np.random.choice([0.01, 0.05, 0.1, 0.5, 1], 1)[0]    #[0,1]\n",
    "    param['max_depth'] = np.random.choice([2,3,4,5,6,7,8,9,10], 1)[0]                       #[1,]\n",
    "    param['min_child_weight'] = np.random.choice([0,1,2,3,4,5], 1)[0]                    #[0,]\n",
    "    param['subsample'] = np.random.choice([0.4,0.5,0.6,0.7,0.8], 1)[0]                 #(0,1]\n",
    "    param['colsample_bytree'] = np.random.choice([0.4,0.5,0.6,0.7,0.8], 1)[0]          #(0,1]\n",
    "\n",
    "    \n",
    "    print 'params: %s' % param\n",
    "    #init result for this round\n",
    "    training_result[i] = {}\n",
    "    training_result[i]['param'] = param\n",
    "    \n",
    "    cv_scores = []\n",
    "    kf = model_selection.KFold(n_splits=2, shuffle=True, random_state=2016)\n",
    "    fold = 0 \n",
    "    for dev_index, val_index in kf.split(range(train_x.shape[0])):\n",
    "            print \"Fold: %s\" % fold\n",
    "            dev_x, val_x = train_x[dev_index,:], train_x[val_index,:]\n",
    "            dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "            # Xbgoost parameter \n",
    "            val_y_pred, model = runXGB(param, dev_x, dev_y, val_x, val_y)\n",
    "            cv_scores.append(log_loss(val_y, val_y_pred))\n",
    "\n",
    "            print(cv_scores)\n",
    "            fold += 1\n",
    "    \n",
    "    training_result[i]['cv_scores'] = cv_scores\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'cv_scores': [0.58891432777555008,\n",
       "   0.59059962393845011,\n",
       "   0.59504002662790501,\n",
       "   0.57816091002066994,\n",
       "   0.5870666042403766],\n",
       "  'param': {'colsample_bytree': 0.80000000000000004,\n",
       "   'eta': 0.5,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.5}},\n",
       " 1: {'cv_scores': [0.59185194983836598,\n",
       "   0.61654965019753549,\n",
       "   0.60507615376509849,\n",
       "   0.5925758511877478,\n",
       "   0.58725648113202444],\n",
       "  'param': {'colsample_bytree': 0.5,\n",
       "   'eta': 0.5,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 0,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.59999999999999998}},\n",
       " 2: {'cv_scores': [0.56162437424026679,\n",
       "   0.5663586329296797,\n",
       "   0.56865498546715931,\n",
       "   0.55313734497072098,\n",
       "   0.55607142226158446],\n",
       "  'param': {'colsample_bytree': 0.59999999999999998,\n",
       "   'eta': 0.10000000000000001,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 0,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.59999999999999998}},\n",
       " 3: {'cv_scores': [0.56911250190929208,\n",
       "   0.5724484096132022,\n",
       "   0.57618323667899496,\n",
       "   0.56044322142898451,\n",
       "   0.56574364038459579],\n",
       "  'param': {'colsample_bytree': 0.69999999999999996,\n",
       "   'eta': 0.5,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 2,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.80000000000000004}},\n",
       " 4: {'cv_scores': [0.56103465433952626,\n",
       "   0.56707318681116092,\n",
       "   0.56806043684898011,\n",
       "   0.55330758739587826,\n",
       "   0.55505291406199608],\n",
       "  'param': {'colsample_bytree': 0.59999999999999998,\n",
       "   'eta': 0.10000000000000001,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.59999999999999998}},\n",
       " 5: {'cv_scores': [0.55963006193121934,\n",
       "   0.56306998763962768,\n",
       "   0.5644037809950444,\n",
       "   0.5487925603824374,\n",
       "   0.55467064015507239],\n",
       "  'param': {'colsample_bytree': 0.59999999999999998,\n",
       "   'eta': 0.050000000000000003,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 2,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.69999999999999996}},\n",
       " 6: {'cv_scores': [0.56318622389693129,\n",
       "   0.56746949385480916,\n",
       "   0.56931993411052595,\n",
       "   0.55376250844926589,\n",
       "   0.55615076971227961],\n",
       "  'param': {'colsample_bytree': 0.5,\n",
       "   'eta': 0.10000000000000001,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 0,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.80000000000000004}},\n",
       " 7: {'cv_scores': [0.57269626468768886,\n",
       "   0.57366817315972773,\n",
       "   0.5742847497546526,\n",
       "   0.56202846492471037,\n",
       "   0.56887160555429395],\n",
       "  'param': {'colsample_bytree': 0.5,\n",
       "   'eta': 0.5,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.80000000000000004}},\n",
       " 8: {'cv_scores': [0.56196417734499293,\n",
       "   0.56449077972221584,\n",
       "   0.56691100035528719,\n",
       "   0.55270689365494463,\n",
       "   0.5569741436143304],\n",
       "  'param': {'colsample_bytree': 0.59999999999999998,\n",
       "   'eta': 0.10000000000000001,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 2,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.69999999999999996}},\n",
       " 9: {'cv_scores': [0.56079236966583723,\n",
       "   0.56503852413863498,\n",
       "   0.56586663994197106,\n",
       "   0.55030982316069699,\n",
       "   0.55480083337565711],\n",
       "  'param': {'colsample_bytree': 0.69999999999999996,\n",
       "   'eta': 0.050000000000000003,\n",
       "   'eval_metric': 'mlogloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 0,\n",
       "   'num_class': 3,\n",
       "   'objective': 'multi:softprob',\n",
       "   'seed': 0,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.5}}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mixed_model(training_result, train_x, train_y, target_x, num_rounds=500):\n",
    "    mix_model_df = pd.DataFrame()\n",
    "    for i in xrange(10):\n",
    "        print 'round: %s' % i\n",
    "        preds, model = runXGB(training_result[i]['param'], train_x, train_y, target_x, num_rounds=500)\n",
    "        preds_df = pd.DataFrame(preds, columns=['pred_high_%s' % i, 'pred_medium_%s' % i, 'pred_low_%s' % i])\n",
    "\n",
    "        if i == 0:\n",
    "            mix_model_df = preds_df\n",
    "        else:\n",
    "            mix_model_df = pd.concat([mix_model_df, preds_df], axis = 1)\n",
    "        print 'dataframe: {0}'.format(mix_model_df.shape)  \n",
    "        \n",
    "    return mix_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 0\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 5, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 4}\n",
      "dataframe: (49352, 3)\n",
      "round: 1\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 6}\n",
      "dataframe: (49352, 6)\n",
      "round: 2\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 2, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 6}\n",
      "dataframe: (49352, 9)\n",
      "round: 3\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 4, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 6}\n",
      "dataframe: (49352, 12)\n",
      "round: 4\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 3, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 7}\n",
      "dataframe: (49352, 15)\n",
      "round: 5\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 9}\n",
      "dataframe: (49352, 18)\n",
      "round: 6\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 1, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 7}\n",
      "dataframe: (49352, 21)\n",
      "round: 7\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 1, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 4}\n",
      "dataframe: (49352, 24)\n",
      "round: 8\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 0, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 4}\n",
      "dataframe: (49352, 27)\n",
      "round: 9\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 5, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 9}\n",
      "dataframe: (49352, 30)\n"
     ]
    }
   ],
   "source": [
    "# get preds by each model\n",
    "mix_model_df = pd.DataFrame()\n",
    "for i in xrange(10):\n",
    "    print 'round: %s' % i\n",
    "    param = {}\n",
    "    # fixed parems\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['seed'] = 0\n",
    "    param['silent'] = 1 \n",
    "    param['num_class'] = 3\n",
    "    \n",
    "    # random\n",
    "    param['eta'] = np.random.choice([0.01, 0.05, 0.1, 0.5, 1], 1)[0]    #[0,1]\n",
    "    param['max_depth'] = np.random.choice([2,3,4,5,6,7,8,9,10], 1)[0]                       #[1,]\n",
    "    param['min_child_weight'] = np.random.choice([0,1,2,3,4,5], 1)[0]                    #[0,]\n",
    "    param['subsample'] = np.random.choice([0.4,0.5,0.6,0.7,0.8], 1)[0]                 #(0,1]\n",
    "    param['colsample_bytree'] = np.random.choice([0.4,0.5,0.6,0.7,0.8], 1)[0]          #(0,1]\n",
    "    print 'parma: %s' % param\n",
    "    preds, model = runXGB(param, train_x, train_y, train_x, num_rounds=2000)\n",
    "    preds_df = pd.DataFrame(preds, columns=['pred_high_%s' % i, 'pred_medium_%s' % i, 'pred_low_%s' % i])\n",
    "    \n",
    "    if i == 0:\n",
    "        mix_model_df = preds_df\n",
    "    else:\n",
    "        mix_model_df = pd.concat([mix_model_df, preds_df], axis = 1)\n",
    "\n",
    "    print 'dataframe: {0}'.format(mix_model_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensenble modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mix_model = sparse.csr_matrix(mix_model_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 0\n",
      "params: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 0, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 7}\n",
      "Fold: 0\n",
      "[0]\ttrain-mlogloss:1.08378\ttest-mlogloss:1.0838\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[100]\ttrain-mlogloss:0.332147\ttest-mlogloss:0.33278\n",
      "[200]\ttrain-mlogloss:0.116574\ttest-mlogloss:0.117731\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-f7ed10e7e54a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Xbgoost parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mval_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-24ccbf6eff64>\u001b[0m in \u001b[0;36mrunXGB\u001b[0;34m(param, train_X, train_y, test_X, test_y, feature_names, num_rounds)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ensenble_training_result = {}\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    print 'round: %s' % i\n",
    "    param = {}\n",
    "    # fixed parems\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['seed'] = 0\n",
    "    param['silent'] = 1 \n",
    "    param['num_class'] = 3\n",
    "    \n",
    "    # random\n",
    "    param['eta'] = np.random.choice([0.01, 0.05, 0.1, 0.5], 1)[0]    #[0,1]\n",
    "    param['max_depth'] = np.random.choice([4,5,6,7,8], 1)[0]                       #[1,]\n",
    "    param['min_child_weight'] = np.random.choice([0,1,2], 1)[0]                    #[0,]\n",
    "    param['subsample'] = np.random.choice([0.5,0.6,0.7,0.8], 1)[0]                 #(0,1]\n",
    "    param['colsample_bytree'] = np.random.choice([0.5,0.6,0.7,0.8], 1)[0]          #(0,1]\n",
    "\n",
    "    \n",
    "    print 'params: %s' % param\n",
    "    #init result for this round\n",
    "    ensenble_training_result[i] = {}\n",
    "    ensenble_training_result[i]['param'] = param\n",
    "    \n",
    "    cv_scores = []\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "    fold = 0 \n",
    "    for dev_index, val_index in kf.split(range(train_x.shape[0])):\n",
    "            print \"Fold: %s\" % fold\n",
    "            dev_x, val_x = train_mix_model[dev_index,:], train_mix_model[val_index,:]\n",
    "            dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "            # Xbgoost parameter \n",
    "            val_y_pred, model = runXGB(param, dev_x, dev_y, val_x, val_y)\n",
    "            cv_scores.append(log_loss(val_y, val_y_pred))\n",
    "\n",
    "            print(cv_scores)\n",
    "            fold += 1\n",
    "    \n",
    "    ensenble_training_result[i]['cv_scores'] = cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submit_data(param, train_x, train_y, test_df, num_rounds=500):\n",
    "    print 'param: {0}'.format(param)\n",
    "    test_x = feature_preprocessing(test_df, False)\n",
    "    preds, model = runXGB(param, train_x, train_y, test_x, num_rounds=num_rounds)\n",
    "    out_df = pd.DataFrame(preds)\n",
    "    out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "    out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "    out_df = out_df[[\"listing_id\",\"high\", \"medium\", \"low\" ]]\n",
    "    print 'shape: {0}'.format(out_df.shape)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.1, 'min_child_weight': 0, 'subsample': 0.7, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.7, 'max_depth': 6}\n",
      "                 quadkey_15_bathrooms  quadkey_15_bedrooms  quadkey_15_price\n",
      "quadkey_15                                                                  \n",
      "021333333001101                   1.0                  0.0            2200.0\n",
      "023010211023323                   1.0                  2.0            3200.0\n",
      "023012311310010                   1.0                  1.0            2425.0\n",
      "023101012323320                   1.0                  2.0            2150.0\n",
      "023130121200020                   3.0                  3.0             500.0\n",
      "tr_sparse(74659, 100)\n",
      "tr_sparse_desc(74659, 100)\n",
      "cloumns: Index([                u'bathrooms',                  u'bedrooms',\n",
      "                        u'latitude',                 u'longitude',\n",
      "                           u'price',                u'diff_price',\n",
      "                  u'diff_bathrooms',             u'diff_bedrooms',\n",
      "                     u'ratio_price',            u'building_price',\n",
      "              u'building_bathrooms',         u'building_bedrooms',\n",
      "              u'diff_mean_of_price',     u'diff_mean_of_bedrooms',\n",
      "          u'diff_mean_of_bathrooms', u'diff_bathrooms_quadkey_15',\n",
      "        u'diff_bedrooms_quadkey_15',     u'diff_price_quadkey_15',\n",
      "          u'ratio_price_quadkey_15', u'diff_bathrooms_quadkey_13',\n",
      "        u'diff_bedrooms_quadkey_13',     u'diff_price_quadkey_13',\n",
      "          u'ratio_price_quadkey_13',             u'price_per_bed',\n",
      "                  u'price_per_bath',            u'price_per_room',\n",
      "         u'building_price_per_room',      u'diff_price_per_rooms',\n",
      "                      u'total_room',                 u'diff_room',\n",
      "                      u'ratio_room',              u'created_year',\n",
      "                   u'created_month',               u'created_day',\n",
      "                    u'created_hour',              u'features_cnt',\n",
      "                      u'photos_cnt',                  u'desc_cnt'],\n",
      "      dtype='object')\n",
      "train_x: (74659, 4089)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874', 'f875', 'f876', 'f877', 'f878', 'f879', 'f880', 'f881', 'f882', 'f883', 'f884', 'f885', 'f886', 'f887', 'f888', 'f889', 'f890', 'f891', 'f892', 'f893', 'f894', 'f895', 'f896', 'f897', 'f898', 'f899', 'f900', 'f901', 'f902', 'f903', 'f904', 'f905', 'f906', 'f907', 'f908', 'f909', 'f910', 'f911', 'f912', 'f913', 'f914', 'f915', 'f916', 'f917', 'f918', 'f919', 'f920', 'f921', 'f922', 'f923', 'f924', 'f925', 'f926', 'f927', 'f928', 'f929', 'f930', 'f931', 'f932', 'f933', 'f934', 'f935', 'f936', 'f937', 'f938', 'f939', 'f940', 'f941', 'f942', 'f943', 'f944', 'f945', 'f946', 'f947', 'f948', 'f949', 'f950', 'f951', 'f952', 'f953', 'f954', 'f955', 'f956', 'f957', 'f958', 'f959', 'f960', 'f961', 'f962', 'f963', 'f964', 'f965', 'f966', 'f967', 'f968', 'f969', 'f970', 'f971', 'f972', 'f973', 'f974', 'f975', 'f976', 'f977', 'f978', 'f979', 'f980', 'f981', 'f982', 'f983', 'f984', 'f985', 'f986', 'f987', 'f988', 'f989', 'f990', 'f991', 'f992', 'f993', 'f994', 'f995', 'f996', 'f997', 'f998', 'f999', 'f1000', 'f1001', 'f1002', 'f1003', 'f1004', 'f1005', 'f1006', 'f1007', 'f1008', 'f1009', 'f1010', 'f1011', 'f1012', 'f1013', 'f1014', 'f1015', 'f1016', 'f1017', 'f1018', 'f1019', 'f1020', 'f1021', 'f1022', 'f1023', 'f1024', 'f1025', 'f1026', 'f1027', 'f1028', 'f1029', 'f1030', 'f1031', 'f1032', 'f1033', 'f1034', 'f1035', 'f1036', 'f1037', 'f1038', 'f1039', 'f1040', 'f1041', 'f1042', 'f1043', 'f1044', 'f1045', 'f1046', 'f1047', 'f1048', 'f1049', 'f1050', 'f1051', 'f1052', 'f1053', 'f1054', 'f1055', 'f1056', 'f1057', 'f1058', 'f1059', 'f1060', 'f1061', 'f1062', 'f1063', 'f1064', 'f1065', 'f1066', 'f1067', 'f1068', 'f1069', 'f1070', 'f1071', 'f1072', 'f1073', 'f1074', 'f1075', 'f1076', 'f1077', 'f1078', 'f1079', 'f1080', 'f1081', 'f1082', 'f1083', 'f1084', 'f1085', 'f1086', 'f1087', 'f1088', 'f1089', 'f1090', 'f1091', 'f1092', 'f1093', 'f1094', 'f1095', 'f1096', 'f1097', 'f1098', 'f1099', 'f1100', 'f1101', 'f1102', 'f1103', 'f1104', 'f1105', 'f1106', 'f1107', 'f1108', 'f1109', 'f1110', 'f1111', 'f1112', 'f1113', 'f1114', 'f1115', 'f1116', 'f1117', 'f1118', 'f1119', 'f1120', 'f1121', 'f1122', 'f1123', 'f1124', 'f1125', 'f1126', 'f1127', 'f1128', 'f1129', 'f1130', 'f1131', 'f1132', 'f1133', 'f1134', 'f1135', 'f1136', 'f1137', 'f1138', 'f1139', 'f1140', 'f1141', 'f1142', 'f1143', 'f1144', 'f1145', 'f1146', 'f1147', 'f1148', 'f1149', 'f1150', 'f1151', 'f1152', 'f1153', 'f1154', 'f1155', 'f1156', 'f1157', 'f1158', 'f1159', 'f1160', 'f1161', 'f1162', 'f1163', 'f1164', 'f1165', 'f1166', 'f1167', 'f1168', 'f1169', 'f1170', 'f1171', 'f1172', 'f1173', 'f1174', 'f1175', 'f1176', 'f1177', 'f1178', 'f1179', 'f1180', 'f1181', 'f1182', 'f1183', 'f1184', 'f1185', 'f1186', 'f1187', 'f1188', 'f1189', 'f1190', 'f1191', 'f1192', 'f1193', 'f1194', 'f1195', 'f1196', 'f1197', 'f1198', 'f1199', 'f1200', 'f1201', 'f1202', 'f1203', 'f1204', 'f1205', 'f1206', 'f1207', 'f1208', 'f1209', 'f1210', 'f1211', 'f1212', 'f1213', 'f1214', 'f1215', 'f1216', 'f1217', 'f1218', 'f1219', 'f1220', 'f1221', 'f1222', 'f1223', 'f1224', 'f1225', 'f1226', 'f1227', 'f1228', 'f1229', 'f1230', 'f1231', 'f1232', 'f1233', 'f1234', 'f1235', 'f1236', 'f1237', 'f1238', 'f1239', 'f1240', 'f1241', 'f1242', 'f1243', 'f1244', 'f1245', 'f1246', 'f1247', 'f1248', 'f1249', 'f1250', 'f1251', 'f1252', 'f1253', 'f1254', 'f1255', 'f1256', 'f1257', 'f1258', 'f1259', 'f1260', 'f1261', 'f1262', 'f1263', 'f1264', 'f1265', 'f1266', 'f1267', 'f1268', 'f1269', 'f1270', 'f1271', 'f1272', 'f1273', 'f1274', 'f1275', 'f1276', 'f1277', 'f1278', 'f1279', 'f1280', 'f1281', 'f1282', 'f1283', 'f1284', 'f1285', 'f1286', 'f1287', 'f1288', 'f1289', 'f1290', 'f1291', 'f1292', 'f1293', 'f1294', 'f1295', 'f1296', 'f1297', 'f1298', 'f1299', 'f1300', 'f1301', 'f1302', 'f1303', 'f1304', 'f1305', 'f1306', 'f1307', 'f1308', 'f1309', 'f1310', 'f1311', 'f1312', 'f1313', 'f1314', 'f1315', 'f1316', 'f1317', 'f1318', 'f1319', 'f1320', 'f1321', 'f1322', 'f1323', 'f1324', 'f1325', 'f1326', 'f1327', 'f1328', 'f1329', 'f1330', 'f1331', 'f1332', 'f1333', 'f1334', 'f1335', 'f1336', 'f1337', 'f1338', 'f1339', 'f1340', 'f1341', 'f1342', 'f1343', 'f1344', 'f1345', 'f1346', 'f1347', 'f1348', 'f1349', 'f1350', 'f1351', 'f1352', 'f1353', 'f1354', 'f1355', 'f1356', 'f1357', 'f1358', 'f1359', 'f1360', 'f1361', 'f1362', 'f1363', 'f1364', 'f1365', 'f1366', 'f1367', 'f1368', 'f1369', 'f1370', 'f1371', 'f1372', 'f1373', 'f1374', 'f1375', 'f1376', 'f1377', 'f1378', 'f1379', 'f1380', 'f1381', 'f1382', 'f1383', 'f1384', 'f1385', 'f1386', 'f1387', 'f1388', 'f1389', 'f1390', 'f1391', 'f1392', 'f1393', 'f1394', 'f1395', 'f1396', 'f1397', 'f1398', 'f1399', 'f1400', 'f1401', 'f1402', 'f1403', 'f1404', 'f1405', 'f1406', 'f1407', 'f1408', 'f1409', 'f1410', 'f1411', 'f1412', 'f1413', 'f1414', 'f1415', 'f1416', 'f1417', 'f1418', 'f1419', 'f1420', 'f1421', 'f1422', 'f1423', 'f1424', 'f1425', 'f1426', 'f1427', 'f1428', 'f1429', 'f1430', 'f1431', 'f1432', 'f1433', 'f1434', 'f1435', 'f1436', 'f1437', 'f1438', 'f1439', 'f1440', 'f1441', 'f1442', 'f1443', 'f1444', 'f1445', 'f1446', 'f1447', 'f1448', 'f1449', 'f1450', 'f1451', 'f1452', 'f1453', 'f1454', 'f1455', 'f1456', 'f1457', 'f1458', 'f1459', 'f1460', 'f1461', 'f1462', 'f1463', 'f1464', 'f1465', 'f1466', 'f1467', 'f1468', 'f1469', 'f1470', 'f1471', 'f1472', 'f1473', 'f1474', 'f1475', 'f1476', 'f1477', 'f1478', 'f1479', 'f1480', 'f1481', 'f1482', 'f1483', 'f1484', 'f1485', 'f1486', 'f1487', 'f1488', 'f1489', 'f1490', 'f1491', 'f1492', 'f1493', 'f1494', 'f1495', 'f1496', 'f1497', 'f1498', 'f1499', 'f1500', 'f1501', 'f1502', 'f1503', 'f1504', 'f1505', 'f1506', 'f1507', 'f1508', 'f1509', 'f1510', 'f1511', 'f1512', 'f1513', 'f1514', 'f1515', 'f1516', 'f1517', 'f1518', 'f1519', 'f1520', 'f1521', 'f1522', 'f1523', 'f1524', 'f1525', 'f1526', 'f1527', 'f1528', 'f1529', 'f1530', 'f1531', 'f1532', 'f1533', 'f1534', 'f1535', 'f1536', 'f1537', 'f1538', 'f1539', 'f1540', 'f1541', 'f1542', 'f1543', 'f1544', 'f1545', 'f1546', 'f1547', 'f1548', 'f1549', 'f1550', 'f1551', 'f1552', 'f1553', 'f1554', 'f1555', 'f1556', 'f1557', 'f1558', 'f1559', 'f1560', 'f1561', 'f1562', 'f1563', 'f1564', 'f1565', 'f1566', 'f1567', 'f1568', 'f1569', 'f1570', 'f1571', 'f1572', 'f1573', 'f1574', 'f1575', 'f1576', 'f1577', 'f1578', 'f1579', 'f1580', 'f1581', 'f1582', 'f1583', 'f1584', 'f1585', 'f1586', 'f1587', 'f1588', 'f1589', 'f1590', 'f1591', 'f1592', 'f1593', 'f1594', 'f1595', 'f1596', 'f1597', 'f1598', 'f1599', 'f1600', 'f1601', 'f1602', 'f1603', 'f1604', 'f1605', 'f1606', 'f1607', 'f1608', 'f1609', 'f1610', 'f1611', 'f1612', 'f1613', 'f1614', 'f1615', 'f1616', 'f1617', 'f1618', 'f1619', 'f1620', 'f1621', 'f1622', 'f1623', 'f1624', 'f1625', 'f1626', 'f1627', 'f1628', 'f1629', 'f1630', 'f1631', 'f1632', 'f1633', 'f1634', 'f1635', 'f1636', 'f1637', 'f1638', 'f1639', 'f1640', 'f1641', 'f1642', 'f1643', 'f1644', 'f1645', 'f1646', 'f1647', 'f1648', 'f1649', 'f1650', 'f1651', 'f1652', 'f1653', 'f1654', 'f1655', 'f1656', 'f1657', 'f1658', 'f1659', 'f1660', 'f1661', 'f1662', 'f1663', 'f1664', 'f1665', 'f1666', 'f1667', 'f1668', 'f1669', 'f1670', 'f1671', 'f1672', 'f1673', 'f1674', 'f1675', 'f1676', 'f1677', 'f1678', 'f1679', 'f1680', 'f1681', 'f1682', 'f1683', 'f1684', 'f1685', 'f1686', 'f1687', 'f1688', 'f1689', 'f1690', 'f1691', 'f1692', 'f1693', 'f1694', 'f1695', 'f1696', 'f1697', 'f1698', 'f1699', 'f1700', 'f1701', 'f1702', 'f1703', 'f1704', 'f1705', 'f1706', 'f1707', 'f1708', 'f1709', 'f1710', 'f1711', 'f1712', 'f1713', 'f1714', 'f1715', 'f1716', 'f1717', 'f1718', 'f1719', 'f1720', 'f1721', 'f1722', 'f1723', 'f1724', 'f1725', 'f1726', 'f1727', 'f1728', 'f1729', 'f1730', 'f1731', 'f1732', 'f1733', 'f1734', 'f1735', 'f1736', 'f1737', 'f1738', 'f1739', 'f1740', 'f1741', 'f1742', 'f1743', 'f1744', 'f1745', 'f1746', 'f1747', 'f1748', 'f1749', 'f1750', 'f1751', 'f1752', 'f1753', 'f1754', 'f1755', 'f1756', 'f1757', 'f1758', 'f1759', 'f1760', 'f1761', 'f1762', 'f1763', 'f1764', 'f1765', 'f1766', 'f1767', 'f1768', 'f1769', 'f1770', 'f1771', 'f1772', 'f1773', 'f1774', 'f1775', 'f1776', 'f1777', 'f1778', 'f1779', 'f1780', 'f1781', 'f1782', 'f1783', 'f1784', 'f1785', 'f1786', 'f1787', 'f1788', 'f1789', 'f1790', 'f1791', 'f1792', 'f1793', 'f1794', 'f1795', 'f1796', 'f1797', 'f1798', 'f1799', 'f1800', 'f1801', 'f1802', 'f1803', 'f1804', 'f1805', 'f1806', 'f1807', 'f1808', 'f1809', 'f1810', 'f1811', 'f1812', 'f1813', 'f1814', 'f1815', 'f1816', 'f1817', 'f1818', 'f1819', 'f1820', 'f1821', 'f1822', 'f1823', 'f1824', 'f1825', 'f1826', 'f1827', 'f1828', 'f1829', 'f1830', 'f1831', 'f1832', 'f1833', 'f1834', 'f1835', 'f1836', 'f1837', 'f1838', 'f1839', 'f1840', 'f1841', 'f1842', 'f1843', 'f1844', 'f1845', 'f1846', 'f1847', 'f1848', 'f1849', 'f1850', 'f1851', 'f1852', 'f1853', 'f1854', 'f1855', 'f1856', 'f1857', 'f1858', 'f1859', 'f1860', 'f1861', 'f1862', 'f1863', 'f1864', 'f1865', 'f1866', 'f1867', 'f1868', 'f1869', 'f1870', 'f1871', 'f1872', 'f1873', 'f1874', 'f1875', 'f1876', 'f1877', 'f1878', 'f1879', 'f1880', 'f1881', 'f1882', 'f1883', 'f1884', 'f1885', 'f1886', 'f1887', 'f1888', 'f1889', 'f1890', 'f1891', 'f1892', 'f1893', 'f1894', 'f1895', 'f1896', 'f1897', 'f1898', 'f1899', 'f1900', 'f1901', 'f1902', 'f1903', 'f1904', 'f1905', 'f1906', 'f1907', 'f1908', 'f1909', 'f1910', 'f1911', 'f1912', 'f1913', 'f1914', 'f1915', 'f1916', 'f1917', 'f1918', 'f1919', 'f1920', 'f1921', 'f1922', 'f1923', 'f1924', 'f1925', 'f1926', 'f1927', 'f1928', 'f1929', 'f1930', 'f1931', 'f1932', 'f1933', 'f1934', 'f1935', 'f1936', 'f1937', 'f1938', 'f1939', 'f1940', 'f1941', 'f1942', 'f1943', 'f1944', 'f1945', 'f1946', 'f1947', 'f1948', 'f1949', 'f1950', 'f1951', 'f1952', 'f1953', 'f1954', 'f1955', 'f1956', 'f1957', 'f1958', 'f1959', 'f1960', 'f1961', 'f1962', 'f1963', 'f1964', 'f1965', 'f1966', 'f1967', 'f1968', 'f1969', 'f1970', 'f1971', 'f1972', 'f1973', 'f1974', 'f1975', 'f1976', 'f1977', 'f1978', 'f1979', 'f1980', 'f1981', 'f1982', 'f1983', 'f1984', 'f1985', 'f1986', 'f1987', 'f1988', 'f1989', 'f1990', 'f1991', 'f1992', 'f1993', 'f1994', 'f1995', 'f1996', 'f1997', 'f1998', 'f1999', 'f2000', 'f2001', 'f2002', 'f2003', 'f2004', 'f2005', 'f2006', 'f2007', 'f2008', 'f2009', 'f2010', 'f2011', 'f2012', 'f2013', 'f2014', 'f2015', 'f2016', 'f2017', 'f2018', 'f2019', 'f2020', 'f2021', 'f2022', 'f2023', 'f2024', 'f2025', 'f2026', 'f2027', 'f2028', 'f2029', 'f2030', 'f2031', 'f2032', 'f2033', 'f2034', 'f2035', 'f2036', 'f2037', 'f2038', 'f2039', 'f2040', 'f2041', 'f2042', 'f2043', 'f2044', 'f2045', 'f2046', 'f2047', 'f2048', 'f2049', 'f2050', 'f2051', 'f2052', 'f2053', 'f2054', 'f2055', 'f2056', 'f2057', 'f2058', 'f2059', 'f2060', 'f2061', 'f2062', 'f2063', 'f2064', 'f2065', 'f2066', 'f2067', 'f2068', 'f2069', 'f2070', 'f2071', 'f2072', 'f2073', 'f2074', 'f2075', 'f2076', 'f2077', 'f2078', 'f2079', 'f2080', 'f2081', 'f2082', 'f2083', 'f2084', 'f2085', 'f2086', 'f2087', 'f2088', 'f2089', 'f2090', 'f2091', 'f2092', 'f2093', 'f2094', 'f2095', 'f2096', 'f2097', 'f2098', 'f2099', 'f2100', 'f2101', 'f2102', 'f2103', 'f2104', 'f2105', 'f2106', 'f2107', 'f2108', 'f2109', 'f2110', 'f2111', 'f2112', 'f2113', 'f2114', 'f2115', 'f2116', 'f2117', 'f2118', 'f2119', 'f2120', 'f2121', 'f2122', 'f2123', 'f2124', 'f2125', 'f2126', 'f2127', 'f2128', 'f2129', 'f2130', 'f2131', 'f2132', 'f2133', 'f2134', 'f2135', 'f2136', 'f2137', 'f2138', 'f2139', 'f2140', 'f2141', 'f2142', 'f2143', 'f2144', 'f2145', 'f2146', 'f2147', 'f2148', 'f2149', 'f2150', 'f2151', 'f2152', 'f2153', 'f2154', 'f2155', 'f2156', 'f2157', 'f2158', 'f2159', 'f2160', 'f2161', 'f2162', 'f2163', 'f2164', 'f2165', 'f2166', 'f2167', 'f2168', 'f2169', 'f2170', 'f2171', 'f2172', 'f2173', 'f2174', 'f2175', 'f2176', 'f2177', 'f2178', 'f2179', 'f2180', 'f2181', 'f2182', 'f2183', 'f2184', 'f2185', 'f2186', 'f2187', 'f2188', 'f2189', 'f2190', 'f2191', 'f2192', 'f2193', 'f2194', 'f2195', 'f2196', 'f2197', 'f2198', 'f2199', 'f2200', 'f2201', 'f2202', 'f2203', 'f2204', 'f2205', 'f2206', 'f2207', 'f2208', 'f2209', 'f2210', 'f2211', 'f2212', 'f2213', 'f2214', 'f2215', 'f2216', 'f2217', 'f2218', 'f2219', 'f2220', 'f2221', 'f2222', 'f2223', 'f2224', 'f2225', 'f2226', 'f2227', 'f2228', 'f2229', 'f2230', 'f2231', 'f2232', 'f2233', 'f2234', 'f2235', 'f2236', 'f2237', 'f2238', 'f2239', 'f2240', 'f2241', 'f2242', 'f2243', 'f2244', 'f2245', 'f2246', 'f2247', 'f2248', 'f2249', 'f2250', 'f2251', 'f2252', 'f2253', 'f2254', 'f2255', 'f2256', 'f2257', 'f2258', 'f2259', 'f2260', 'f2261', 'f2262', 'f2263', 'f2264', 'f2265', 'f2266', 'f2267', 'f2268', 'f2269', 'f2270', 'f2271', 'f2272', 'f2273', 'f2274', 'f2275', 'f2276', 'f2277', 'f2278', 'f2279', 'f2280', 'f2281', 'f2282', 'f2283', 'f2284', 'f2285', 'f2286', 'f2287', 'f2288', 'f2289', 'f2290', 'f2291', 'f2292', 'f2293', 'f2294', 'f2295', 'f2296', 'f2297', 'f2298', 'f2299', 'f2300', 'f2301', 'f2302', 'f2303', 'f2304', 'f2305', 'f2306', 'f2307', 'f2308', 'f2309', 'f2310', 'f2311', 'f2312', 'f2313', 'f2314', 'f2315', 'f2316', 'f2317', 'f2318', 'f2319', 'f2320', 'f2321', 'f2322', 'f2323', 'f2324', 'f2325', 'f2326', 'f2327', 'f2328', 'f2329', 'f2330', 'f2331', 'f2332', 'f2333', 'f2334', 'f2335', 'f2336', 'f2337', 'f2338', 'f2339', 'f2340', 'f2341', 'f2342', 'f2343', 'f2344', 'f2345', 'f2346', 'f2347', 'f2348', 'f2349', 'f2350', 'f2351', 'f2352', 'f2353', 'f2354', 'f2355', 'f2356', 'f2357', 'f2358', 'f2359', 'f2360', 'f2361', 'f2362', 'f2363', 'f2364', 'f2365', 'f2366', 'f2367', 'f2368', 'f2369', 'f2370', 'f2371', 'f2372', 'f2373', 'f2374', 'f2375', 'f2376', 'f2377', 'f2378', 'f2379', 'f2380', 'f2381', 'f2382', 'f2383', 'f2384', 'f2385', 'f2386', 'f2387', 'f2388', 'f2389', 'f2390', 'f2391', 'f2392', 'f2393', 'f2394', 'f2395', 'f2396', 'f2397', 'f2398', 'f2399', 'f2400', 'f2401', 'f2402', 'f2403', 'f2404', 'f2405', 'f2406', 'f2407', 'f2408', 'f2409', 'f2410', 'f2411', 'f2412', 'f2413', 'f2414', 'f2415', 'f2416', 'f2417', 'f2418', 'f2419', 'f2420', 'f2421', 'f2422', 'f2423', 'f2424', 'f2425', 'f2426', 'f2427', 'f2428', 'f2429', 'f2430', 'f2431', 'f2432', 'f2433', 'f2434', 'f2435', 'f2436', 'f2437', 'f2438', 'f2439', 'f2440', 'f2441', 'f2442', 'f2443', 'f2444', 'f2445', 'f2446', 'f2447', 'f2448', 'f2449', 'f2450', 'f2451', 'f2452', 'f2453', 'f2454', 'f2455', 'f2456', 'f2457', 'f2458', 'f2459', 'f2460', 'f2461', 'f2462', 'f2463', 'f2464', 'f2465', 'f2466', 'f2467', 'f2468', 'f2469', 'f2470', 'f2471', 'f2472', 'f2473', 'f2474', 'f2475', 'f2476', 'f2477', 'f2478', 'f2479', 'f2480', 'f2481', 'f2482', 'f2483', 'f2484', 'f2485', 'f2486', 'f2487', 'f2488', 'f2489', 'f2490', 'f2491', 'f2492', 'f2493', 'f2494', 'f2495', 'f2496', 'f2497', 'f2498', 'f2499', 'f2500', 'f2501', 'f2502', 'f2503', 'f2504', 'f2505', 'f2506', 'f2507', 'f2508', 'f2509', 'f2510', 'f2511', 'f2512', 'f2513', 'f2514', 'f2515', 'f2516', 'f2517', 'f2518', 'f2519', 'f2520', 'f2521', 'f2522', 'f2523', 'f2524', 'f2525', 'f2526', 'f2527', 'f2528', 'f2529', 'f2530', 'f2531', 'f2532', 'f2533', 'f2534', 'f2535', 'f2536', 'f2537', 'f2538', 'f2539', 'f2540', 'f2541', 'f2542', 'f2543', 'f2544', 'f2545', 'f2546', 'f2547', 'f2548', 'f2549', 'f2550', 'f2551', 'f2552', 'f2553', 'f2554', 'f2555', 'f2556', 'f2557', 'f2558', 'f2559', 'f2560', 'f2561', 'f2562', 'f2563', 'f2564', 'f2565', 'f2566', 'f2567', 'f2568', 'f2569', 'f2570', 'f2571', 'f2572', 'f2573', 'f2574', 'f2575', 'f2576', 'f2577', 'f2578', 'f2579', 'f2580', 'f2581', 'f2582', 'f2583', 'f2584', 'f2585', 'f2586', 'f2587', 'f2588', 'f2589', 'f2590', 'f2591', 'f2592', 'f2593', 'f2594', 'f2595', 'f2596', 'f2597', 'f2598', 'f2599', 'f2600', 'f2601', 'f2602', 'f2603', 'f2604', 'f2605', 'f2606', 'f2607', 'f2608', 'f2609', 'f2610', 'f2611', 'f2612', 'f2613', 'f2614', 'f2615', 'f2616', 'f2617', 'f2618', 'f2619', 'f2620', 'f2621', 'f2622', 'f2623', 'f2624', 'f2625', 'f2626', 'f2627', 'f2628', 'f2629', 'f2630', 'f2631', 'f2632', 'f2633', 'f2634', 'f2635', 'f2636', 'f2637', 'f2638', 'f2639', 'f2640', 'f2641', 'f2642', 'f2643', 'f2644', 'f2645', 'f2646', 'f2647', 'f2648', 'f2649', 'f2650', 'f2651', 'f2652', 'f2653', 'f2654', 'f2655', 'f2656', 'f2657', 'f2658', 'f2659', 'f2660', 'f2661', 'f2662', 'f2663', 'f2664', 'f2665', 'f2666', 'f2667', 'f2668', 'f2669', 'f2670', 'f2671', 'f2672', 'f2673', 'f2674', 'f2675', 'f2676', 'f2677', 'f2678', 'f2679', 'f2680', 'f2681', 'f2682', 'f2683', 'f2684', 'f2685', 'f2686', 'f2687', 'f2688', 'f2689', 'f2690', 'f2691', 'f2692', 'f2693', 'f2694', 'f2695', 'f2696', 'f2697', 'f2698', 'f2699', 'f2700', 'f2701', 'f2702', 'f2703', 'f2704', 'f2705', 'f2706', 'f2707', 'f2708', 'f2709', 'f2710', 'f2711', 'f2712', 'f2713', 'f2714', 'f2715', 'f2716', 'f2717', 'f2718', 'f2719', 'f2720', 'f2721', 'f2722', 'f2723', 'f2724', 'f2725', 'f2726', 'f2727', 'f2728', 'f2729', 'f2730', 'f2731', 'f2732', 'f2733', 'f2734', 'f2735', 'f2736', 'f2737', 'f2738', 'f2739', 'f2740', 'f2741', 'f2742', 'f2743', 'f2744', 'f2745', 'f2746', 'f2747', 'f2748', 'f2749', 'f2750', 'f2751', 'f2752', 'f2753', 'f2754', 'f2755', 'f2756', 'f2757', 'f2758', 'f2759', 'f2760', 'f2761', 'f2762', 'f2763', 'f2764', 'f2765', 'f2766', 'f2767', 'f2768', 'f2769', 'f2770', 'f2771', 'f2772', 'f2773', 'f2774', 'f2775', 'f2776', 'f2777', 'f2778', 'f2779', 'f2780', 'f2781', 'f2782', 'f2783', 'f2784', 'f2785', 'f2786', 'f2787', 'f2788', 'f2789', 'f2790', 'f2791', 'f2792', 'f2793', 'f2794', 'f2795', 'f2796', 'f2797', 'f2798', 'f2799', 'f2800', 'f2801', 'f2802', 'f2803', 'f2804', 'f2805', 'f2806', 'f2807', 'f2808', 'f2809', 'f2810', 'f2811', 'f2812', 'f2813', 'f2814', 'f2815', 'f2816', 'f2817', 'f2818', 'f2819', 'f2820', 'f2821', 'f2822', 'f2823', 'f2824', 'f2825', 'f2826', 'f2827', 'f2828', 'f2829', 'f2830', 'f2831', 'f2832', 'f2833', 'f2834', 'f2835', 'f2836', 'f2837', 'f2838', 'f2839', 'f2840', 'f2841', 'f2842', 'f2843', 'f2844', 'f2845', 'f2846', 'f2847', 'f2848', 'f2849', 'f2850', 'f2851', 'f2852', 'f2853', 'f2854', 'f2855', 'f2856', 'f2857', 'f2858', 'f2859', 'f2860', 'f2861', 'f2862', 'f2863', 'f2864', 'f2865', 'f2866', 'f2867', 'f2868', 'f2869', 'f2870', 'f2871', 'f2872', 'f2873', 'f2874', 'f2875', 'f2876', 'f2877', 'f2878', 'f2879', 'f2880', 'f2881', 'f2882', 'f2883', 'f2884', 'f2885', 'f2886', 'f2887', 'f2888', 'f2889', 'f2890', 'f2891', 'f2892', 'f2893', 'f2894', 'f2895', 'f2896', 'f2897', 'f2898', 'f2899', 'f2900', 'f2901', 'f2902', 'f2903', 'f2904', 'f2905', 'f2906', 'f2907', 'f2908', 'f2909', 'f2910', 'f2911', 'f2912', 'f2913', 'f2914', 'f2915', 'f2916', 'f2917', 'f2918', 'f2919', 'f2920', 'f2921', 'f2922', 'f2923', 'f2924', 'f2925', 'f2926', 'f2927', 'f2928', 'f2929', 'f2930', 'f2931', 'f2932', 'f2933', 'f2934', 'f2935', 'f2936', 'f2937', 'f2938', 'f2939', 'f2940', 'f2941', 'f2942', 'f2943', 'f2944', 'f2945', 'f2946', 'f2947', 'f2948', 'f2949', 'f2950', 'f2951', 'f2952', 'f2953', 'f2954', 'f2955', 'f2956', 'f2957', 'f2958', 'f2959', 'f2960', 'f2961', 'f2962', 'f2963', 'f2964', 'f2965', 'f2966', 'f2967', 'f2968', 'f2969', 'f2970', 'f2971', 'f2972', 'f2973', 'f2974', 'f2975', 'f2976', 'f2977', 'f2978', 'f2979', 'f2980', 'f2981', 'f2982', 'f2983', 'f2984', 'f2985', 'f2986', 'f2987', 'f2988', 'f2989', 'f2990', 'f2991', 'f2992', 'f2993', 'f2994', 'f2995', 'f2996', 'f2997', 'f2998', 'f2999', 'f3000', 'f3001', 'f3002', 'f3003', 'f3004', 'f3005', 'f3006', 'f3007', 'f3008', 'f3009', 'f3010', 'f3011', 'f3012', 'f3013', 'f3014', 'f3015', 'f3016', 'f3017', 'f3018', 'f3019', 'f3020', 'f3021', 'f3022', 'f3023', 'f3024', 'f3025', 'f3026', 'f3027', 'f3028', 'f3029', 'f3030', 'f3031', 'f3032', 'f3033', 'f3034', 'f3035', 'f3036', 'f3037', 'f3038', 'f3039', 'f3040', 'f3041', 'f3042', 'f3043', 'f3044', 'f3045', 'f3046', 'f3047', 'f3048', 'f3049', 'f3050', 'f3051', 'f3052', 'f3053', 'f3054', 'f3055', 'f3056', 'f3057', 'f3058', 'f3059', 'f3060', 'f3061', 'f3062', 'f3063', 'f3064', 'f3065', 'f3066', 'f3067', 'f3068', 'f3069', 'f3070', 'f3071', 'f3072', 'f3073', 'f3074', 'f3075', 'f3076', 'f3077', 'f3078', 'f3079', 'f3080', 'f3081', 'f3082', 'f3083', 'f3084', 'f3085', 'f3086', 'f3087', 'f3088', 'f3089', 'f3090', 'f3091', 'f3092', 'f3093', 'f3094', 'f3095', 'f3096', 'f3097', 'f3098', 'f3099', 'f3100', 'f3101', 'f3102', 'f3103', 'f3104', 'f3105', 'f3106', 'f3107', 'f3108', 'f3109', 'f3110', 'f3111', 'f3112', 'f3113', 'f3114', 'f3115', 'f3116', 'f3117', 'f3118', 'f3119', 'f3120', 'f3121', 'f3122', 'f3123', 'f3124', 'f3125', 'f3126', 'f3127', 'f3128', 'f3129', 'f3130', 'f3131', 'f3132', 'f3133', 'f3134', 'f3135', 'f3136', 'f3137', 'f3138', 'f3139', 'f3140', 'f3141', 'f3142', 'f3143', 'f3144', 'f3145', 'f3146', 'f3147', 'f3148', 'f3149', 'f3150', 'f3151', 'f3152', 'f3153', 'f3154', 'f3155', 'f3156', 'f3157', 'f3158', 'f3159', 'f3160', 'f3161', 'f3162', 'f3163', 'f3164', 'f3165', 'f3166', 'f3167', 'f3168', 'f3169', 'f3170', 'f3171', 'f3172', 'f3173', 'f3174', 'f3175', 'f3176', 'f3177', 'f3178', 'f3179', 'f3180', 'f3181', 'f3182', 'f3183', 'f3184', 'f3185', 'f3186', 'f3187', 'f3188', 'f3189', 'f3190', 'f3191', 'f3192', 'f3193', 'f3194', 'f3195', 'f3196', 'f3197', 'f3198', 'f3199', 'f3200', 'f3201', 'f3202', 'f3203', 'f3204', 'f3205', 'f3206', 'f3207', 'f3208', 'f3209', 'f3210', 'f3211', 'f3212', 'f3213', 'f3214', 'f3215', 'f3216', 'f3217', 'f3218', 'f3219', 'f3220', 'f3221', 'f3222', 'f3223', 'f3224', 'f3225', 'f3226', 'f3227', 'f3228', 'f3229', 'f3230', 'f3231', 'f3232', 'f3233', 'f3234', 'f3235', 'f3236', 'f3237', 'f3238', 'f3239', 'f3240', 'f3241', 'f3242', 'f3243', 'f3244', 'f3245', 'f3246', 'f3247', 'f3248', 'f3249', 'f3250', 'f3251', 'f3252', 'f3253', 'f3254', 'f3255', 'f3256', 'f3257', 'f3258', 'f3259', 'f3260', 'f3261', 'f3262', 'f3263', 'f3264', 'f3265', 'f3266', 'f3267', 'f3268', 'f3269', 'f3270', 'f3271', 'f3272', 'f3273', 'f3274', 'f3275', 'f3276', 'f3277', 'f3278', 'f3279', 'f3280', 'f3281', 'f3282', 'f3283', 'f3284', 'f3285', 'f3286', 'f3287', 'f3288', 'f3289', 'f3290', 'f3291', 'f3292', 'f3293', 'f3294', 'f3295', 'f3296', 'f3297', 'f3298', 'f3299', 'f3300', 'f3301', 'f3302', 'f3303', 'f3304', 'f3305', 'f3306', 'f3307', 'f3308', 'f3309', 'f3310', 'f3311', 'f3312', 'f3313', 'f3314', 'f3315', 'f3316', 'f3317', 'f3318', 'f3319', 'f3320', 'f3321', 'f3322', 'f3323', 'f3324', 'f3325', 'f3326', 'f3327', 'f3328', 'f3329', 'f3330', 'f3331', 'f3332', 'f3333', 'f3334', 'f3335', 'f3336', 'f3337', 'f3338', 'f3339', 'f3340', 'f3341', 'f3342', 'f3343', 'f3344', 'f3345', 'f3346', 'f3347', 'f3348', 'f3349', 'f3350', 'f3351', 'f3352', 'f3353', 'f3354', 'f3355', 'f3356', 'f3357', 'f3358', 'f3359', 'f3360', 'f3361', 'f3362', 'f3363', 'f3364', 'f3365', 'f3366', 'f3367', 'f3368', 'f3369', 'f3370', 'f3371', 'f3372', 'f3373', 'f3374', 'f3375', 'f3376', 'f3377', 'f3378', 'f3379', 'f3380', 'f3381', 'f3382', 'f3383', 'f3384', 'f3385', 'f3386', 'f3387', 'f3388', 'f3389', 'f3390', 'f3391', 'f3392', 'f3393', 'f3394', 'f3395', 'f3396', 'f3397', 'f3398', 'f3399', 'f3400', 'f3401', 'f3402', 'f3403', 'f3404', 'f3405', 'f3406', 'f3407', 'f3408', 'f3409', 'f3410', 'f3411', 'f3412', 'f3413', 'f3414', 'f3415', 'f3416', 'f3417', 'f3418', 'f3419', 'f3420', 'f3421', 'f3422', 'f3423', 'f3424', 'f3425', 'f3426', 'f3427', 'f3428', 'f3429', 'f3430', 'f3431', 'f3432', 'f3433', 'f3434', 'f3435', 'f3436', 'f3437', 'f3438', 'f3439', 'f3440', 'f3441', 'f3442', 'f3443', 'f3444', 'f3445', 'f3446', 'f3447', 'f3448', 'f3449', 'f3450', 'f3451', 'f3452', 'f3453', 'f3454', 'f3455', 'f3456', 'f3457', 'f3458', 'f3459', 'f3460', 'f3461', 'f3462', 'f3463', 'f3464', 'f3465', 'f3466', 'f3467', 'f3468', 'f3469', 'f3470', 'f3471', 'f3472', 'f3473', 'f3474', 'f3475', 'f3476', 'f3477', 'f3478', 'f3479', 'f3480', 'f3481', 'f3482', 'f3483', 'f3484', 'f3485', 'f3486', 'f3487', 'f3488', 'f3489', 'f3490', 'f3491', 'f3492', 'f3493', 'f3494', 'f3495', 'f3496', 'f3497', 'f3498', 'f3499', 'f3500', 'f3501', 'f3502', 'f3503', 'f3504', 'f3505', 'f3506', 'f3507', 'f3508', 'f3509', 'f3510', 'f3511', 'f3512', 'f3513', 'f3514', 'f3515', 'f3516', 'f3517', 'f3518', 'f3519', 'f3520', 'f3521', 'f3522', 'f3523', 'f3524', 'f3525', 'f3526', 'f3527', 'f3528', 'f3529', 'f3530', 'f3531', 'f3532', 'f3533', 'f3534', 'f3535', 'f3536', 'f3537', 'f3538', 'f3539', 'f3540', 'f3541', 'f3542', 'f3543', 'f3544', 'f3545', 'f3546', 'f3547', 'f3548', 'f3549', 'f3550', 'f3551', 'f3552', 'f3553', 'f3554', 'f3555', 'f3556', 'f3557', 'f3558', 'f3559', 'f3560', 'f3561', 'f3562', 'f3563', 'f3564', 'f3565', 'f3566', 'f3567', 'f3568', 'f3569', 'f3570', 'f3571', 'f3572', 'f3573', 'f3574', 'f3575', 'f3576', 'f3577', 'f3578', 'f3579', 'f3580', 'f3581', 'f3582', 'f3583', 'f3584', 'f3585', 'f3586', 'f3587', 'f3588', 'f3589', 'f3590', 'f3591', 'f3592', 'f3593', 'f3594', 'f3595', 'f3596', 'f3597', 'f3598', 'f3599', 'f3600', 'f3601', 'f3602', 'f3603', 'f3604', 'f3605', 'f3606', 'f3607', 'f3608', 'f3609', 'f3610', 'f3611', 'f3612', 'f3613', 'f3614', 'f3615', 'f3616', 'f3617', 'f3618', 'f3619', 'f3620', 'f3621', 'f3622', 'f3623', 'f3624', 'f3625', 'f3626', 'f3627', 'f3628', 'f3629', 'f3630', 'f3631', 'f3632', 'f3633', 'f3634', 'f3635', 'f3636', 'f3637', 'f3638', 'f3639', 'f3640', 'f3641', 'f3642', 'f3643', 'f3644', 'f3645', 'f3646', 'f3647', 'f3648', 'f3649', 'f3650', 'f3651', 'f3652', 'f3653', 'f3654', 'f3655', 'f3656', 'f3657', 'f3658', 'f3659', 'f3660', 'f3661', 'f3662', 'f3663', 'f3664', 'f3665', 'f3666', 'f3667', 'f3668', 'f3669', 'f3670', 'f3671', 'f3672', 'f3673', 'f3674', 'f3675', 'f3676', 'f3677', 'f3678', 'f3679', 'f3680', 'f3681', 'f3682', 'f3683', 'f3684', 'f3685', 'f3686', 'f3687', 'f3688', 'f3689', 'f3690', 'f3691', 'f3692', 'f3693', 'f3694', 'f3695', 'f3696', 'f3697', 'f3698', 'f3699', 'f3700', 'f3701', 'f3702', 'f3703', 'f3704', 'f3705', 'f3706', 'f3707', 'f3708', 'f3709', 'f3710', 'f3711', 'f3712', 'f3713', 'f3714', 'f3715', 'f3716', 'f3717', 'f3718'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874', 'f875', 'f876', 'f877', 'f878', 'f879', 'f880', 'f881', 'f882', 'f883', 'f884', 'f885', 'f886', 'f887', 'f888', 'f889', 'f890', 'f891', 'f892', 'f893', 'f894', 'f895', 'f896', 'f897', 'f898', 'f899', 'f900', 'f901', 'f902', 'f903', 'f904', 'f905', 'f906', 'f907', 'f908', 'f909', 'f910', 'f911', 'f912', 'f913', 'f914', 'f915', 'f916', 'f917', 'f918', 'f919', 'f920', 'f921', 'f922', 'f923', 'f924', 'f925', 'f926', 'f927', 'f928', 'f929', 'f930', 'f931', 'f932', 'f933', 'f934', 'f935', 'f936', 'f937', 'f938', 'f939', 'f940', 'f941', 'f942', 'f943', 'f944', 'f945', 'f946', 'f947', 'f948', 'f949', 'f950', 'f951', 'f952', 'f953', 'f954', 'f955', 'f956', 'f957', 'f958', 'f959', 'f960', 'f961', 'f962', 'f963', 'f964', 'f965', 'f966', 'f967', 'f968', 'f969', 'f970', 'f971', 'f972', 'f973', 'f974', 'f975', 'f976', 'f977', 'f978', 'f979', 'f980', 'f981', 'f982', 'f983', 'f984', 'f985', 'f986', 'f987', 'f988', 'f989', 'f990', 'f991', 'f992', 'f993', 'f994', 'f995', 'f996', 'f997', 'f998', 'f999', 'f1000', 'f1001', 'f1002', 'f1003', 'f1004', 'f1005', 'f1006', 'f1007', 'f1008', 'f1009', 'f1010', 'f1011', 'f1012', 'f1013', 'f1014', 'f1015', 'f1016', 'f1017', 'f1018', 'f1019', 'f1020', 'f1021', 'f1022', 'f1023', 'f1024', 'f1025', 'f1026', 'f1027', 'f1028', 'f1029', 'f1030', 'f1031', 'f1032', 'f1033', 'f1034', 'f1035', 'f1036', 'f1037', 'f1038', 'f1039', 'f1040', 'f1041', 'f1042', 'f1043', 'f1044', 'f1045', 'f1046', 'f1047', 'f1048', 'f1049', 'f1050', 'f1051', 'f1052', 'f1053', 'f1054', 'f1055', 'f1056', 'f1057', 'f1058', 'f1059', 'f1060', 'f1061', 'f1062', 'f1063', 'f1064', 'f1065', 'f1066', 'f1067', 'f1068', 'f1069', 'f1070', 'f1071', 'f1072', 'f1073', 'f1074', 'f1075', 'f1076', 'f1077', 'f1078', 'f1079', 'f1080', 'f1081', 'f1082', 'f1083', 'f1084', 'f1085', 'f1086', 'f1087', 'f1088', 'f1089', 'f1090', 'f1091', 'f1092', 'f1093', 'f1094', 'f1095', 'f1096', 'f1097', 'f1098', 'f1099', 'f1100', 'f1101', 'f1102', 'f1103', 'f1104', 'f1105', 'f1106', 'f1107', 'f1108', 'f1109', 'f1110', 'f1111', 'f1112', 'f1113', 'f1114', 'f1115', 'f1116', 'f1117', 'f1118', 'f1119', 'f1120', 'f1121', 'f1122', 'f1123', 'f1124', 'f1125', 'f1126', 'f1127', 'f1128', 'f1129', 'f1130', 'f1131', 'f1132', 'f1133', 'f1134', 'f1135', 'f1136', 'f1137', 'f1138', 'f1139', 'f1140', 'f1141', 'f1142', 'f1143', 'f1144', 'f1145', 'f1146', 'f1147', 'f1148', 'f1149', 'f1150', 'f1151', 'f1152', 'f1153', 'f1154', 'f1155', 'f1156', 'f1157', 'f1158', 'f1159', 'f1160', 'f1161', 'f1162', 'f1163', 'f1164', 'f1165', 'f1166', 'f1167', 'f1168', 'f1169', 'f1170', 'f1171', 'f1172', 'f1173', 'f1174', 'f1175', 'f1176', 'f1177', 'f1178', 'f1179', 'f1180', 'f1181', 'f1182', 'f1183', 'f1184', 'f1185', 'f1186', 'f1187', 'f1188', 'f1189', 'f1190', 'f1191', 'f1192', 'f1193', 'f1194', 'f1195', 'f1196', 'f1197', 'f1198', 'f1199', 'f1200', 'f1201', 'f1202', 'f1203', 'f1204', 'f1205', 'f1206', 'f1207', 'f1208', 'f1209', 'f1210', 'f1211', 'f1212', 'f1213', 'f1214', 'f1215', 'f1216', 'f1217', 'f1218', 'f1219', 'f1220', 'f1221', 'f1222', 'f1223', 'f1224', 'f1225', 'f1226', 'f1227', 'f1228', 'f1229', 'f1230', 'f1231', 'f1232', 'f1233', 'f1234', 'f1235', 'f1236', 'f1237', 'f1238', 'f1239', 'f1240', 'f1241', 'f1242', 'f1243', 'f1244', 'f1245', 'f1246', 'f1247', 'f1248', 'f1249', 'f1250', 'f1251', 'f1252', 'f1253', 'f1254', 'f1255', 'f1256', 'f1257', 'f1258', 'f1259', 'f1260', 'f1261', 'f1262', 'f1263', 'f1264', 'f1265', 'f1266', 'f1267', 'f1268', 'f1269', 'f1270', 'f1271', 'f1272', 'f1273', 'f1274', 'f1275', 'f1276', 'f1277', 'f1278', 'f1279', 'f1280', 'f1281', 'f1282', 'f1283', 'f1284', 'f1285', 'f1286', 'f1287', 'f1288', 'f1289', 'f1290', 'f1291', 'f1292', 'f1293', 'f1294', 'f1295', 'f1296', 'f1297', 'f1298', 'f1299', 'f1300', 'f1301', 'f1302', 'f1303', 'f1304', 'f1305', 'f1306', 'f1307', 'f1308', 'f1309', 'f1310', 'f1311', 'f1312', 'f1313', 'f1314', 'f1315', 'f1316', 'f1317', 'f1318', 'f1319', 'f1320', 'f1321', 'f1322', 'f1323', 'f1324', 'f1325', 'f1326', 'f1327', 'f1328', 'f1329', 'f1330', 'f1331', 'f1332', 'f1333', 'f1334', 'f1335', 'f1336', 'f1337', 'f1338', 'f1339', 'f1340', 'f1341', 'f1342', 'f1343', 'f1344', 'f1345', 'f1346', 'f1347', 'f1348', 'f1349', 'f1350', 'f1351', 'f1352', 'f1353', 'f1354', 'f1355', 'f1356', 'f1357', 'f1358', 'f1359', 'f1360', 'f1361', 'f1362', 'f1363', 'f1364', 'f1365', 'f1366', 'f1367', 'f1368', 'f1369', 'f1370', 'f1371', 'f1372', 'f1373', 'f1374', 'f1375', 'f1376', 'f1377', 'f1378', 'f1379', 'f1380', 'f1381', 'f1382', 'f1383', 'f1384', 'f1385', 'f1386', 'f1387', 'f1388', 'f1389', 'f1390', 'f1391', 'f1392', 'f1393', 'f1394', 'f1395', 'f1396', 'f1397', 'f1398', 'f1399', 'f1400', 'f1401', 'f1402', 'f1403', 'f1404', 'f1405', 'f1406', 'f1407', 'f1408', 'f1409', 'f1410', 'f1411', 'f1412', 'f1413', 'f1414', 'f1415', 'f1416', 'f1417', 'f1418', 'f1419', 'f1420', 'f1421', 'f1422', 'f1423', 'f1424', 'f1425', 'f1426', 'f1427', 'f1428', 'f1429', 'f1430', 'f1431', 'f1432', 'f1433', 'f1434', 'f1435', 'f1436', 'f1437', 'f1438', 'f1439', 'f1440', 'f1441', 'f1442', 'f1443', 'f1444', 'f1445', 'f1446', 'f1447', 'f1448', 'f1449', 'f1450', 'f1451', 'f1452', 'f1453', 'f1454', 'f1455', 'f1456', 'f1457', 'f1458', 'f1459', 'f1460', 'f1461', 'f1462', 'f1463', 'f1464', 'f1465', 'f1466', 'f1467', 'f1468', 'f1469', 'f1470', 'f1471', 'f1472', 'f1473', 'f1474', 'f1475', 'f1476', 'f1477', 'f1478', 'f1479', 'f1480', 'f1481', 'f1482', 'f1483', 'f1484', 'f1485', 'f1486', 'f1487', 'f1488', 'f1489', 'f1490', 'f1491', 'f1492', 'f1493', 'f1494', 'f1495', 'f1496', 'f1497', 'f1498', 'f1499', 'f1500', 'f1501', 'f1502', 'f1503', 'f1504', 'f1505', 'f1506', 'f1507', 'f1508', 'f1509', 'f1510', 'f1511', 'f1512', 'f1513', 'f1514', 'f1515', 'f1516', 'f1517', 'f1518', 'f1519', 'f1520', 'f1521', 'f1522', 'f1523', 'f1524', 'f1525', 'f1526', 'f1527', 'f1528', 'f1529', 'f1530', 'f1531', 'f1532', 'f1533', 'f1534', 'f1535', 'f1536', 'f1537', 'f1538', 'f1539', 'f1540', 'f1541', 'f1542', 'f1543', 'f1544', 'f1545', 'f1546', 'f1547', 'f1548', 'f1549', 'f1550', 'f1551', 'f1552', 'f1553', 'f1554', 'f1555', 'f1556', 'f1557', 'f1558', 'f1559', 'f1560', 'f1561', 'f1562', 'f1563', 'f1564', 'f1565', 'f1566', 'f1567', 'f1568', 'f1569', 'f1570', 'f1571', 'f1572', 'f1573', 'f1574', 'f1575', 'f1576', 'f1577', 'f1578', 'f1579', 'f1580', 'f1581', 'f1582', 'f1583', 'f1584', 'f1585', 'f1586', 'f1587', 'f1588', 'f1589', 'f1590', 'f1591', 'f1592', 'f1593', 'f1594', 'f1595', 'f1596', 'f1597', 'f1598', 'f1599', 'f1600', 'f1601', 'f1602', 'f1603', 'f1604', 'f1605', 'f1606', 'f1607', 'f1608', 'f1609', 'f1610', 'f1611', 'f1612', 'f1613', 'f1614', 'f1615', 'f1616', 'f1617', 'f1618', 'f1619', 'f1620', 'f1621', 'f1622', 'f1623', 'f1624', 'f1625', 'f1626', 'f1627', 'f1628', 'f1629', 'f1630', 'f1631', 'f1632', 'f1633', 'f1634', 'f1635', 'f1636', 'f1637', 'f1638', 'f1639', 'f1640', 'f1641', 'f1642', 'f1643', 'f1644', 'f1645', 'f1646', 'f1647', 'f1648', 'f1649', 'f1650', 'f1651', 'f1652', 'f1653', 'f1654', 'f1655', 'f1656', 'f1657', 'f1658', 'f1659', 'f1660', 'f1661', 'f1662', 'f1663', 'f1664', 'f1665', 'f1666', 'f1667', 'f1668', 'f1669', 'f1670', 'f1671', 'f1672', 'f1673', 'f1674', 'f1675', 'f1676', 'f1677', 'f1678', 'f1679', 'f1680', 'f1681', 'f1682', 'f1683', 'f1684', 'f1685', 'f1686', 'f1687', 'f1688', 'f1689', 'f1690', 'f1691', 'f1692', 'f1693', 'f1694', 'f1695', 'f1696', 'f1697', 'f1698', 'f1699', 'f1700', 'f1701', 'f1702', 'f1703', 'f1704', 'f1705', 'f1706', 'f1707', 'f1708', 'f1709', 'f1710', 'f1711', 'f1712', 'f1713', 'f1714', 'f1715', 'f1716', 'f1717', 'f1718', 'f1719', 'f1720', 'f1721', 'f1722', 'f1723', 'f1724', 'f1725', 'f1726', 'f1727', 'f1728', 'f1729', 'f1730', 'f1731', 'f1732', 'f1733', 'f1734', 'f1735', 'f1736', 'f1737', 'f1738', 'f1739', 'f1740', 'f1741', 'f1742', 'f1743', 'f1744', 'f1745', 'f1746', 'f1747', 'f1748', 'f1749', 'f1750', 'f1751', 'f1752', 'f1753', 'f1754', 'f1755', 'f1756', 'f1757', 'f1758', 'f1759', 'f1760', 'f1761', 'f1762', 'f1763', 'f1764', 'f1765', 'f1766', 'f1767', 'f1768', 'f1769', 'f1770', 'f1771', 'f1772', 'f1773', 'f1774', 'f1775', 'f1776', 'f1777', 'f1778', 'f1779', 'f1780', 'f1781', 'f1782', 'f1783', 'f1784', 'f1785', 'f1786', 'f1787', 'f1788', 'f1789', 'f1790', 'f1791', 'f1792', 'f1793', 'f1794', 'f1795', 'f1796', 'f1797', 'f1798', 'f1799', 'f1800', 'f1801', 'f1802', 'f1803', 'f1804', 'f1805', 'f1806', 'f1807', 'f1808', 'f1809', 'f1810', 'f1811', 'f1812', 'f1813', 'f1814', 'f1815', 'f1816', 'f1817', 'f1818', 'f1819', 'f1820', 'f1821', 'f1822', 'f1823', 'f1824', 'f1825', 'f1826', 'f1827', 'f1828', 'f1829', 'f1830', 'f1831', 'f1832', 'f1833', 'f1834', 'f1835', 'f1836', 'f1837', 'f1838', 'f1839', 'f1840', 'f1841', 'f1842', 'f1843', 'f1844', 'f1845', 'f1846', 'f1847', 'f1848', 'f1849', 'f1850', 'f1851', 'f1852', 'f1853', 'f1854', 'f1855', 'f1856', 'f1857', 'f1858', 'f1859', 'f1860', 'f1861', 'f1862', 'f1863', 'f1864', 'f1865', 'f1866', 'f1867', 'f1868', 'f1869', 'f1870', 'f1871', 'f1872', 'f1873', 'f1874', 'f1875', 'f1876', 'f1877', 'f1878', 'f1879', 'f1880', 'f1881', 'f1882', 'f1883', 'f1884', 'f1885', 'f1886', 'f1887', 'f1888', 'f1889', 'f1890', 'f1891', 'f1892', 'f1893', 'f1894', 'f1895', 'f1896', 'f1897', 'f1898', 'f1899', 'f1900', 'f1901', 'f1902', 'f1903', 'f1904', 'f1905', 'f1906', 'f1907', 'f1908', 'f1909', 'f1910', 'f1911', 'f1912', 'f1913', 'f1914', 'f1915', 'f1916', 'f1917', 'f1918', 'f1919', 'f1920', 'f1921', 'f1922', 'f1923', 'f1924', 'f1925', 'f1926', 'f1927', 'f1928', 'f1929', 'f1930', 'f1931', 'f1932', 'f1933', 'f1934', 'f1935', 'f1936', 'f1937', 'f1938', 'f1939', 'f1940', 'f1941', 'f1942', 'f1943', 'f1944', 'f1945', 'f1946', 'f1947', 'f1948', 'f1949', 'f1950', 'f1951', 'f1952', 'f1953', 'f1954', 'f1955', 'f1956', 'f1957', 'f1958', 'f1959', 'f1960', 'f1961', 'f1962', 'f1963', 'f1964', 'f1965', 'f1966', 'f1967', 'f1968', 'f1969', 'f1970', 'f1971', 'f1972', 'f1973', 'f1974', 'f1975', 'f1976', 'f1977', 'f1978', 'f1979', 'f1980', 'f1981', 'f1982', 'f1983', 'f1984', 'f1985', 'f1986', 'f1987', 'f1988', 'f1989', 'f1990', 'f1991', 'f1992', 'f1993', 'f1994', 'f1995', 'f1996', 'f1997', 'f1998', 'f1999', 'f2000', 'f2001', 'f2002', 'f2003', 'f2004', 'f2005', 'f2006', 'f2007', 'f2008', 'f2009', 'f2010', 'f2011', 'f2012', 'f2013', 'f2014', 'f2015', 'f2016', 'f2017', 'f2018', 'f2019', 'f2020', 'f2021', 'f2022', 'f2023', 'f2024', 'f2025', 'f2026', 'f2027', 'f2028', 'f2029', 'f2030', 'f2031', 'f2032', 'f2033', 'f2034', 'f2035', 'f2036', 'f2037', 'f2038', 'f2039', 'f2040', 'f2041', 'f2042', 'f2043', 'f2044', 'f2045', 'f2046', 'f2047', 'f2048', 'f2049', 'f2050', 'f2051', 'f2052', 'f2053', 'f2054', 'f2055', 'f2056', 'f2057', 'f2058', 'f2059', 'f2060', 'f2061', 'f2062', 'f2063', 'f2064', 'f2065', 'f2066', 'f2067', 'f2068', 'f2069', 'f2070', 'f2071', 'f2072', 'f2073', 'f2074', 'f2075', 'f2076', 'f2077', 'f2078', 'f2079', 'f2080', 'f2081', 'f2082', 'f2083', 'f2084', 'f2085', 'f2086', 'f2087', 'f2088', 'f2089', 'f2090', 'f2091', 'f2092', 'f2093', 'f2094', 'f2095', 'f2096', 'f2097', 'f2098', 'f2099', 'f2100', 'f2101', 'f2102', 'f2103', 'f2104', 'f2105', 'f2106', 'f2107', 'f2108', 'f2109', 'f2110', 'f2111', 'f2112', 'f2113', 'f2114', 'f2115', 'f2116', 'f2117', 'f2118', 'f2119', 'f2120', 'f2121', 'f2122', 'f2123', 'f2124', 'f2125', 'f2126', 'f2127', 'f2128', 'f2129', 'f2130', 'f2131', 'f2132', 'f2133', 'f2134', 'f2135', 'f2136', 'f2137', 'f2138', 'f2139', 'f2140', 'f2141', 'f2142', 'f2143', 'f2144', 'f2145', 'f2146', 'f2147', 'f2148', 'f2149', 'f2150', 'f2151', 'f2152', 'f2153', 'f2154', 'f2155', 'f2156', 'f2157', 'f2158', 'f2159', 'f2160', 'f2161', 'f2162', 'f2163', 'f2164', 'f2165', 'f2166', 'f2167', 'f2168', 'f2169', 'f2170', 'f2171', 'f2172', 'f2173', 'f2174', 'f2175', 'f2176', 'f2177', 'f2178', 'f2179', 'f2180', 'f2181', 'f2182', 'f2183', 'f2184', 'f2185', 'f2186', 'f2187', 'f2188', 'f2189', 'f2190', 'f2191', 'f2192', 'f2193', 'f2194', 'f2195', 'f2196', 'f2197', 'f2198', 'f2199', 'f2200', 'f2201', 'f2202', 'f2203', 'f2204', 'f2205', 'f2206', 'f2207', 'f2208', 'f2209', 'f2210', 'f2211', 'f2212', 'f2213', 'f2214', 'f2215', 'f2216', 'f2217', 'f2218', 'f2219', 'f2220', 'f2221', 'f2222', 'f2223', 'f2224', 'f2225', 'f2226', 'f2227', 'f2228', 'f2229', 'f2230', 'f2231', 'f2232', 'f2233', 'f2234', 'f2235', 'f2236', 'f2237', 'f2238', 'f2239', 'f2240', 'f2241', 'f2242', 'f2243', 'f2244', 'f2245', 'f2246', 'f2247', 'f2248', 'f2249', 'f2250', 'f2251', 'f2252', 'f2253', 'f2254', 'f2255', 'f2256', 'f2257', 'f2258', 'f2259', 'f2260', 'f2261', 'f2262', 'f2263', 'f2264', 'f2265', 'f2266', 'f2267', 'f2268', 'f2269', 'f2270', 'f2271', 'f2272', 'f2273', 'f2274', 'f2275', 'f2276', 'f2277', 'f2278', 'f2279', 'f2280', 'f2281', 'f2282', 'f2283', 'f2284', 'f2285', 'f2286', 'f2287', 'f2288', 'f2289', 'f2290', 'f2291', 'f2292', 'f2293', 'f2294', 'f2295', 'f2296', 'f2297', 'f2298', 'f2299', 'f2300', 'f2301', 'f2302', 'f2303', 'f2304', 'f2305', 'f2306', 'f2307', 'f2308', 'f2309', 'f2310', 'f2311', 'f2312', 'f2313', 'f2314', 'f2315', 'f2316', 'f2317', 'f2318', 'f2319', 'f2320', 'f2321', 'f2322', 'f2323', 'f2324', 'f2325', 'f2326', 'f2327', 'f2328', 'f2329', 'f2330', 'f2331', 'f2332', 'f2333', 'f2334', 'f2335', 'f2336', 'f2337', 'f2338', 'f2339', 'f2340', 'f2341', 'f2342', 'f2343', 'f2344', 'f2345', 'f2346', 'f2347', 'f2348', 'f2349', 'f2350', 'f2351', 'f2352', 'f2353', 'f2354', 'f2355', 'f2356', 'f2357', 'f2358', 'f2359', 'f2360', 'f2361', 'f2362', 'f2363', 'f2364', 'f2365', 'f2366', 'f2367', 'f2368', 'f2369', 'f2370', 'f2371', 'f2372', 'f2373', 'f2374', 'f2375', 'f2376', 'f2377', 'f2378', 'f2379', 'f2380', 'f2381', 'f2382', 'f2383', 'f2384', 'f2385', 'f2386', 'f2387', 'f2388', 'f2389', 'f2390', 'f2391', 'f2392', 'f2393', 'f2394', 'f2395', 'f2396', 'f2397', 'f2398', 'f2399', 'f2400', 'f2401', 'f2402', 'f2403', 'f2404', 'f2405', 'f2406', 'f2407', 'f2408', 'f2409', 'f2410', 'f2411', 'f2412', 'f2413', 'f2414', 'f2415', 'f2416', 'f2417', 'f2418', 'f2419', 'f2420', 'f2421', 'f2422', 'f2423', 'f2424', 'f2425', 'f2426', 'f2427', 'f2428', 'f2429', 'f2430', 'f2431', 'f2432', 'f2433', 'f2434', 'f2435', 'f2436', 'f2437', 'f2438', 'f2439', 'f2440', 'f2441', 'f2442', 'f2443', 'f2444', 'f2445', 'f2446', 'f2447', 'f2448', 'f2449', 'f2450', 'f2451', 'f2452', 'f2453', 'f2454', 'f2455', 'f2456', 'f2457', 'f2458', 'f2459', 'f2460', 'f2461', 'f2462', 'f2463', 'f2464', 'f2465', 'f2466', 'f2467', 'f2468', 'f2469', 'f2470', 'f2471', 'f2472', 'f2473', 'f2474', 'f2475', 'f2476', 'f2477', 'f2478', 'f2479', 'f2480', 'f2481', 'f2482', 'f2483', 'f2484', 'f2485', 'f2486', 'f2487', 'f2488', 'f2489', 'f2490', 'f2491', 'f2492', 'f2493', 'f2494', 'f2495', 'f2496', 'f2497', 'f2498', 'f2499', 'f2500', 'f2501', 'f2502', 'f2503', 'f2504', 'f2505', 'f2506', 'f2507', 'f2508', 'f2509', 'f2510', 'f2511', 'f2512', 'f2513', 'f2514', 'f2515', 'f2516', 'f2517', 'f2518', 'f2519', 'f2520', 'f2521', 'f2522', 'f2523', 'f2524', 'f2525', 'f2526', 'f2527', 'f2528', 'f2529', 'f2530', 'f2531', 'f2532', 'f2533', 'f2534', 'f2535', 'f2536', 'f2537', 'f2538', 'f2539', 'f2540', 'f2541', 'f2542', 'f2543', 'f2544', 'f2545', 'f2546', 'f2547', 'f2548', 'f2549', 'f2550', 'f2551', 'f2552', 'f2553', 'f2554', 'f2555', 'f2556', 'f2557', 'f2558', 'f2559', 'f2560', 'f2561', 'f2562', 'f2563', 'f2564', 'f2565', 'f2566', 'f2567', 'f2568', 'f2569', 'f2570', 'f2571', 'f2572', 'f2573', 'f2574', 'f2575', 'f2576', 'f2577', 'f2578', 'f2579', 'f2580', 'f2581', 'f2582', 'f2583', 'f2584', 'f2585', 'f2586', 'f2587', 'f2588', 'f2589', 'f2590', 'f2591', 'f2592', 'f2593', 'f2594', 'f2595', 'f2596', 'f2597', 'f2598', 'f2599', 'f2600', 'f2601', 'f2602', 'f2603', 'f2604', 'f2605', 'f2606', 'f2607', 'f2608', 'f2609', 'f2610', 'f2611', 'f2612', 'f2613', 'f2614', 'f2615', 'f2616', 'f2617', 'f2618', 'f2619', 'f2620', 'f2621', 'f2622', 'f2623', 'f2624', 'f2625', 'f2626', 'f2627', 'f2628', 'f2629', 'f2630', 'f2631', 'f2632', 'f2633', 'f2634', 'f2635', 'f2636', 'f2637', 'f2638', 'f2639', 'f2640', 'f2641', 'f2642', 'f2643', 'f2644', 'f2645', 'f2646', 'f2647', 'f2648', 'f2649', 'f2650', 'f2651', 'f2652', 'f2653', 'f2654', 'f2655', 'f2656', 'f2657', 'f2658', 'f2659', 'f2660', 'f2661', 'f2662', 'f2663', 'f2664', 'f2665', 'f2666', 'f2667', 'f2668', 'f2669', 'f2670', 'f2671', 'f2672', 'f2673', 'f2674', 'f2675', 'f2676', 'f2677', 'f2678', 'f2679', 'f2680', 'f2681', 'f2682', 'f2683', 'f2684', 'f2685', 'f2686', 'f2687', 'f2688', 'f2689', 'f2690', 'f2691', 'f2692', 'f2693', 'f2694', 'f2695', 'f2696', 'f2697', 'f2698', 'f2699', 'f2700', 'f2701', 'f2702', 'f2703', 'f2704', 'f2705', 'f2706', 'f2707', 'f2708', 'f2709', 'f2710', 'f2711', 'f2712', 'f2713', 'f2714', 'f2715', 'f2716', 'f2717', 'f2718', 'f2719', 'f2720', 'f2721', 'f2722', 'f2723', 'f2724', 'f2725', 'f2726', 'f2727', 'f2728', 'f2729', 'f2730', 'f2731', 'f2732', 'f2733', 'f2734', 'f2735', 'f2736', 'f2737', 'f2738', 'f2739', 'f2740', 'f2741', 'f2742', 'f2743', 'f2744', 'f2745', 'f2746', 'f2747', 'f2748', 'f2749', 'f2750', 'f2751', 'f2752', 'f2753', 'f2754', 'f2755', 'f2756', 'f2757', 'f2758', 'f2759', 'f2760', 'f2761', 'f2762', 'f2763', 'f2764', 'f2765', 'f2766', 'f2767', 'f2768', 'f2769', 'f2770', 'f2771', 'f2772', 'f2773', 'f2774', 'f2775', 'f2776', 'f2777', 'f2778', 'f2779', 'f2780', 'f2781', 'f2782', 'f2783', 'f2784', 'f2785', 'f2786', 'f2787', 'f2788', 'f2789', 'f2790', 'f2791', 'f2792', 'f2793', 'f2794', 'f2795', 'f2796', 'f2797', 'f2798', 'f2799', 'f2800', 'f2801', 'f2802', 'f2803', 'f2804', 'f2805', 'f2806', 'f2807', 'f2808', 'f2809', 'f2810', 'f2811', 'f2812', 'f2813', 'f2814', 'f2815', 'f2816', 'f2817', 'f2818', 'f2819', 'f2820', 'f2821', 'f2822', 'f2823', 'f2824', 'f2825', 'f2826', 'f2827', 'f2828', 'f2829', 'f2830', 'f2831', 'f2832', 'f2833', 'f2834', 'f2835', 'f2836', 'f2837', 'f2838', 'f2839', 'f2840', 'f2841', 'f2842', 'f2843', 'f2844', 'f2845', 'f2846', 'f2847', 'f2848', 'f2849', 'f2850', 'f2851', 'f2852', 'f2853', 'f2854', 'f2855', 'f2856', 'f2857', 'f2858', 'f2859', 'f2860', 'f2861', 'f2862', 'f2863', 'f2864', 'f2865', 'f2866', 'f2867', 'f2868', 'f2869', 'f2870', 'f2871', 'f2872', 'f2873', 'f2874', 'f2875', 'f2876', 'f2877', 'f2878', 'f2879', 'f2880', 'f2881', 'f2882', 'f2883', 'f2884', 'f2885', 'f2886', 'f2887', 'f2888', 'f2889', 'f2890', 'f2891', 'f2892', 'f2893', 'f2894', 'f2895', 'f2896', 'f2897', 'f2898', 'f2899', 'f2900', 'f2901', 'f2902', 'f2903', 'f2904', 'f2905', 'f2906', 'f2907', 'f2908', 'f2909', 'f2910', 'f2911', 'f2912', 'f2913', 'f2914', 'f2915', 'f2916', 'f2917', 'f2918', 'f2919', 'f2920', 'f2921', 'f2922', 'f2923', 'f2924', 'f2925', 'f2926', 'f2927', 'f2928', 'f2929', 'f2930', 'f2931', 'f2932', 'f2933', 'f2934', 'f2935', 'f2936', 'f2937', 'f2938', 'f2939', 'f2940', 'f2941', 'f2942', 'f2943', 'f2944', 'f2945', 'f2946', 'f2947', 'f2948', 'f2949', 'f2950', 'f2951', 'f2952', 'f2953', 'f2954', 'f2955', 'f2956', 'f2957', 'f2958', 'f2959', 'f2960', 'f2961', 'f2962', 'f2963', 'f2964', 'f2965', 'f2966', 'f2967', 'f2968', 'f2969', 'f2970', 'f2971', 'f2972', 'f2973', 'f2974', 'f2975', 'f2976', 'f2977', 'f2978', 'f2979', 'f2980', 'f2981', 'f2982', 'f2983', 'f2984', 'f2985', 'f2986', 'f2987', 'f2988', 'f2989', 'f2990', 'f2991', 'f2992', 'f2993', 'f2994', 'f2995', 'f2996', 'f2997', 'f2998', 'f2999', 'f3000', 'f3001', 'f3002', 'f3003', 'f3004', 'f3005', 'f3006', 'f3007', 'f3008', 'f3009', 'f3010', 'f3011', 'f3012', 'f3013', 'f3014', 'f3015', 'f3016', 'f3017', 'f3018', 'f3019', 'f3020', 'f3021', 'f3022', 'f3023', 'f3024', 'f3025', 'f3026', 'f3027', 'f3028', 'f3029', 'f3030', 'f3031', 'f3032', 'f3033', 'f3034', 'f3035', 'f3036', 'f3037', 'f3038', 'f3039', 'f3040', 'f3041', 'f3042', 'f3043', 'f3044', 'f3045', 'f3046', 'f3047', 'f3048', 'f3049', 'f3050', 'f3051', 'f3052', 'f3053', 'f3054', 'f3055', 'f3056', 'f3057', 'f3058', 'f3059', 'f3060', 'f3061', 'f3062', 'f3063', 'f3064', 'f3065', 'f3066', 'f3067', 'f3068', 'f3069', 'f3070', 'f3071', 'f3072', 'f3073', 'f3074', 'f3075', 'f3076', 'f3077', 'f3078', 'f3079', 'f3080', 'f3081', 'f3082', 'f3083', 'f3084', 'f3085', 'f3086', 'f3087', 'f3088', 'f3089', 'f3090', 'f3091', 'f3092', 'f3093', 'f3094', 'f3095', 'f3096', 'f3097', 'f3098', 'f3099', 'f3100', 'f3101', 'f3102', 'f3103', 'f3104', 'f3105', 'f3106', 'f3107', 'f3108', 'f3109', 'f3110', 'f3111', 'f3112', 'f3113', 'f3114', 'f3115', 'f3116', 'f3117', 'f3118', 'f3119', 'f3120', 'f3121', 'f3122', 'f3123', 'f3124', 'f3125', 'f3126', 'f3127', 'f3128', 'f3129', 'f3130', 'f3131', 'f3132', 'f3133', 'f3134', 'f3135', 'f3136', 'f3137', 'f3138', 'f3139', 'f3140', 'f3141', 'f3142', 'f3143', 'f3144', 'f3145', 'f3146', 'f3147', 'f3148', 'f3149', 'f3150', 'f3151', 'f3152', 'f3153', 'f3154', 'f3155', 'f3156', 'f3157', 'f3158', 'f3159', 'f3160', 'f3161', 'f3162', 'f3163', 'f3164', 'f3165', 'f3166', 'f3167', 'f3168', 'f3169', 'f3170', 'f3171', 'f3172', 'f3173', 'f3174', 'f3175', 'f3176', 'f3177', 'f3178', 'f3179', 'f3180', 'f3181', 'f3182', 'f3183', 'f3184', 'f3185', 'f3186', 'f3187', 'f3188', 'f3189', 'f3190', 'f3191', 'f3192', 'f3193', 'f3194', 'f3195', 'f3196', 'f3197', 'f3198', 'f3199', 'f3200', 'f3201', 'f3202', 'f3203', 'f3204', 'f3205', 'f3206', 'f3207', 'f3208', 'f3209', 'f3210', 'f3211', 'f3212', 'f3213', 'f3214', 'f3215', 'f3216', 'f3217', 'f3218', 'f3219', 'f3220', 'f3221', 'f3222', 'f3223', 'f3224', 'f3225', 'f3226', 'f3227', 'f3228', 'f3229', 'f3230', 'f3231', 'f3232', 'f3233', 'f3234', 'f3235', 'f3236', 'f3237', 'f3238', 'f3239', 'f3240', 'f3241', 'f3242', 'f3243', 'f3244', 'f3245', 'f3246', 'f3247', 'f3248', 'f3249', 'f3250', 'f3251', 'f3252', 'f3253', 'f3254', 'f3255', 'f3256', 'f3257', 'f3258', 'f3259', 'f3260', 'f3261', 'f3262', 'f3263', 'f3264', 'f3265', 'f3266', 'f3267', 'f3268', 'f3269', 'f3270', 'f3271', 'f3272', 'f3273', 'f3274', 'f3275', 'f3276', 'f3277', 'f3278', 'f3279', 'f3280', 'f3281', 'f3282', 'f3283', 'f3284', 'f3285', 'f3286', 'f3287', 'f3288', 'f3289', 'f3290', 'f3291', 'f3292', 'f3293', 'f3294', 'f3295', 'f3296', 'f3297', 'f3298', 'f3299', 'f3300', 'f3301', 'f3302', 'f3303', 'f3304', 'f3305', 'f3306', 'f3307', 'f3308', 'f3309', 'f3310', 'f3311', 'f3312', 'f3313', 'f3314', 'f3315', 'f3316', 'f3317', 'f3318', 'f3319', 'f3320', 'f3321', 'f3322', 'f3323', 'f3324', 'f3325', 'f3326', 'f3327', 'f3328', 'f3329', 'f3330', 'f3331', 'f3332', 'f3333', 'f3334', 'f3335', 'f3336', 'f3337', 'f3338', 'f3339', 'f3340', 'f3341', 'f3342', 'f3343', 'f3344', 'f3345', 'f3346', 'f3347', 'f3348', 'f3349', 'f3350', 'f3351', 'f3352', 'f3353', 'f3354', 'f3355', 'f3356', 'f3357', 'f3358', 'f3359', 'f3360', 'f3361', 'f3362', 'f3363', 'f3364', 'f3365', 'f3366', 'f3367', 'f3368', 'f3369', 'f3370', 'f3371', 'f3372', 'f3373', 'f3374', 'f3375', 'f3376', 'f3377', 'f3378', 'f3379', 'f3380', 'f3381', 'f3382', 'f3383', 'f3384', 'f3385', 'f3386', 'f3387', 'f3388', 'f3389', 'f3390', 'f3391', 'f3392', 'f3393', 'f3394', 'f3395', 'f3396', 'f3397', 'f3398', 'f3399', 'f3400', 'f3401', 'f3402', 'f3403', 'f3404', 'f3405', 'f3406', 'f3407', 'f3408', 'f3409', 'f3410', 'f3411', 'f3412', 'f3413', 'f3414', 'f3415', 'f3416', 'f3417', 'f3418', 'f3419', 'f3420', 'f3421', 'f3422', 'f3423', 'f3424', 'f3425', 'f3426', 'f3427', 'f3428', 'f3429', 'f3430', 'f3431', 'f3432', 'f3433', 'f3434', 'f3435', 'f3436', 'f3437', 'f3438', 'f3439', 'f3440', 'f3441', 'f3442', 'f3443', 'f3444', 'f3445', 'f3446', 'f3447', 'f3448', 'f3449', 'f3450', 'f3451', 'f3452', 'f3453', 'f3454', 'f3455', 'f3456', 'f3457', 'f3458', 'f3459', 'f3460', 'f3461', 'f3462', 'f3463', 'f3464', 'f3465', 'f3466', 'f3467', 'f3468', 'f3469', 'f3470', 'f3471', 'f3472', 'f3473', 'f3474', 'f3475', 'f3476', 'f3477', 'f3478', 'f3479', 'f3480', 'f3481', 'f3482', 'f3483', 'f3484', 'f3485', 'f3486', 'f3487', 'f3488', 'f3489', 'f3490', 'f3491', 'f3492', 'f3493', 'f3494', 'f3495', 'f3496', 'f3497', 'f3498', 'f3499', 'f3500', 'f3501', 'f3502', 'f3503', 'f3504', 'f3505', 'f3506', 'f3507', 'f3508', 'f3509', 'f3510', 'f3511', 'f3512', 'f3513', 'f3514', 'f3515', 'f3516', 'f3517', 'f3518', 'f3519', 'f3520', 'f3521', 'f3522', 'f3523', 'f3524', 'f3525', 'f3526', 'f3527', 'f3528', 'f3529', 'f3530', 'f3531', 'f3532', 'f3533', 'f3534', 'f3535', 'f3536', 'f3537', 'f3538', 'f3539', 'f3540', 'f3541', 'f3542', 'f3543', 'f3544', 'f3545', 'f3546', 'f3547', 'f3548', 'f3549', 'f3550', 'f3551', 'f3552', 'f3553', 'f3554', 'f3555', 'f3556', 'f3557', 'f3558', 'f3559', 'f3560', 'f3561', 'f3562', 'f3563', 'f3564', 'f3565', 'f3566', 'f3567', 'f3568', 'f3569', 'f3570', 'f3571', 'f3572', 'f3573', 'f3574', 'f3575', 'f3576', 'f3577', 'f3578', 'f3579', 'f3580', 'f3581', 'f3582', 'f3583', 'f3584', 'f3585', 'f3586', 'f3587', 'f3588', 'f3589', 'f3590', 'f3591', 'f3592', 'f3593', 'f3594', 'f3595', 'f3596', 'f3597', 'f3598', 'f3599', 'f3600', 'f3601', 'f3602', 'f3603', 'f3604', 'f3605', 'f3606', 'f3607', 'f3608', 'f3609', 'f3610', 'f3611', 'f3612', 'f3613', 'f3614', 'f3615', 'f3616', 'f3617', 'f3618', 'f3619', 'f3620', 'f3621', 'f3622', 'f3623', 'f3624', 'f3625', 'f3626', 'f3627', 'f3628', 'f3629', 'f3630', 'f3631', 'f3632', 'f3633', 'f3634', 'f3635', 'f3636', 'f3637', 'f3638', 'f3639', 'f3640', 'f3641', 'f3642', 'f3643', 'f3644', 'f3645', 'f3646', 'f3647', 'f3648', 'f3649', 'f3650', 'f3651', 'f3652', 'f3653', 'f3654', 'f3655', 'f3656', 'f3657', 'f3658', 'f3659', 'f3660', 'f3661', 'f3662', 'f3663', 'f3664', 'f3665', 'f3666', 'f3667', 'f3668', 'f3669', 'f3670', 'f3671', 'f3672', 'f3673', 'f3674', 'f3675', 'f3676', 'f3677', 'f3678', 'f3679', 'f3680', 'f3681', 'f3682', 'f3683', 'f3684', 'f3685', 'f3686', 'f3687', 'f3688', 'f3689', 'f3690', 'f3691', 'f3692', 'f3693', 'f3694', 'f3695', 'f3696', 'f3697', 'f3698', 'f3699', 'f3700', 'f3701', 'f3702', 'f3703', 'f3704', 'f3705', 'f3706', 'f3707', 'f3708', 'f3709', 'f3710', 'f3711', 'f3712', 'f3713', 'f3714', 'f3715', 'f3716', 'f3717', 'f3718', 'f3719', 'f3720', 'f3721', 'f3722', 'f3723', 'f3724', 'f3725', 'f3726', 'f3727', 'f3728', 'f3729', 'f3730', 'f3731', 'f3732', 'f3733', 'f3734', 'f3735', 'f3736', 'f3737', 'f3738', 'f3739', 'f3740', 'f3741', 'f3742', 'f3743', 'f3744', 'f3745', 'f3746', 'f3747', 'f3748', 'f3749', 'f3750', 'f3751', 'f3752', 'f3753', 'f3754', 'f3755', 'f3756', 'f3757', 'f3758', 'f3759', 'f3760', 'f3761', 'f3762', 'f3763', 'f3764', 'f3765', 'f3766', 'f3767', 'f3768', 'f3769', 'f3770', 'f3771', 'f3772', 'f3773', 'f3774', 'f3775', 'f3776', 'f3777', 'f3778', 'f3779', 'f3780', 'f3781', 'f3782', 'f3783', 'f3784', 'f3785', 'f3786', 'f3787', 'f3788', 'f3789', 'f3790', 'f3791', 'f3792', 'f3793', 'f3794', 'f3795', 'f3796', 'f3797', 'f3798', 'f3799', 'f3800', 'f3801', 'f3802', 'f3803', 'f3804', 'f3805', 'f3806', 'f3807', 'f3808', 'f3809', 'f3810', 'f3811', 'f3812', 'f3813', 'f3814', 'f3815', 'f3816', 'f3817', 'f3818', 'f3819', 'f3820', 'f3821', 'f3822', 'f3823', 'f3824', 'f3825', 'f3826', 'f3827', 'f3828', 'f3829', 'f3830', 'f3831', 'f3832', 'f3833', 'f3834', 'f3835', 'f3836', 'f3837', 'f3838', 'f3839', 'f3840', 'f3841', 'f3842', 'f3843', 'f3844', 'f3845', 'f3846', 'f3847', 'f3848', 'f3849', 'f3850', 'f3851', 'f3852', 'f3853', 'f3854', 'f3855', 'f3856', 'f3857', 'f3858', 'f3859', 'f3860', 'f3861', 'f3862', 'f3863', 'f3864', 'f3865', 'f3866', 'f3867', 'f3868', 'f3869', 'f3870', 'f3871', 'f3872', 'f3873', 'f3874', 'f3875', 'f3876', 'f3877', 'f3878', 'f3879', 'f3880', 'f3881', 'f3882', 'f3883', 'f3884', 'f3885', 'f3886', 'f3887', 'f3888', 'f3889', 'f3890', 'f3891', 'f3892', 'f3893', 'f3894', 'f3895', 'f3896', 'f3897', 'f3898', 'f3899', 'f3900', 'f3901', 'f3902', 'f3903', 'f3904', 'f3905', 'f3906', 'f3907', 'f3908', 'f3909', 'f3910', 'f3911', 'f3912', 'f3913', 'f3914', 'f3915', 'f3916', 'f3917', 'f3918', 'f3919', 'f3920', 'f3921', 'f3922', 'f3923', 'f3924', 'f3925', 'f3926', 'f3927', 'f3928', 'f3929', 'f3930', 'f3931', 'f3932', 'f3933', 'f3934', 'f3935', 'f3936', 'f3937', 'f3938', 'f3939', 'f3940', 'f3941', 'f3942', 'f3943', 'f3944', 'f3945', 'f3946', 'f3947', 'f3948', 'f3949', 'f3950', 'f3951', 'f3952', 'f3953', 'f3954', 'f3955', 'f3956', 'f3957', 'f3958', 'f3959', 'f3960', 'f3961', 'f3962', 'f3963', 'f3964', 'f3965', 'f3966', 'f3967', 'f3968', 'f3969', 'f3970', 'f3971', 'f3972', 'f3973', 'f3974', 'f3975', 'f3976', 'f3977', 'f3978', 'f3979', 'f3980', 'f3981', 'f3982', 'f3983', 'f3984', 'f3985', 'f3986', 'f3987', 'f3988', 'f3989', 'f3990', 'f3991', 'f3992', 'f3993', 'f3994', 'f3995', 'f3996', 'f3997', 'f3998', 'f3999', 'f4000', 'f4001', 'f4002', 'f4003', 'f4004', 'f4005', 'f4006', 'f4007', 'f4008', 'f4009', 'f4010', 'f4011', 'f4012', 'f4013', 'f4014', 'f4015', 'f4016', 'f4017', 'f4018', 'f4019', 'f4020', 'f4021', 'f4022', 'f4023', 'f4024', 'f4025', 'f4026', 'f4027', 'f4028', 'f4029', 'f4030', 'f4031', 'f4032', 'f4033', 'f4034', 'f4035', 'f4036', 'f4037', 'f4038', 'f4039', 'f4040', 'f4041', 'f4042', 'f4043', 'f4044', 'f4045', 'f4046', 'f4047', 'f4048', 'f4049', 'f4050', 'f4051', 'f4052', 'f4053', 'f4054', 'f4055', 'f4056', 'f4057', 'f4058', 'f4059', 'f4060', 'f4061', 'f4062', 'f4063', 'f4064', 'f4065', 'f4066', 'f4067', 'f4068', 'f4069', 'f4070', 'f4071', 'f4072', 'f4073', 'f4074', 'f4075', 'f4076', 'f4077', 'f4078', 'f4079', 'f4080', 'f4081', 'f4082', 'f4083', 'f4084', 'f4085', 'f4086', 'f4087', 'f4088']\ntraining data did not have the following fields: f3949, f3948, f3943, f3942, f3941, f3940, f3947, f3946, f3945, f3944, f4043, f4042, f4041, f4040, f4047, f4046, f4045, f4044, f4049, f4048, f3798, f3799, f3792, f3793, f3790, f3791, f3796, f3797, f3794, f3795, f3888, f3889, f3886, f3887, f3884, f3885, f3882, f3883, f3880, f3881, f3833, f3832, f3831, f3830, f3837, f3836, f3835, f3834, f3839, f3838, f4020, f3909, f3908, f3907, f3906, f3905, f3904, f3903, f3902, f3901, f3900, f3758, f3759, f3756, f3757, f3754, f3755, f3752, f3753, f3750, f3751, f3990, f3991, f3992, f3993, f3994, f3995, f3996, f3997, f3998, f3999, f3877, f3876, f3875, f3874, f3873, f3872, f3871, f3870, f3879, f3878, f4007, f4006, f4005, f4004, f4003, f4002, f4001, f4000, f4009, f4008, f3954, f3955, f3956, f3957, f3950, f3951, f3952, f3953, f3958, f3959, f4058, f4059, f4054, f4055, f4056, f4057, f4050, f4051, f4052, f4053, f3719, f3828, f3829, f3824, f3825, f3826, f3827, f3820, f3821, f3822, f3823, f3918, f3919, f3910, f3911, f3912, f3913, f3914, f3915, f3916, f3917, f3769, f3768, f3763, f3762, f3761, f3760, f3767, f3766, f3765, f3764, f3737, f4088, f4087, f4086, f4085, f4084, f4083, f4082, f4081, f4080, f3969, f3968, f3965, f3964, f3967, f3966, f3961, f3960, f3963, f3962, f4065, f4064, f4067, f4066, f4061, f4060, f4063, f4062, f4069, f4068, f3860, f3861, f3862, f3863, f3864, f3865, f3866, f3867, f3868, f3869, f4010, f4011, f4012, f4013, f4014, f4015, f4016, f4017, f4018, f4019, f3815, f3814, f3817, f3816, f3811, f3810, f3813, f3812, f3819, f3818, f3921, f3920, f3923, f3922, f3925, f3924, f3927, f3926, f3929, f3928, f3745, f3744, f3747, f4029, f4028, f3746, f4021, f3741, f4023, f4022, f4025, f4024, f4027, f4026, f3743, f3742, f3729, f3728, f3727, f3726, f3725, f3724, f3723, f3722, f3721, f3720, f3859, f3858, f3851, f3850, f3853, f3852, f3855, f3854, f3857, f3856, f3738, f3739, f3989, f3978, f3979, f3976, f3977, f3974, f3975, f3972, f3973, f3970, f3971, f4076, f4077, f4074, f4075, f4072, f4073, f4070, f4071, f4078, f4079, f3789, f3788, f3781, f3780, f3783, f3782, f3785, f3784, f3787, f3786, f3899, f3898, f3895, f3894, f3897, f3896, f3891, f3890, f3893, f3892, f3774, f3775, f3776, f3777, f3770, f3771, f3772, f3773, f3778, f3779, f3806, f3807, f3804, f3805, f3802, f3803, f3800, f3801, f3808, f3809, f3932, f3933, f3930, f3931, f3936, f3937, f3934, f3935, f3938, f3939, f4038, f4039, f3749, f3748, f4032, f4033, f4030, f4031, f4036, f4037, f4034, f4035, f3987, f3986, f3985, f3984, f3983, f3982, f3981, f3980, f3730, f3731, f3732, f3733, f3734, f3735, f3736, f3988, f3740, f3848, f3849, f3842, f3843, f3840, f3841, f3846, f3847, f3844, f3845",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-711efc61d8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_submit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xgb_managerid.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-357-6be0fd507f85>\u001b[0m in \u001b[0;36mget_submit_data\u001b[0;34m(param, train_x, train_y, test_df, num_rounds)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'param: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mout_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mout_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"high\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"low\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-355-ce13a094d31d>\u001b[0m in \u001b[0;36mrunXGB\u001b[0;34m(param, train_X, train_y, test_X, test_y, feature_names, num_rounds)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpred_test_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0moption_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;36m0x02\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1193\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874', 'f875', 'f876', 'f877', 'f878', 'f879', 'f880', 'f881', 'f882', 'f883', 'f884', 'f885', 'f886', 'f887', 'f888', 'f889', 'f890', 'f891', 'f892', 'f893', 'f894', 'f895', 'f896', 'f897', 'f898', 'f899', 'f900', 'f901', 'f902', 'f903', 'f904', 'f905', 'f906', 'f907', 'f908', 'f909', 'f910', 'f911', 'f912', 'f913', 'f914', 'f915', 'f916', 'f917', 'f918', 'f919', 'f920', 'f921', 'f922', 'f923', 'f924', 'f925', 'f926', 'f927', 'f928', 'f929', 'f930', 'f931', 'f932', 'f933', 'f934', 'f935', 'f936', 'f937', 'f938', 'f939', 'f940', 'f941', 'f942', 'f943', 'f944', 'f945', 'f946', 'f947', 'f948', 'f949', 'f950', 'f951', 'f952', 'f953', 'f954', 'f955', 'f956', 'f957', 'f958', 'f959', 'f960', 'f961', 'f962', 'f963', 'f964', 'f965', 'f966', 'f967', 'f968', 'f969', 'f970', 'f971', 'f972', 'f973', 'f974', 'f975', 'f976', 'f977', 'f978', 'f979', 'f980', 'f981', 'f982', 'f983', 'f984', 'f985', 'f986', 'f987', 'f988', 'f989', 'f990', 'f991', 'f992', 'f993', 'f994', 'f995', 'f996', 'f997', 'f998', 'f999', 'f1000', 'f1001', 'f1002', 'f1003', 'f1004', 'f1005', 'f1006', 'f1007', 'f1008', 'f1009', 'f1010', 'f1011', 'f1012', 'f1013', 'f1014', 'f1015', 'f1016', 'f1017', 'f1018', 'f1019', 'f1020', 'f1021', 'f1022', 'f1023', 'f1024', 'f1025', 'f1026', 'f1027', 'f1028', 'f1029', 'f1030', 'f1031', 'f1032', 'f1033', 'f1034', 'f1035', 'f1036', 'f1037', 'f1038', 'f1039', 'f1040', 'f1041', 'f1042', 'f1043', 'f1044', 'f1045', 'f1046', 'f1047', 'f1048', 'f1049', 'f1050', 'f1051', 'f1052', 'f1053', 'f1054', 'f1055', 'f1056', 'f1057', 'f1058', 'f1059', 'f1060', 'f1061', 'f1062', 'f1063', 'f1064', 'f1065', 'f1066', 'f1067', 'f1068', 'f1069', 'f1070', 'f1071', 'f1072', 'f1073', 'f1074', 'f1075', 'f1076', 'f1077', 'f1078', 'f1079', 'f1080', 'f1081', 'f1082', 'f1083', 'f1084', 'f1085', 'f1086', 'f1087', 'f1088', 'f1089', 'f1090', 'f1091', 'f1092', 'f1093', 'f1094', 'f1095', 'f1096', 'f1097', 'f1098', 'f1099', 'f1100', 'f1101', 'f1102', 'f1103', 'f1104', 'f1105', 'f1106', 'f1107', 'f1108', 'f1109', 'f1110', 'f1111', 'f1112', 'f1113', 'f1114', 'f1115', 'f1116', 'f1117', 'f1118', 'f1119', 'f1120', 'f1121', 'f1122', 'f1123', 'f1124', 'f1125', 'f1126', 'f1127', 'f1128', 'f1129', 'f1130', 'f1131', 'f1132', 'f1133', 'f1134', 'f1135', 'f1136', 'f1137', 'f1138', 'f1139', 'f1140', 'f1141', 'f1142', 'f1143', 'f1144', 'f1145', 'f1146', 'f1147', 'f1148', 'f1149', 'f1150', 'f1151', 'f1152', 'f1153', 'f1154', 'f1155', 'f1156', 'f1157', 'f1158', 'f1159', 'f1160', 'f1161', 'f1162', 'f1163', 'f1164', 'f1165', 'f1166', 'f1167', 'f1168', 'f1169', 'f1170', 'f1171', 'f1172', 'f1173', 'f1174', 'f1175', 'f1176', 'f1177', 'f1178', 'f1179', 'f1180', 'f1181', 'f1182', 'f1183', 'f1184', 'f1185', 'f1186', 'f1187', 'f1188', 'f1189', 'f1190', 'f1191', 'f1192', 'f1193', 'f1194', 'f1195', 'f1196', 'f1197', 'f1198', 'f1199', 'f1200', 'f1201', 'f1202', 'f1203', 'f1204', 'f1205', 'f1206', 'f1207', 'f1208', 'f1209', 'f1210', 'f1211', 'f1212', 'f1213', 'f1214', 'f1215', 'f1216', 'f1217', 'f1218', 'f1219', 'f1220', 'f1221', 'f1222', 'f1223', 'f1224', 'f1225', 'f1226', 'f1227', 'f1228', 'f1229', 'f1230', 'f1231', 'f1232', 'f1233', 'f1234', 'f1235', 'f1236', 'f1237', 'f1238', 'f1239', 'f1240', 'f1241', 'f1242', 'f1243', 'f1244', 'f1245', 'f1246', 'f1247', 'f1248', 'f1249', 'f1250', 'f1251', 'f1252', 'f1253', 'f1254', 'f1255', 'f1256', 'f1257', 'f1258', 'f1259', 'f1260', 'f1261', 'f1262', 'f1263', 'f1264', 'f1265', 'f1266', 'f1267', 'f1268', 'f1269', 'f1270', 'f1271', 'f1272', 'f1273', 'f1274', 'f1275', 'f1276', 'f1277', 'f1278', 'f1279', 'f1280', 'f1281', 'f1282', 'f1283', 'f1284', 'f1285', 'f1286', 'f1287', 'f1288', 'f1289', 'f1290', 'f1291', 'f1292', 'f1293', 'f1294', 'f1295', 'f1296', 'f1297', 'f1298', 'f1299', 'f1300', 'f1301', 'f1302', 'f1303', 'f1304', 'f1305', 'f1306', 'f1307', 'f1308', 'f1309', 'f1310', 'f1311', 'f1312', 'f1313', 'f1314', 'f1315', 'f1316', 'f1317', 'f1318', 'f1319', 'f1320', 'f1321', 'f1322', 'f1323', 'f1324', 'f1325', 'f1326', 'f1327', 'f1328', 'f1329', 'f1330', 'f1331', 'f1332', 'f1333', 'f1334', 'f1335', 'f1336', 'f1337', 'f1338', 'f1339', 'f1340', 'f1341', 'f1342', 'f1343', 'f1344', 'f1345', 'f1346', 'f1347', 'f1348', 'f1349', 'f1350', 'f1351', 'f1352', 'f1353', 'f1354', 'f1355', 'f1356', 'f1357', 'f1358', 'f1359', 'f1360', 'f1361', 'f1362', 'f1363', 'f1364', 'f1365', 'f1366', 'f1367', 'f1368', 'f1369', 'f1370', 'f1371', 'f1372', 'f1373', 'f1374', 'f1375', 'f1376', 'f1377', 'f1378', 'f1379', 'f1380', 'f1381', 'f1382', 'f1383', 'f1384', 'f1385', 'f1386', 'f1387', 'f1388', 'f1389', 'f1390', 'f1391', 'f1392', 'f1393', 'f1394', 'f1395', 'f1396', 'f1397', 'f1398', 'f1399', 'f1400', 'f1401', 'f1402', 'f1403', 'f1404', 'f1405', 'f1406', 'f1407', 'f1408', 'f1409', 'f1410', 'f1411', 'f1412', 'f1413', 'f1414', 'f1415', 'f1416', 'f1417', 'f1418', 'f1419', 'f1420', 'f1421', 'f1422', 'f1423', 'f1424', 'f1425', 'f1426', 'f1427', 'f1428', 'f1429', 'f1430', 'f1431', 'f1432', 'f1433', 'f1434', 'f1435', 'f1436', 'f1437', 'f1438', 'f1439', 'f1440', 'f1441', 'f1442', 'f1443', 'f1444', 'f1445', 'f1446', 'f1447', 'f1448', 'f1449', 'f1450', 'f1451', 'f1452', 'f1453', 'f1454', 'f1455', 'f1456', 'f1457', 'f1458', 'f1459', 'f1460', 'f1461', 'f1462', 'f1463', 'f1464', 'f1465', 'f1466', 'f1467', 'f1468', 'f1469', 'f1470', 'f1471', 'f1472', 'f1473', 'f1474', 'f1475', 'f1476', 'f1477', 'f1478', 'f1479', 'f1480', 'f1481', 'f1482', 'f1483', 'f1484', 'f1485', 'f1486', 'f1487', 'f1488', 'f1489', 'f1490', 'f1491', 'f1492', 'f1493', 'f1494', 'f1495', 'f1496', 'f1497', 'f1498', 'f1499', 'f1500', 'f1501', 'f1502', 'f1503', 'f1504', 'f1505', 'f1506', 'f1507', 'f1508', 'f1509', 'f1510', 'f1511', 'f1512', 'f1513', 'f1514', 'f1515', 'f1516', 'f1517', 'f1518', 'f1519', 'f1520', 'f1521', 'f1522', 'f1523', 'f1524', 'f1525', 'f1526', 'f1527', 'f1528', 'f1529', 'f1530', 'f1531', 'f1532', 'f1533', 'f1534', 'f1535', 'f1536', 'f1537', 'f1538', 'f1539', 'f1540', 'f1541', 'f1542', 'f1543', 'f1544', 'f1545', 'f1546', 'f1547', 'f1548', 'f1549', 'f1550', 'f1551', 'f1552', 'f1553', 'f1554', 'f1555', 'f1556', 'f1557', 'f1558', 'f1559', 'f1560', 'f1561', 'f1562', 'f1563', 'f1564', 'f1565', 'f1566', 'f1567', 'f1568', 'f1569', 'f1570', 'f1571', 'f1572', 'f1573', 'f1574', 'f1575', 'f1576', 'f1577', 'f1578', 'f1579', 'f1580', 'f1581', 'f1582', 'f1583', 'f1584', 'f1585', 'f1586', 'f1587', 'f1588', 'f1589', 'f1590', 'f1591', 'f1592', 'f1593', 'f1594', 'f1595', 'f1596', 'f1597', 'f1598', 'f1599', 'f1600', 'f1601', 'f1602', 'f1603', 'f1604', 'f1605', 'f1606', 'f1607', 'f1608', 'f1609', 'f1610', 'f1611', 'f1612', 'f1613', 'f1614', 'f1615', 'f1616', 'f1617', 'f1618', 'f1619', 'f1620', 'f1621', 'f1622', 'f1623', 'f1624', 'f1625', 'f1626', 'f1627', 'f1628', 'f1629', 'f1630', 'f1631', 'f1632', 'f1633', 'f1634', 'f1635', 'f1636', 'f1637', 'f1638', 'f1639', 'f1640', 'f1641', 'f1642', 'f1643', 'f1644', 'f1645', 'f1646', 'f1647', 'f1648', 'f1649', 'f1650', 'f1651', 'f1652', 'f1653', 'f1654', 'f1655', 'f1656', 'f1657', 'f1658', 'f1659', 'f1660', 'f1661', 'f1662', 'f1663', 'f1664', 'f1665', 'f1666', 'f1667', 'f1668', 'f1669', 'f1670', 'f1671', 'f1672', 'f1673', 'f1674', 'f1675', 'f1676', 'f1677', 'f1678', 'f1679', 'f1680', 'f1681', 'f1682', 'f1683', 'f1684', 'f1685', 'f1686', 'f1687', 'f1688', 'f1689', 'f1690', 'f1691', 'f1692', 'f1693', 'f1694', 'f1695', 'f1696', 'f1697', 'f1698', 'f1699', 'f1700', 'f1701', 'f1702', 'f1703', 'f1704', 'f1705', 'f1706', 'f1707', 'f1708', 'f1709', 'f1710', 'f1711', 'f1712', 'f1713', 'f1714', 'f1715', 'f1716', 'f1717', 'f1718', 'f1719', 'f1720', 'f1721', 'f1722', 'f1723', 'f1724', 'f1725', 'f1726', 'f1727', 'f1728', 'f1729', 'f1730', 'f1731', 'f1732', 'f1733', 'f1734', 'f1735', 'f1736', 'f1737', 'f1738', 'f1739', 'f1740', 'f1741', 'f1742', 'f1743', 'f1744', 'f1745', 'f1746', 'f1747', 'f1748', 'f1749', 'f1750', 'f1751', 'f1752', 'f1753', 'f1754', 'f1755', 'f1756', 'f1757', 'f1758', 'f1759', 'f1760', 'f1761', 'f1762', 'f1763', 'f1764', 'f1765', 'f1766', 'f1767', 'f1768', 'f1769', 'f1770', 'f1771', 'f1772', 'f1773', 'f1774', 'f1775', 'f1776', 'f1777', 'f1778', 'f1779', 'f1780', 'f1781', 'f1782', 'f1783', 'f1784', 'f1785', 'f1786', 'f1787', 'f1788', 'f1789', 'f1790', 'f1791', 'f1792', 'f1793', 'f1794', 'f1795', 'f1796', 'f1797', 'f1798', 'f1799', 'f1800', 'f1801', 'f1802', 'f1803', 'f1804', 'f1805', 'f1806', 'f1807', 'f1808', 'f1809', 'f1810', 'f1811', 'f1812', 'f1813', 'f1814', 'f1815', 'f1816', 'f1817', 'f1818', 'f1819', 'f1820', 'f1821', 'f1822', 'f1823', 'f1824', 'f1825', 'f1826', 'f1827', 'f1828', 'f1829', 'f1830', 'f1831', 'f1832', 'f1833', 'f1834', 'f1835', 'f1836', 'f1837', 'f1838', 'f1839', 'f1840', 'f1841', 'f1842', 'f1843', 'f1844', 'f1845', 'f1846', 'f1847', 'f1848', 'f1849', 'f1850', 'f1851', 'f1852', 'f1853', 'f1854', 'f1855', 'f1856', 'f1857', 'f1858', 'f1859', 'f1860', 'f1861', 'f1862', 'f1863', 'f1864', 'f1865', 'f1866', 'f1867', 'f1868', 'f1869', 'f1870', 'f1871', 'f1872', 'f1873', 'f1874', 'f1875', 'f1876', 'f1877', 'f1878', 'f1879', 'f1880', 'f1881', 'f1882', 'f1883', 'f1884', 'f1885', 'f1886', 'f1887', 'f1888', 'f1889', 'f1890', 'f1891', 'f1892', 'f1893', 'f1894', 'f1895', 'f1896', 'f1897', 'f1898', 'f1899', 'f1900', 'f1901', 'f1902', 'f1903', 'f1904', 'f1905', 'f1906', 'f1907', 'f1908', 'f1909', 'f1910', 'f1911', 'f1912', 'f1913', 'f1914', 'f1915', 'f1916', 'f1917', 'f1918', 'f1919', 'f1920', 'f1921', 'f1922', 'f1923', 'f1924', 'f1925', 'f1926', 'f1927', 'f1928', 'f1929', 'f1930', 'f1931', 'f1932', 'f1933', 'f1934', 'f1935', 'f1936', 'f1937', 'f1938', 'f1939', 'f1940', 'f1941', 'f1942', 'f1943', 'f1944', 'f1945', 'f1946', 'f1947', 'f1948', 'f1949', 'f1950', 'f1951', 'f1952', 'f1953', 'f1954', 'f1955', 'f1956', 'f1957', 'f1958', 'f1959', 'f1960', 'f1961', 'f1962', 'f1963', 'f1964', 'f1965', 'f1966', 'f1967', 'f1968', 'f1969', 'f1970', 'f1971', 'f1972', 'f1973', 'f1974', 'f1975', 'f1976', 'f1977', 'f1978', 'f1979', 'f1980', 'f1981', 'f1982', 'f1983', 'f1984', 'f1985', 'f1986', 'f1987', 'f1988', 'f1989', 'f1990', 'f1991', 'f1992', 'f1993', 'f1994', 'f1995', 'f1996', 'f1997', 'f1998', 'f1999', 'f2000', 'f2001', 'f2002', 'f2003', 'f2004', 'f2005', 'f2006', 'f2007', 'f2008', 'f2009', 'f2010', 'f2011', 'f2012', 'f2013', 'f2014', 'f2015', 'f2016', 'f2017', 'f2018', 'f2019', 'f2020', 'f2021', 'f2022', 'f2023', 'f2024', 'f2025', 'f2026', 'f2027', 'f2028', 'f2029', 'f2030', 'f2031', 'f2032', 'f2033', 'f2034', 'f2035', 'f2036', 'f2037', 'f2038', 'f2039', 'f2040', 'f2041', 'f2042', 'f2043', 'f2044', 'f2045', 'f2046', 'f2047', 'f2048', 'f2049', 'f2050', 'f2051', 'f2052', 'f2053', 'f2054', 'f2055', 'f2056', 'f2057', 'f2058', 'f2059', 'f2060', 'f2061', 'f2062', 'f2063', 'f2064', 'f2065', 'f2066', 'f2067', 'f2068', 'f2069', 'f2070', 'f2071', 'f2072', 'f2073', 'f2074', 'f2075', 'f2076', 'f2077', 'f2078', 'f2079', 'f2080', 'f2081', 'f2082', 'f2083', 'f2084', 'f2085', 'f2086', 'f2087', 'f2088', 'f2089', 'f2090', 'f2091', 'f2092', 'f2093', 'f2094', 'f2095', 'f2096', 'f2097', 'f2098', 'f2099', 'f2100', 'f2101', 'f2102', 'f2103', 'f2104', 'f2105', 'f2106', 'f2107', 'f2108', 'f2109', 'f2110', 'f2111', 'f2112', 'f2113', 'f2114', 'f2115', 'f2116', 'f2117', 'f2118', 'f2119', 'f2120', 'f2121', 'f2122', 'f2123', 'f2124', 'f2125', 'f2126', 'f2127', 'f2128', 'f2129', 'f2130', 'f2131', 'f2132', 'f2133', 'f2134', 'f2135', 'f2136', 'f2137', 'f2138', 'f2139', 'f2140', 'f2141', 'f2142', 'f2143', 'f2144', 'f2145', 'f2146', 'f2147', 'f2148', 'f2149', 'f2150', 'f2151', 'f2152', 'f2153', 'f2154', 'f2155', 'f2156', 'f2157', 'f2158', 'f2159', 'f2160', 'f2161', 'f2162', 'f2163', 'f2164', 'f2165', 'f2166', 'f2167', 'f2168', 'f2169', 'f2170', 'f2171', 'f2172', 'f2173', 'f2174', 'f2175', 'f2176', 'f2177', 'f2178', 'f2179', 'f2180', 'f2181', 'f2182', 'f2183', 'f2184', 'f2185', 'f2186', 'f2187', 'f2188', 'f2189', 'f2190', 'f2191', 'f2192', 'f2193', 'f2194', 'f2195', 'f2196', 'f2197', 'f2198', 'f2199', 'f2200', 'f2201', 'f2202', 'f2203', 'f2204', 'f2205', 'f2206', 'f2207', 'f2208', 'f2209', 'f2210', 'f2211', 'f2212', 'f2213', 'f2214', 'f2215', 'f2216', 'f2217', 'f2218', 'f2219', 'f2220', 'f2221', 'f2222', 'f2223', 'f2224', 'f2225', 'f2226', 'f2227', 'f2228', 'f2229', 'f2230', 'f2231', 'f2232', 'f2233', 'f2234', 'f2235', 'f2236', 'f2237', 'f2238', 'f2239', 'f2240', 'f2241', 'f2242', 'f2243', 'f2244', 'f2245', 'f2246', 'f2247', 'f2248', 'f2249', 'f2250', 'f2251', 'f2252', 'f2253', 'f2254', 'f2255', 'f2256', 'f2257', 'f2258', 'f2259', 'f2260', 'f2261', 'f2262', 'f2263', 'f2264', 'f2265', 'f2266', 'f2267', 'f2268', 'f2269', 'f2270', 'f2271', 'f2272', 'f2273', 'f2274', 'f2275', 'f2276', 'f2277', 'f2278', 'f2279', 'f2280', 'f2281', 'f2282', 'f2283', 'f2284', 'f2285', 'f2286', 'f2287', 'f2288', 'f2289', 'f2290', 'f2291', 'f2292', 'f2293', 'f2294', 'f2295', 'f2296', 'f2297', 'f2298', 'f2299', 'f2300', 'f2301', 'f2302', 'f2303', 'f2304', 'f2305', 'f2306', 'f2307', 'f2308', 'f2309', 'f2310', 'f2311', 'f2312', 'f2313', 'f2314', 'f2315', 'f2316', 'f2317', 'f2318', 'f2319', 'f2320', 'f2321', 'f2322', 'f2323', 'f2324', 'f2325', 'f2326', 'f2327', 'f2328', 'f2329', 'f2330', 'f2331', 'f2332', 'f2333', 'f2334', 'f2335', 'f2336', 'f2337', 'f2338', 'f2339', 'f2340', 'f2341', 'f2342', 'f2343', 'f2344', 'f2345', 'f2346', 'f2347', 'f2348', 'f2349', 'f2350', 'f2351', 'f2352', 'f2353', 'f2354', 'f2355', 'f2356', 'f2357', 'f2358', 'f2359', 'f2360', 'f2361', 'f2362', 'f2363', 'f2364', 'f2365', 'f2366', 'f2367', 'f2368', 'f2369', 'f2370', 'f2371', 'f2372', 'f2373', 'f2374', 'f2375', 'f2376', 'f2377', 'f2378', 'f2379', 'f2380', 'f2381', 'f2382', 'f2383', 'f2384', 'f2385', 'f2386', 'f2387', 'f2388', 'f2389', 'f2390', 'f2391', 'f2392', 'f2393', 'f2394', 'f2395', 'f2396', 'f2397', 'f2398', 'f2399', 'f2400', 'f2401', 'f2402', 'f2403', 'f2404', 'f2405', 'f2406', 'f2407', 'f2408', 'f2409', 'f2410', 'f2411', 'f2412', 'f2413', 'f2414', 'f2415', 'f2416', 'f2417', 'f2418', 'f2419', 'f2420', 'f2421', 'f2422', 'f2423', 'f2424', 'f2425', 'f2426', 'f2427', 'f2428', 'f2429', 'f2430', 'f2431', 'f2432', 'f2433', 'f2434', 'f2435', 'f2436', 'f2437', 'f2438', 'f2439', 'f2440', 'f2441', 'f2442', 'f2443', 'f2444', 'f2445', 'f2446', 'f2447', 'f2448', 'f2449', 'f2450', 'f2451', 'f2452', 'f2453', 'f2454', 'f2455', 'f2456', 'f2457', 'f2458', 'f2459', 'f2460', 'f2461', 'f2462', 'f2463', 'f2464', 'f2465', 'f2466', 'f2467', 'f2468', 'f2469', 'f2470', 'f2471', 'f2472', 'f2473', 'f2474', 'f2475', 'f2476', 'f2477', 'f2478', 'f2479', 'f2480', 'f2481', 'f2482', 'f2483', 'f2484', 'f2485', 'f2486', 'f2487', 'f2488', 'f2489', 'f2490', 'f2491', 'f2492', 'f2493', 'f2494', 'f2495', 'f2496', 'f2497', 'f2498', 'f2499', 'f2500', 'f2501', 'f2502', 'f2503', 'f2504', 'f2505', 'f2506', 'f2507', 'f2508', 'f2509', 'f2510', 'f2511', 'f2512', 'f2513', 'f2514', 'f2515', 'f2516', 'f2517', 'f2518', 'f2519', 'f2520', 'f2521', 'f2522', 'f2523', 'f2524', 'f2525', 'f2526', 'f2527', 'f2528', 'f2529', 'f2530', 'f2531', 'f2532', 'f2533', 'f2534', 'f2535', 'f2536', 'f2537', 'f2538', 'f2539', 'f2540', 'f2541', 'f2542', 'f2543', 'f2544', 'f2545', 'f2546', 'f2547', 'f2548', 'f2549', 'f2550', 'f2551', 'f2552', 'f2553', 'f2554', 'f2555', 'f2556', 'f2557', 'f2558', 'f2559', 'f2560', 'f2561', 'f2562', 'f2563', 'f2564', 'f2565', 'f2566', 'f2567', 'f2568', 'f2569', 'f2570', 'f2571', 'f2572', 'f2573', 'f2574', 'f2575', 'f2576', 'f2577', 'f2578', 'f2579', 'f2580', 'f2581', 'f2582', 'f2583', 'f2584', 'f2585', 'f2586', 'f2587', 'f2588', 'f2589', 'f2590', 'f2591', 'f2592', 'f2593', 'f2594', 'f2595', 'f2596', 'f2597', 'f2598', 'f2599', 'f2600', 'f2601', 'f2602', 'f2603', 'f2604', 'f2605', 'f2606', 'f2607', 'f2608', 'f2609', 'f2610', 'f2611', 'f2612', 'f2613', 'f2614', 'f2615', 'f2616', 'f2617', 'f2618', 'f2619', 'f2620', 'f2621', 'f2622', 'f2623', 'f2624', 'f2625', 'f2626', 'f2627', 'f2628', 'f2629', 'f2630', 'f2631', 'f2632', 'f2633', 'f2634', 'f2635', 'f2636', 'f2637', 'f2638', 'f2639', 'f2640', 'f2641', 'f2642', 'f2643', 'f2644', 'f2645', 'f2646', 'f2647', 'f2648', 'f2649', 'f2650', 'f2651', 'f2652', 'f2653', 'f2654', 'f2655', 'f2656', 'f2657', 'f2658', 'f2659', 'f2660', 'f2661', 'f2662', 'f2663', 'f2664', 'f2665', 'f2666', 'f2667', 'f2668', 'f2669', 'f2670', 'f2671', 'f2672', 'f2673', 'f2674', 'f2675', 'f2676', 'f2677', 'f2678', 'f2679', 'f2680', 'f2681', 'f2682', 'f2683', 'f2684', 'f2685', 'f2686', 'f2687', 'f2688', 'f2689', 'f2690', 'f2691', 'f2692', 'f2693', 'f2694', 'f2695', 'f2696', 'f2697', 'f2698', 'f2699', 'f2700', 'f2701', 'f2702', 'f2703', 'f2704', 'f2705', 'f2706', 'f2707', 'f2708', 'f2709', 'f2710', 'f2711', 'f2712', 'f2713', 'f2714', 'f2715', 'f2716', 'f2717', 'f2718', 'f2719', 'f2720', 'f2721', 'f2722', 'f2723', 'f2724', 'f2725', 'f2726', 'f2727', 'f2728', 'f2729', 'f2730', 'f2731', 'f2732', 'f2733', 'f2734', 'f2735', 'f2736', 'f2737', 'f2738', 'f2739', 'f2740', 'f2741', 'f2742', 'f2743', 'f2744', 'f2745', 'f2746', 'f2747', 'f2748', 'f2749', 'f2750', 'f2751', 'f2752', 'f2753', 'f2754', 'f2755', 'f2756', 'f2757', 'f2758', 'f2759', 'f2760', 'f2761', 'f2762', 'f2763', 'f2764', 'f2765', 'f2766', 'f2767', 'f2768', 'f2769', 'f2770', 'f2771', 'f2772', 'f2773', 'f2774', 'f2775', 'f2776', 'f2777', 'f2778', 'f2779', 'f2780', 'f2781', 'f2782', 'f2783', 'f2784', 'f2785', 'f2786', 'f2787', 'f2788', 'f2789', 'f2790', 'f2791', 'f2792', 'f2793', 'f2794', 'f2795', 'f2796', 'f2797', 'f2798', 'f2799', 'f2800', 'f2801', 'f2802', 'f2803', 'f2804', 'f2805', 'f2806', 'f2807', 'f2808', 'f2809', 'f2810', 'f2811', 'f2812', 'f2813', 'f2814', 'f2815', 'f2816', 'f2817', 'f2818', 'f2819', 'f2820', 'f2821', 'f2822', 'f2823', 'f2824', 'f2825', 'f2826', 'f2827', 'f2828', 'f2829', 'f2830', 'f2831', 'f2832', 'f2833', 'f2834', 'f2835', 'f2836', 'f2837', 'f2838', 'f2839', 'f2840', 'f2841', 'f2842', 'f2843', 'f2844', 'f2845', 'f2846', 'f2847', 'f2848', 'f2849', 'f2850', 'f2851', 'f2852', 'f2853', 'f2854', 'f2855', 'f2856', 'f2857', 'f2858', 'f2859', 'f2860', 'f2861', 'f2862', 'f2863', 'f2864', 'f2865', 'f2866', 'f2867', 'f2868', 'f2869', 'f2870', 'f2871', 'f2872', 'f2873', 'f2874', 'f2875', 'f2876', 'f2877', 'f2878', 'f2879', 'f2880', 'f2881', 'f2882', 'f2883', 'f2884', 'f2885', 'f2886', 'f2887', 'f2888', 'f2889', 'f2890', 'f2891', 'f2892', 'f2893', 'f2894', 'f2895', 'f2896', 'f2897', 'f2898', 'f2899', 'f2900', 'f2901', 'f2902', 'f2903', 'f2904', 'f2905', 'f2906', 'f2907', 'f2908', 'f2909', 'f2910', 'f2911', 'f2912', 'f2913', 'f2914', 'f2915', 'f2916', 'f2917', 'f2918', 'f2919', 'f2920', 'f2921', 'f2922', 'f2923', 'f2924', 'f2925', 'f2926', 'f2927', 'f2928', 'f2929', 'f2930', 'f2931', 'f2932', 'f2933', 'f2934', 'f2935', 'f2936', 'f2937', 'f2938', 'f2939', 'f2940', 'f2941', 'f2942', 'f2943', 'f2944', 'f2945', 'f2946', 'f2947', 'f2948', 'f2949', 'f2950', 'f2951', 'f2952', 'f2953', 'f2954', 'f2955', 'f2956', 'f2957', 'f2958', 'f2959', 'f2960', 'f2961', 'f2962', 'f2963', 'f2964', 'f2965', 'f2966', 'f2967', 'f2968', 'f2969', 'f2970', 'f2971', 'f2972', 'f2973', 'f2974', 'f2975', 'f2976', 'f2977', 'f2978', 'f2979', 'f2980', 'f2981', 'f2982', 'f2983', 'f2984', 'f2985', 'f2986', 'f2987', 'f2988', 'f2989', 'f2990', 'f2991', 'f2992', 'f2993', 'f2994', 'f2995', 'f2996', 'f2997', 'f2998', 'f2999', 'f3000', 'f3001', 'f3002', 'f3003', 'f3004', 'f3005', 'f3006', 'f3007', 'f3008', 'f3009', 'f3010', 'f3011', 'f3012', 'f3013', 'f3014', 'f3015', 'f3016', 'f3017', 'f3018', 'f3019', 'f3020', 'f3021', 'f3022', 'f3023', 'f3024', 'f3025', 'f3026', 'f3027', 'f3028', 'f3029', 'f3030', 'f3031', 'f3032', 'f3033', 'f3034', 'f3035', 'f3036', 'f3037', 'f3038', 'f3039', 'f3040', 'f3041', 'f3042', 'f3043', 'f3044', 'f3045', 'f3046', 'f3047', 'f3048', 'f3049', 'f3050', 'f3051', 'f3052', 'f3053', 'f3054', 'f3055', 'f3056', 'f3057', 'f3058', 'f3059', 'f3060', 'f3061', 'f3062', 'f3063', 'f3064', 'f3065', 'f3066', 'f3067', 'f3068', 'f3069', 'f3070', 'f3071', 'f3072', 'f3073', 'f3074', 'f3075', 'f3076', 'f3077', 'f3078', 'f3079', 'f3080', 'f3081', 'f3082', 'f3083', 'f3084', 'f3085', 'f3086', 'f3087', 'f3088', 'f3089', 'f3090', 'f3091', 'f3092', 'f3093', 'f3094', 'f3095', 'f3096', 'f3097', 'f3098', 'f3099', 'f3100', 'f3101', 'f3102', 'f3103', 'f3104', 'f3105', 'f3106', 'f3107', 'f3108', 'f3109', 'f3110', 'f3111', 'f3112', 'f3113', 'f3114', 'f3115', 'f3116', 'f3117', 'f3118', 'f3119', 'f3120', 'f3121', 'f3122', 'f3123', 'f3124', 'f3125', 'f3126', 'f3127', 'f3128', 'f3129', 'f3130', 'f3131', 'f3132', 'f3133', 'f3134', 'f3135', 'f3136', 'f3137', 'f3138', 'f3139', 'f3140', 'f3141', 'f3142', 'f3143', 'f3144', 'f3145', 'f3146', 'f3147', 'f3148', 'f3149', 'f3150', 'f3151', 'f3152', 'f3153', 'f3154', 'f3155', 'f3156', 'f3157', 'f3158', 'f3159', 'f3160', 'f3161', 'f3162', 'f3163', 'f3164', 'f3165', 'f3166', 'f3167', 'f3168', 'f3169', 'f3170', 'f3171', 'f3172', 'f3173', 'f3174', 'f3175', 'f3176', 'f3177', 'f3178', 'f3179', 'f3180', 'f3181', 'f3182', 'f3183', 'f3184', 'f3185', 'f3186', 'f3187', 'f3188', 'f3189', 'f3190', 'f3191', 'f3192', 'f3193', 'f3194', 'f3195', 'f3196', 'f3197', 'f3198', 'f3199', 'f3200', 'f3201', 'f3202', 'f3203', 'f3204', 'f3205', 'f3206', 'f3207', 'f3208', 'f3209', 'f3210', 'f3211', 'f3212', 'f3213', 'f3214', 'f3215', 'f3216', 'f3217', 'f3218', 'f3219', 'f3220', 'f3221', 'f3222', 'f3223', 'f3224', 'f3225', 'f3226', 'f3227', 'f3228', 'f3229', 'f3230', 'f3231', 'f3232', 'f3233', 'f3234', 'f3235', 'f3236', 'f3237', 'f3238', 'f3239', 'f3240', 'f3241', 'f3242', 'f3243', 'f3244', 'f3245', 'f3246', 'f3247', 'f3248', 'f3249', 'f3250', 'f3251', 'f3252', 'f3253', 'f3254', 'f3255', 'f3256', 'f3257', 'f3258', 'f3259', 'f3260', 'f3261', 'f3262', 'f3263', 'f3264', 'f3265', 'f3266', 'f3267', 'f3268', 'f3269', 'f3270', 'f3271', 'f3272', 'f3273', 'f3274', 'f3275', 'f3276', 'f3277', 'f3278', 'f3279', 'f3280', 'f3281', 'f3282', 'f3283', 'f3284', 'f3285', 'f3286', 'f3287', 'f3288', 'f3289', 'f3290', 'f3291', 'f3292', 'f3293', 'f3294', 'f3295', 'f3296', 'f3297', 'f3298', 'f3299', 'f3300', 'f3301', 'f3302', 'f3303', 'f3304', 'f3305', 'f3306', 'f3307', 'f3308', 'f3309', 'f3310', 'f3311', 'f3312', 'f3313', 'f3314', 'f3315', 'f3316', 'f3317', 'f3318', 'f3319', 'f3320', 'f3321', 'f3322', 'f3323', 'f3324', 'f3325', 'f3326', 'f3327', 'f3328', 'f3329', 'f3330', 'f3331', 'f3332', 'f3333', 'f3334', 'f3335', 'f3336', 'f3337', 'f3338', 'f3339', 'f3340', 'f3341', 'f3342', 'f3343', 'f3344', 'f3345', 'f3346', 'f3347', 'f3348', 'f3349', 'f3350', 'f3351', 'f3352', 'f3353', 'f3354', 'f3355', 'f3356', 'f3357', 'f3358', 'f3359', 'f3360', 'f3361', 'f3362', 'f3363', 'f3364', 'f3365', 'f3366', 'f3367', 'f3368', 'f3369', 'f3370', 'f3371', 'f3372', 'f3373', 'f3374', 'f3375', 'f3376', 'f3377', 'f3378', 'f3379', 'f3380', 'f3381', 'f3382', 'f3383', 'f3384', 'f3385', 'f3386', 'f3387', 'f3388', 'f3389', 'f3390', 'f3391', 'f3392', 'f3393', 'f3394', 'f3395', 'f3396', 'f3397', 'f3398', 'f3399', 'f3400', 'f3401', 'f3402', 'f3403', 'f3404', 'f3405', 'f3406', 'f3407', 'f3408', 'f3409', 'f3410', 'f3411', 'f3412', 'f3413', 'f3414', 'f3415', 'f3416', 'f3417', 'f3418', 'f3419', 'f3420', 'f3421', 'f3422', 'f3423', 'f3424', 'f3425', 'f3426', 'f3427', 'f3428', 'f3429', 'f3430', 'f3431', 'f3432', 'f3433', 'f3434', 'f3435', 'f3436', 'f3437', 'f3438', 'f3439', 'f3440', 'f3441', 'f3442', 'f3443', 'f3444', 'f3445', 'f3446', 'f3447', 'f3448', 'f3449', 'f3450', 'f3451', 'f3452', 'f3453', 'f3454', 'f3455', 'f3456', 'f3457', 'f3458', 'f3459', 'f3460', 'f3461', 'f3462', 'f3463', 'f3464', 'f3465', 'f3466', 'f3467', 'f3468', 'f3469', 'f3470', 'f3471', 'f3472', 'f3473', 'f3474', 'f3475', 'f3476', 'f3477', 'f3478', 'f3479', 'f3480', 'f3481', 'f3482', 'f3483', 'f3484', 'f3485', 'f3486', 'f3487', 'f3488', 'f3489', 'f3490', 'f3491', 'f3492', 'f3493', 'f3494', 'f3495', 'f3496', 'f3497', 'f3498', 'f3499', 'f3500', 'f3501', 'f3502', 'f3503', 'f3504', 'f3505', 'f3506', 'f3507', 'f3508', 'f3509', 'f3510', 'f3511', 'f3512', 'f3513', 'f3514', 'f3515', 'f3516', 'f3517', 'f3518', 'f3519', 'f3520', 'f3521', 'f3522', 'f3523', 'f3524', 'f3525', 'f3526', 'f3527', 'f3528', 'f3529', 'f3530', 'f3531', 'f3532', 'f3533', 'f3534', 'f3535', 'f3536', 'f3537', 'f3538', 'f3539', 'f3540', 'f3541', 'f3542', 'f3543', 'f3544', 'f3545', 'f3546', 'f3547', 'f3548', 'f3549', 'f3550', 'f3551', 'f3552', 'f3553', 'f3554', 'f3555', 'f3556', 'f3557', 'f3558', 'f3559', 'f3560', 'f3561', 'f3562', 'f3563', 'f3564', 'f3565', 'f3566', 'f3567', 'f3568', 'f3569', 'f3570', 'f3571', 'f3572', 'f3573', 'f3574', 'f3575', 'f3576', 'f3577', 'f3578', 'f3579', 'f3580', 'f3581', 'f3582', 'f3583', 'f3584', 'f3585', 'f3586', 'f3587', 'f3588', 'f3589', 'f3590', 'f3591', 'f3592', 'f3593', 'f3594', 'f3595', 'f3596', 'f3597', 'f3598', 'f3599', 'f3600', 'f3601', 'f3602', 'f3603', 'f3604', 'f3605', 'f3606', 'f3607', 'f3608', 'f3609', 'f3610', 'f3611', 'f3612', 'f3613', 'f3614', 'f3615', 'f3616', 'f3617', 'f3618', 'f3619', 'f3620', 'f3621', 'f3622', 'f3623', 'f3624', 'f3625', 'f3626', 'f3627', 'f3628', 'f3629', 'f3630', 'f3631', 'f3632', 'f3633', 'f3634', 'f3635', 'f3636', 'f3637', 'f3638', 'f3639', 'f3640', 'f3641', 'f3642', 'f3643', 'f3644', 'f3645', 'f3646', 'f3647', 'f3648', 'f3649', 'f3650', 'f3651', 'f3652', 'f3653', 'f3654', 'f3655', 'f3656', 'f3657', 'f3658', 'f3659', 'f3660', 'f3661', 'f3662', 'f3663', 'f3664', 'f3665', 'f3666', 'f3667', 'f3668', 'f3669', 'f3670', 'f3671', 'f3672', 'f3673', 'f3674', 'f3675', 'f3676', 'f3677', 'f3678', 'f3679', 'f3680', 'f3681', 'f3682', 'f3683', 'f3684', 'f3685', 'f3686', 'f3687', 'f3688', 'f3689', 'f3690', 'f3691', 'f3692', 'f3693', 'f3694', 'f3695', 'f3696', 'f3697', 'f3698', 'f3699', 'f3700', 'f3701', 'f3702', 'f3703', 'f3704', 'f3705', 'f3706', 'f3707', 'f3708', 'f3709', 'f3710', 'f3711', 'f3712', 'f3713', 'f3714', 'f3715', 'f3716', 'f3717', 'f3718'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874', 'f875', 'f876', 'f877', 'f878', 'f879', 'f880', 'f881', 'f882', 'f883', 'f884', 'f885', 'f886', 'f887', 'f888', 'f889', 'f890', 'f891', 'f892', 'f893', 'f894', 'f895', 'f896', 'f897', 'f898', 'f899', 'f900', 'f901', 'f902', 'f903', 'f904', 'f905', 'f906', 'f907', 'f908', 'f909', 'f910', 'f911', 'f912', 'f913', 'f914', 'f915', 'f916', 'f917', 'f918', 'f919', 'f920', 'f921', 'f922', 'f923', 'f924', 'f925', 'f926', 'f927', 'f928', 'f929', 'f930', 'f931', 'f932', 'f933', 'f934', 'f935', 'f936', 'f937', 'f938', 'f939', 'f940', 'f941', 'f942', 'f943', 'f944', 'f945', 'f946', 'f947', 'f948', 'f949', 'f950', 'f951', 'f952', 'f953', 'f954', 'f955', 'f956', 'f957', 'f958', 'f959', 'f960', 'f961', 'f962', 'f963', 'f964', 'f965', 'f966', 'f967', 'f968', 'f969', 'f970', 'f971', 'f972', 'f973', 'f974', 'f975', 'f976', 'f977', 'f978', 'f979', 'f980', 'f981', 'f982', 'f983', 'f984', 'f985', 'f986', 'f987', 'f988', 'f989', 'f990', 'f991', 'f992', 'f993', 'f994', 'f995', 'f996', 'f997', 'f998', 'f999', 'f1000', 'f1001', 'f1002', 'f1003', 'f1004', 'f1005', 'f1006', 'f1007', 'f1008', 'f1009', 'f1010', 'f1011', 'f1012', 'f1013', 'f1014', 'f1015', 'f1016', 'f1017', 'f1018', 'f1019', 'f1020', 'f1021', 'f1022', 'f1023', 'f1024', 'f1025', 'f1026', 'f1027', 'f1028', 'f1029', 'f1030', 'f1031', 'f1032', 'f1033', 'f1034', 'f1035', 'f1036', 'f1037', 'f1038', 'f1039', 'f1040', 'f1041', 'f1042', 'f1043', 'f1044', 'f1045', 'f1046', 'f1047', 'f1048', 'f1049', 'f1050', 'f1051', 'f1052', 'f1053', 'f1054', 'f1055', 'f1056', 'f1057', 'f1058', 'f1059', 'f1060', 'f1061', 'f1062', 'f1063', 'f1064', 'f1065', 'f1066', 'f1067', 'f1068', 'f1069', 'f1070', 'f1071', 'f1072', 'f1073', 'f1074', 'f1075', 'f1076', 'f1077', 'f1078', 'f1079', 'f1080', 'f1081', 'f1082', 'f1083', 'f1084', 'f1085', 'f1086', 'f1087', 'f1088', 'f1089', 'f1090', 'f1091', 'f1092', 'f1093', 'f1094', 'f1095', 'f1096', 'f1097', 'f1098', 'f1099', 'f1100', 'f1101', 'f1102', 'f1103', 'f1104', 'f1105', 'f1106', 'f1107', 'f1108', 'f1109', 'f1110', 'f1111', 'f1112', 'f1113', 'f1114', 'f1115', 'f1116', 'f1117', 'f1118', 'f1119', 'f1120', 'f1121', 'f1122', 'f1123', 'f1124', 'f1125', 'f1126', 'f1127', 'f1128', 'f1129', 'f1130', 'f1131', 'f1132', 'f1133', 'f1134', 'f1135', 'f1136', 'f1137', 'f1138', 'f1139', 'f1140', 'f1141', 'f1142', 'f1143', 'f1144', 'f1145', 'f1146', 'f1147', 'f1148', 'f1149', 'f1150', 'f1151', 'f1152', 'f1153', 'f1154', 'f1155', 'f1156', 'f1157', 'f1158', 'f1159', 'f1160', 'f1161', 'f1162', 'f1163', 'f1164', 'f1165', 'f1166', 'f1167', 'f1168', 'f1169', 'f1170', 'f1171', 'f1172', 'f1173', 'f1174', 'f1175', 'f1176', 'f1177', 'f1178', 'f1179', 'f1180', 'f1181', 'f1182', 'f1183', 'f1184', 'f1185', 'f1186', 'f1187', 'f1188', 'f1189', 'f1190', 'f1191', 'f1192', 'f1193', 'f1194', 'f1195', 'f1196', 'f1197', 'f1198', 'f1199', 'f1200', 'f1201', 'f1202', 'f1203', 'f1204', 'f1205', 'f1206', 'f1207', 'f1208', 'f1209', 'f1210', 'f1211', 'f1212', 'f1213', 'f1214', 'f1215', 'f1216', 'f1217', 'f1218', 'f1219', 'f1220', 'f1221', 'f1222', 'f1223', 'f1224', 'f1225', 'f1226', 'f1227', 'f1228', 'f1229', 'f1230', 'f1231', 'f1232', 'f1233', 'f1234', 'f1235', 'f1236', 'f1237', 'f1238', 'f1239', 'f1240', 'f1241', 'f1242', 'f1243', 'f1244', 'f1245', 'f1246', 'f1247', 'f1248', 'f1249', 'f1250', 'f1251', 'f1252', 'f1253', 'f1254', 'f1255', 'f1256', 'f1257', 'f1258', 'f1259', 'f1260', 'f1261', 'f1262', 'f1263', 'f1264', 'f1265', 'f1266', 'f1267', 'f1268', 'f1269', 'f1270', 'f1271', 'f1272', 'f1273', 'f1274', 'f1275', 'f1276', 'f1277', 'f1278', 'f1279', 'f1280', 'f1281', 'f1282', 'f1283', 'f1284', 'f1285', 'f1286', 'f1287', 'f1288', 'f1289', 'f1290', 'f1291', 'f1292', 'f1293', 'f1294', 'f1295', 'f1296', 'f1297', 'f1298', 'f1299', 'f1300', 'f1301', 'f1302', 'f1303', 'f1304', 'f1305', 'f1306', 'f1307', 'f1308', 'f1309', 'f1310', 'f1311', 'f1312', 'f1313', 'f1314', 'f1315', 'f1316', 'f1317', 'f1318', 'f1319', 'f1320', 'f1321', 'f1322', 'f1323', 'f1324', 'f1325', 'f1326', 'f1327', 'f1328', 'f1329', 'f1330', 'f1331', 'f1332', 'f1333', 'f1334', 'f1335', 'f1336', 'f1337', 'f1338', 'f1339', 'f1340', 'f1341', 'f1342', 'f1343', 'f1344', 'f1345', 'f1346', 'f1347', 'f1348', 'f1349', 'f1350', 'f1351', 'f1352', 'f1353', 'f1354', 'f1355', 'f1356', 'f1357', 'f1358', 'f1359', 'f1360', 'f1361', 'f1362', 'f1363', 'f1364', 'f1365', 'f1366', 'f1367', 'f1368', 'f1369', 'f1370', 'f1371', 'f1372', 'f1373', 'f1374', 'f1375', 'f1376', 'f1377', 'f1378', 'f1379', 'f1380', 'f1381', 'f1382', 'f1383', 'f1384', 'f1385', 'f1386', 'f1387', 'f1388', 'f1389', 'f1390', 'f1391', 'f1392', 'f1393', 'f1394', 'f1395', 'f1396', 'f1397', 'f1398', 'f1399', 'f1400', 'f1401', 'f1402', 'f1403', 'f1404', 'f1405', 'f1406', 'f1407', 'f1408', 'f1409', 'f1410', 'f1411', 'f1412', 'f1413', 'f1414', 'f1415', 'f1416', 'f1417', 'f1418', 'f1419', 'f1420', 'f1421', 'f1422', 'f1423', 'f1424', 'f1425', 'f1426', 'f1427', 'f1428', 'f1429', 'f1430', 'f1431', 'f1432', 'f1433', 'f1434', 'f1435', 'f1436', 'f1437', 'f1438', 'f1439', 'f1440', 'f1441', 'f1442', 'f1443', 'f1444', 'f1445', 'f1446', 'f1447', 'f1448', 'f1449', 'f1450', 'f1451', 'f1452', 'f1453', 'f1454', 'f1455', 'f1456', 'f1457', 'f1458', 'f1459', 'f1460', 'f1461', 'f1462', 'f1463', 'f1464', 'f1465', 'f1466', 'f1467', 'f1468', 'f1469', 'f1470', 'f1471', 'f1472', 'f1473', 'f1474', 'f1475', 'f1476', 'f1477', 'f1478', 'f1479', 'f1480', 'f1481', 'f1482', 'f1483', 'f1484', 'f1485', 'f1486', 'f1487', 'f1488', 'f1489', 'f1490', 'f1491', 'f1492', 'f1493', 'f1494', 'f1495', 'f1496', 'f1497', 'f1498', 'f1499', 'f1500', 'f1501', 'f1502', 'f1503', 'f1504', 'f1505', 'f1506', 'f1507', 'f1508', 'f1509', 'f1510', 'f1511', 'f1512', 'f1513', 'f1514', 'f1515', 'f1516', 'f1517', 'f1518', 'f1519', 'f1520', 'f1521', 'f1522', 'f1523', 'f1524', 'f1525', 'f1526', 'f1527', 'f1528', 'f1529', 'f1530', 'f1531', 'f1532', 'f1533', 'f1534', 'f1535', 'f1536', 'f1537', 'f1538', 'f1539', 'f1540', 'f1541', 'f1542', 'f1543', 'f1544', 'f1545', 'f1546', 'f1547', 'f1548', 'f1549', 'f1550', 'f1551', 'f1552', 'f1553', 'f1554', 'f1555', 'f1556', 'f1557', 'f1558', 'f1559', 'f1560', 'f1561', 'f1562', 'f1563', 'f1564', 'f1565', 'f1566', 'f1567', 'f1568', 'f1569', 'f1570', 'f1571', 'f1572', 'f1573', 'f1574', 'f1575', 'f1576', 'f1577', 'f1578', 'f1579', 'f1580', 'f1581', 'f1582', 'f1583', 'f1584', 'f1585', 'f1586', 'f1587', 'f1588', 'f1589', 'f1590', 'f1591', 'f1592', 'f1593', 'f1594', 'f1595', 'f1596', 'f1597', 'f1598', 'f1599', 'f1600', 'f1601', 'f1602', 'f1603', 'f1604', 'f1605', 'f1606', 'f1607', 'f1608', 'f1609', 'f1610', 'f1611', 'f1612', 'f1613', 'f1614', 'f1615', 'f1616', 'f1617', 'f1618', 'f1619', 'f1620', 'f1621', 'f1622', 'f1623', 'f1624', 'f1625', 'f1626', 'f1627', 'f1628', 'f1629', 'f1630', 'f1631', 'f1632', 'f1633', 'f1634', 'f1635', 'f1636', 'f1637', 'f1638', 'f1639', 'f1640', 'f1641', 'f1642', 'f1643', 'f1644', 'f1645', 'f1646', 'f1647', 'f1648', 'f1649', 'f1650', 'f1651', 'f1652', 'f1653', 'f1654', 'f1655', 'f1656', 'f1657', 'f1658', 'f1659', 'f1660', 'f1661', 'f1662', 'f1663', 'f1664', 'f1665', 'f1666', 'f1667', 'f1668', 'f1669', 'f1670', 'f1671', 'f1672', 'f1673', 'f1674', 'f1675', 'f1676', 'f1677', 'f1678', 'f1679', 'f1680', 'f1681', 'f1682', 'f1683', 'f1684', 'f1685', 'f1686', 'f1687', 'f1688', 'f1689', 'f1690', 'f1691', 'f1692', 'f1693', 'f1694', 'f1695', 'f1696', 'f1697', 'f1698', 'f1699', 'f1700', 'f1701', 'f1702', 'f1703', 'f1704', 'f1705', 'f1706', 'f1707', 'f1708', 'f1709', 'f1710', 'f1711', 'f1712', 'f1713', 'f1714', 'f1715', 'f1716', 'f1717', 'f1718', 'f1719', 'f1720', 'f1721', 'f1722', 'f1723', 'f1724', 'f1725', 'f1726', 'f1727', 'f1728', 'f1729', 'f1730', 'f1731', 'f1732', 'f1733', 'f1734', 'f1735', 'f1736', 'f1737', 'f1738', 'f1739', 'f1740', 'f1741', 'f1742', 'f1743', 'f1744', 'f1745', 'f1746', 'f1747', 'f1748', 'f1749', 'f1750', 'f1751', 'f1752', 'f1753', 'f1754', 'f1755', 'f1756', 'f1757', 'f1758', 'f1759', 'f1760', 'f1761', 'f1762', 'f1763', 'f1764', 'f1765', 'f1766', 'f1767', 'f1768', 'f1769', 'f1770', 'f1771', 'f1772', 'f1773', 'f1774', 'f1775', 'f1776', 'f1777', 'f1778', 'f1779', 'f1780', 'f1781', 'f1782', 'f1783', 'f1784', 'f1785', 'f1786', 'f1787', 'f1788', 'f1789', 'f1790', 'f1791', 'f1792', 'f1793', 'f1794', 'f1795', 'f1796', 'f1797', 'f1798', 'f1799', 'f1800', 'f1801', 'f1802', 'f1803', 'f1804', 'f1805', 'f1806', 'f1807', 'f1808', 'f1809', 'f1810', 'f1811', 'f1812', 'f1813', 'f1814', 'f1815', 'f1816', 'f1817', 'f1818', 'f1819', 'f1820', 'f1821', 'f1822', 'f1823', 'f1824', 'f1825', 'f1826', 'f1827', 'f1828', 'f1829', 'f1830', 'f1831', 'f1832', 'f1833', 'f1834', 'f1835', 'f1836', 'f1837', 'f1838', 'f1839', 'f1840', 'f1841', 'f1842', 'f1843', 'f1844', 'f1845', 'f1846', 'f1847', 'f1848', 'f1849', 'f1850', 'f1851', 'f1852', 'f1853', 'f1854', 'f1855', 'f1856', 'f1857', 'f1858', 'f1859', 'f1860', 'f1861', 'f1862', 'f1863', 'f1864', 'f1865', 'f1866', 'f1867', 'f1868', 'f1869', 'f1870', 'f1871', 'f1872', 'f1873', 'f1874', 'f1875', 'f1876', 'f1877', 'f1878', 'f1879', 'f1880', 'f1881', 'f1882', 'f1883', 'f1884', 'f1885', 'f1886', 'f1887', 'f1888', 'f1889', 'f1890', 'f1891', 'f1892', 'f1893', 'f1894', 'f1895', 'f1896', 'f1897', 'f1898', 'f1899', 'f1900', 'f1901', 'f1902', 'f1903', 'f1904', 'f1905', 'f1906', 'f1907', 'f1908', 'f1909', 'f1910', 'f1911', 'f1912', 'f1913', 'f1914', 'f1915', 'f1916', 'f1917', 'f1918', 'f1919', 'f1920', 'f1921', 'f1922', 'f1923', 'f1924', 'f1925', 'f1926', 'f1927', 'f1928', 'f1929', 'f1930', 'f1931', 'f1932', 'f1933', 'f1934', 'f1935', 'f1936', 'f1937', 'f1938', 'f1939', 'f1940', 'f1941', 'f1942', 'f1943', 'f1944', 'f1945', 'f1946', 'f1947', 'f1948', 'f1949', 'f1950', 'f1951', 'f1952', 'f1953', 'f1954', 'f1955', 'f1956', 'f1957', 'f1958', 'f1959', 'f1960', 'f1961', 'f1962', 'f1963', 'f1964', 'f1965', 'f1966', 'f1967', 'f1968', 'f1969', 'f1970', 'f1971', 'f1972', 'f1973', 'f1974', 'f1975', 'f1976', 'f1977', 'f1978', 'f1979', 'f1980', 'f1981', 'f1982', 'f1983', 'f1984', 'f1985', 'f1986', 'f1987', 'f1988', 'f1989', 'f1990', 'f1991', 'f1992', 'f1993', 'f1994', 'f1995', 'f1996', 'f1997', 'f1998', 'f1999', 'f2000', 'f2001', 'f2002', 'f2003', 'f2004', 'f2005', 'f2006', 'f2007', 'f2008', 'f2009', 'f2010', 'f2011', 'f2012', 'f2013', 'f2014', 'f2015', 'f2016', 'f2017', 'f2018', 'f2019', 'f2020', 'f2021', 'f2022', 'f2023', 'f2024', 'f2025', 'f2026', 'f2027', 'f2028', 'f2029', 'f2030', 'f2031', 'f2032', 'f2033', 'f2034', 'f2035', 'f2036', 'f2037', 'f2038', 'f2039', 'f2040', 'f2041', 'f2042', 'f2043', 'f2044', 'f2045', 'f2046', 'f2047', 'f2048', 'f2049', 'f2050', 'f2051', 'f2052', 'f2053', 'f2054', 'f2055', 'f2056', 'f2057', 'f2058', 'f2059', 'f2060', 'f2061', 'f2062', 'f2063', 'f2064', 'f2065', 'f2066', 'f2067', 'f2068', 'f2069', 'f2070', 'f2071', 'f2072', 'f2073', 'f2074', 'f2075', 'f2076', 'f2077', 'f2078', 'f2079', 'f2080', 'f2081', 'f2082', 'f2083', 'f2084', 'f2085', 'f2086', 'f2087', 'f2088', 'f2089', 'f2090', 'f2091', 'f2092', 'f2093', 'f2094', 'f2095', 'f2096', 'f2097', 'f2098', 'f2099', 'f2100', 'f2101', 'f2102', 'f2103', 'f2104', 'f2105', 'f2106', 'f2107', 'f2108', 'f2109', 'f2110', 'f2111', 'f2112', 'f2113', 'f2114', 'f2115', 'f2116', 'f2117', 'f2118', 'f2119', 'f2120', 'f2121', 'f2122', 'f2123', 'f2124', 'f2125', 'f2126', 'f2127', 'f2128', 'f2129', 'f2130', 'f2131', 'f2132', 'f2133', 'f2134', 'f2135', 'f2136', 'f2137', 'f2138', 'f2139', 'f2140', 'f2141', 'f2142', 'f2143', 'f2144', 'f2145', 'f2146', 'f2147', 'f2148', 'f2149', 'f2150', 'f2151', 'f2152', 'f2153', 'f2154', 'f2155', 'f2156', 'f2157', 'f2158', 'f2159', 'f2160', 'f2161', 'f2162', 'f2163', 'f2164', 'f2165', 'f2166', 'f2167', 'f2168', 'f2169', 'f2170', 'f2171', 'f2172', 'f2173', 'f2174', 'f2175', 'f2176', 'f2177', 'f2178', 'f2179', 'f2180', 'f2181', 'f2182', 'f2183', 'f2184', 'f2185', 'f2186', 'f2187', 'f2188', 'f2189', 'f2190', 'f2191', 'f2192', 'f2193', 'f2194', 'f2195', 'f2196', 'f2197', 'f2198', 'f2199', 'f2200', 'f2201', 'f2202', 'f2203', 'f2204', 'f2205', 'f2206', 'f2207', 'f2208', 'f2209', 'f2210', 'f2211', 'f2212', 'f2213', 'f2214', 'f2215', 'f2216', 'f2217', 'f2218', 'f2219', 'f2220', 'f2221', 'f2222', 'f2223', 'f2224', 'f2225', 'f2226', 'f2227', 'f2228', 'f2229', 'f2230', 'f2231', 'f2232', 'f2233', 'f2234', 'f2235', 'f2236', 'f2237', 'f2238', 'f2239', 'f2240', 'f2241', 'f2242', 'f2243', 'f2244', 'f2245', 'f2246', 'f2247', 'f2248', 'f2249', 'f2250', 'f2251', 'f2252', 'f2253', 'f2254', 'f2255', 'f2256', 'f2257', 'f2258', 'f2259', 'f2260', 'f2261', 'f2262', 'f2263', 'f2264', 'f2265', 'f2266', 'f2267', 'f2268', 'f2269', 'f2270', 'f2271', 'f2272', 'f2273', 'f2274', 'f2275', 'f2276', 'f2277', 'f2278', 'f2279', 'f2280', 'f2281', 'f2282', 'f2283', 'f2284', 'f2285', 'f2286', 'f2287', 'f2288', 'f2289', 'f2290', 'f2291', 'f2292', 'f2293', 'f2294', 'f2295', 'f2296', 'f2297', 'f2298', 'f2299', 'f2300', 'f2301', 'f2302', 'f2303', 'f2304', 'f2305', 'f2306', 'f2307', 'f2308', 'f2309', 'f2310', 'f2311', 'f2312', 'f2313', 'f2314', 'f2315', 'f2316', 'f2317', 'f2318', 'f2319', 'f2320', 'f2321', 'f2322', 'f2323', 'f2324', 'f2325', 'f2326', 'f2327', 'f2328', 'f2329', 'f2330', 'f2331', 'f2332', 'f2333', 'f2334', 'f2335', 'f2336', 'f2337', 'f2338', 'f2339', 'f2340', 'f2341', 'f2342', 'f2343', 'f2344', 'f2345', 'f2346', 'f2347', 'f2348', 'f2349', 'f2350', 'f2351', 'f2352', 'f2353', 'f2354', 'f2355', 'f2356', 'f2357', 'f2358', 'f2359', 'f2360', 'f2361', 'f2362', 'f2363', 'f2364', 'f2365', 'f2366', 'f2367', 'f2368', 'f2369', 'f2370', 'f2371', 'f2372', 'f2373', 'f2374', 'f2375', 'f2376', 'f2377', 'f2378', 'f2379', 'f2380', 'f2381', 'f2382', 'f2383', 'f2384', 'f2385', 'f2386', 'f2387', 'f2388', 'f2389', 'f2390', 'f2391', 'f2392', 'f2393', 'f2394', 'f2395', 'f2396', 'f2397', 'f2398', 'f2399', 'f2400', 'f2401', 'f2402', 'f2403', 'f2404', 'f2405', 'f2406', 'f2407', 'f2408', 'f2409', 'f2410', 'f2411', 'f2412', 'f2413', 'f2414', 'f2415', 'f2416', 'f2417', 'f2418', 'f2419', 'f2420', 'f2421', 'f2422', 'f2423', 'f2424', 'f2425', 'f2426', 'f2427', 'f2428', 'f2429', 'f2430', 'f2431', 'f2432', 'f2433', 'f2434', 'f2435', 'f2436', 'f2437', 'f2438', 'f2439', 'f2440', 'f2441', 'f2442', 'f2443', 'f2444', 'f2445', 'f2446', 'f2447', 'f2448', 'f2449', 'f2450', 'f2451', 'f2452', 'f2453', 'f2454', 'f2455', 'f2456', 'f2457', 'f2458', 'f2459', 'f2460', 'f2461', 'f2462', 'f2463', 'f2464', 'f2465', 'f2466', 'f2467', 'f2468', 'f2469', 'f2470', 'f2471', 'f2472', 'f2473', 'f2474', 'f2475', 'f2476', 'f2477', 'f2478', 'f2479', 'f2480', 'f2481', 'f2482', 'f2483', 'f2484', 'f2485', 'f2486', 'f2487', 'f2488', 'f2489', 'f2490', 'f2491', 'f2492', 'f2493', 'f2494', 'f2495', 'f2496', 'f2497', 'f2498', 'f2499', 'f2500', 'f2501', 'f2502', 'f2503', 'f2504', 'f2505', 'f2506', 'f2507', 'f2508', 'f2509', 'f2510', 'f2511', 'f2512', 'f2513', 'f2514', 'f2515', 'f2516', 'f2517', 'f2518', 'f2519', 'f2520', 'f2521', 'f2522', 'f2523', 'f2524', 'f2525', 'f2526', 'f2527', 'f2528', 'f2529', 'f2530', 'f2531', 'f2532', 'f2533', 'f2534', 'f2535', 'f2536', 'f2537', 'f2538', 'f2539', 'f2540', 'f2541', 'f2542', 'f2543', 'f2544', 'f2545', 'f2546', 'f2547', 'f2548', 'f2549', 'f2550', 'f2551', 'f2552', 'f2553', 'f2554', 'f2555', 'f2556', 'f2557', 'f2558', 'f2559', 'f2560', 'f2561', 'f2562', 'f2563', 'f2564', 'f2565', 'f2566', 'f2567', 'f2568', 'f2569', 'f2570', 'f2571', 'f2572', 'f2573', 'f2574', 'f2575', 'f2576', 'f2577', 'f2578', 'f2579', 'f2580', 'f2581', 'f2582', 'f2583', 'f2584', 'f2585', 'f2586', 'f2587', 'f2588', 'f2589', 'f2590', 'f2591', 'f2592', 'f2593', 'f2594', 'f2595', 'f2596', 'f2597', 'f2598', 'f2599', 'f2600', 'f2601', 'f2602', 'f2603', 'f2604', 'f2605', 'f2606', 'f2607', 'f2608', 'f2609', 'f2610', 'f2611', 'f2612', 'f2613', 'f2614', 'f2615', 'f2616', 'f2617', 'f2618', 'f2619', 'f2620', 'f2621', 'f2622', 'f2623', 'f2624', 'f2625', 'f2626', 'f2627', 'f2628', 'f2629', 'f2630', 'f2631', 'f2632', 'f2633', 'f2634', 'f2635', 'f2636', 'f2637', 'f2638', 'f2639', 'f2640', 'f2641', 'f2642', 'f2643', 'f2644', 'f2645', 'f2646', 'f2647', 'f2648', 'f2649', 'f2650', 'f2651', 'f2652', 'f2653', 'f2654', 'f2655', 'f2656', 'f2657', 'f2658', 'f2659', 'f2660', 'f2661', 'f2662', 'f2663', 'f2664', 'f2665', 'f2666', 'f2667', 'f2668', 'f2669', 'f2670', 'f2671', 'f2672', 'f2673', 'f2674', 'f2675', 'f2676', 'f2677', 'f2678', 'f2679', 'f2680', 'f2681', 'f2682', 'f2683', 'f2684', 'f2685', 'f2686', 'f2687', 'f2688', 'f2689', 'f2690', 'f2691', 'f2692', 'f2693', 'f2694', 'f2695', 'f2696', 'f2697', 'f2698', 'f2699', 'f2700', 'f2701', 'f2702', 'f2703', 'f2704', 'f2705', 'f2706', 'f2707', 'f2708', 'f2709', 'f2710', 'f2711', 'f2712', 'f2713', 'f2714', 'f2715', 'f2716', 'f2717', 'f2718', 'f2719', 'f2720', 'f2721', 'f2722', 'f2723', 'f2724', 'f2725', 'f2726', 'f2727', 'f2728', 'f2729', 'f2730', 'f2731', 'f2732', 'f2733', 'f2734', 'f2735', 'f2736', 'f2737', 'f2738', 'f2739', 'f2740', 'f2741', 'f2742', 'f2743', 'f2744', 'f2745', 'f2746', 'f2747', 'f2748', 'f2749', 'f2750', 'f2751', 'f2752', 'f2753', 'f2754', 'f2755', 'f2756', 'f2757', 'f2758', 'f2759', 'f2760', 'f2761', 'f2762', 'f2763', 'f2764', 'f2765', 'f2766', 'f2767', 'f2768', 'f2769', 'f2770', 'f2771', 'f2772', 'f2773', 'f2774', 'f2775', 'f2776', 'f2777', 'f2778', 'f2779', 'f2780', 'f2781', 'f2782', 'f2783', 'f2784', 'f2785', 'f2786', 'f2787', 'f2788', 'f2789', 'f2790', 'f2791', 'f2792', 'f2793', 'f2794', 'f2795', 'f2796', 'f2797', 'f2798', 'f2799', 'f2800', 'f2801', 'f2802', 'f2803', 'f2804', 'f2805', 'f2806', 'f2807', 'f2808', 'f2809', 'f2810', 'f2811', 'f2812', 'f2813', 'f2814', 'f2815', 'f2816', 'f2817', 'f2818', 'f2819', 'f2820', 'f2821', 'f2822', 'f2823', 'f2824', 'f2825', 'f2826', 'f2827', 'f2828', 'f2829', 'f2830', 'f2831', 'f2832', 'f2833', 'f2834', 'f2835', 'f2836', 'f2837', 'f2838', 'f2839', 'f2840', 'f2841', 'f2842', 'f2843', 'f2844', 'f2845', 'f2846', 'f2847', 'f2848', 'f2849', 'f2850', 'f2851', 'f2852', 'f2853', 'f2854', 'f2855', 'f2856', 'f2857', 'f2858', 'f2859', 'f2860', 'f2861', 'f2862', 'f2863', 'f2864', 'f2865', 'f2866', 'f2867', 'f2868', 'f2869', 'f2870', 'f2871', 'f2872', 'f2873', 'f2874', 'f2875', 'f2876', 'f2877', 'f2878', 'f2879', 'f2880', 'f2881', 'f2882', 'f2883', 'f2884', 'f2885', 'f2886', 'f2887', 'f2888', 'f2889', 'f2890', 'f2891', 'f2892', 'f2893', 'f2894', 'f2895', 'f2896', 'f2897', 'f2898', 'f2899', 'f2900', 'f2901', 'f2902', 'f2903', 'f2904', 'f2905', 'f2906', 'f2907', 'f2908', 'f2909', 'f2910', 'f2911', 'f2912', 'f2913', 'f2914', 'f2915', 'f2916', 'f2917', 'f2918', 'f2919', 'f2920', 'f2921', 'f2922', 'f2923', 'f2924', 'f2925', 'f2926', 'f2927', 'f2928', 'f2929', 'f2930', 'f2931', 'f2932', 'f2933', 'f2934', 'f2935', 'f2936', 'f2937', 'f2938', 'f2939', 'f2940', 'f2941', 'f2942', 'f2943', 'f2944', 'f2945', 'f2946', 'f2947', 'f2948', 'f2949', 'f2950', 'f2951', 'f2952', 'f2953', 'f2954', 'f2955', 'f2956', 'f2957', 'f2958', 'f2959', 'f2960', 'f2961', 'f2962', 'f2963', 'f2964', 'f2965', 'f2966', 'f2967', 'f2968', 'f2969', 'f2970', 'f2971', 'f2972', 'f2973', 'f2974', 'f2975', 'f2976', 'f2977', 'f2978', 'f2979', 'f2980', 'f2981', 'f2982', 'f2983', 'f2984', 'f2985', 'f2986', 'f2987', 'f2988', 'f2989', 'f2990', 'f2991', 'f2992', 'f2993', 'f2994', 'f2995', 'f2996', 'f2997', 'f2998', 'f2999', 'f3000', 'f3001', 'f3002', 'f3003', 'f3004', 'f3005', 'f3006', 'f3007', 'f3008', 'f3009', 'f3010', 'f3011', 'f3012', 'f3013', 'f3014', 'f3015', 'f3016', 'f3017', 'f3018', 'f3019', 'f3020', 'f3021', 'f3022', 'f3023', 'f3024', 'f3025', 'f3026', 'f3027', 'f3028', 'f3029', 'f3030', 'f3031', 'f3032', 'f3033', 'f3034', 'f3035', 'f3036', 'f3037', 'f3038', 'f3039', 'f3040', 'f3041', 'f3042', 'f3043', 'f3044', 'f3045', 'f3046', 'f3047', 'f3048', 'f3049', 'f3050', 'f3051', 'f3052', 'f3053', 'f3054', 'f3055', 'f3056', 'f3057', 'f3058', 'f3059', 'f3060', 'f3061', 'f3062', 'f3063', 'f3064', 'f3065', 'f3066', 'f3067', 'f3068', 'f3069', 'f3070', 'f3071', 'f3072', 'f3073', 'f3074', 'f3075', 'f3076', 'f3077', 'f3078', 'f3079', 'f3080', 'f3081', 'f3082', 'f3083', 'f3084', 'f3085', 'f3086', 'f3087', 'f3088', 'f3089', 'f3090', 'f3091', 'f3092', 'f3093', 'f3094', 'f3095', 'f3096', 'f3097', 'f3098', 'f3099', 'f3100', 'f3101', 'f3102', 'f3103', 'f3104', 'f3105', 'f3106', 'f3107', 'f3108', 'f3109', 'f3110', 'f3111', 'f3112', 'f3113', 'f3114', 'f3115', 'f3116', 'f3117', 'f3118', 'f3119', 'f3120', 'f3121', 'f3122', 'f3123', 'f3124', 'f3125', 'f3126', 'f3127', 'f3128', 'f3129', 'f3130', 'f3131', 'f3132', 'f3133', 'f3134', 'f3135', 'f3136', 'f3137', 'f3138', 'f3139', 'f3140', 'f3141', 'f3142', 'f3143', 'f3144', 'f3145', 'f3146', 'f3147', 'f3148', 'f3149', 'f3150', 'f3151', 'f3152', 'f3153', 'f3154', 'f3155', 'f3156', 'f3157', 'f3158', 'f3159', 'f3160', 'f3161', 'f3162', 'f3163', 'f3164', 'f3165', 'f3166', 'f3167', 'f3168', 'f3169', 'f3170', 'f3171', 'f3172', 'f3173', 'f3174', 'f3175', 'f3176', 'f3177', 'f3178', 'f3179', 'f3180', 'f3181', 'f3182', 'f3183', 'f3184', 'f3185', 'f3186', 'f3187', 'f3188', 'f3189', 'f3190', 'f3191', 'f3192', 'f3193', 'f3194', 'f3195', 'f3196', 'f3197', 'f3198', 'f3199', 'f3200', 'f3201', 'f3202', 'f3203', 'f3204', 'f3205', 'f3206', 'f3207', 'f3208', 'f3209', 'f3210', 'f3211', 'f3212', 'f3213', 'f3214', 'f3215', 'f3216', 'f3217', 'f3218', 'f3219', 'f3220', 'f3221', 'f3222', 'f3223', 'f3224', 'f3225', 'f3226', 'f3227', 'f3228', 'f3229', 'f3230', 'f3231', 'f3232', 'f3233', 'f3234', 'f3235', 'f3236', 'f3237', 'f3238', 'f3239', 'f3240', 'f3241', 'f3242', 'f3243', 'f3244', 'f3245', 'f3246', 'f3247', 'f3248', 'f3249', 'f3250', 'f3251', 'f3252', 'f3253', 'f3254', 'f3255', 'f3256', 'f3257', 'f3258', 'f3259', 'f3260', 'f3261', 'f3262', 'f3263', 'f3264', 'f3265', 'f3266', 'f3267', 'f3268', 'f3269', 'f3270', 'f3271', 'f3272', 'f3273', 'f3274', 'f3275', 'f3276', 'f3277', 'f3278', 'f3279', 'f3280', 'f3281', 'f3282', 'f3283', 'f3284', 'f3285', 'f3286', 'f3287', 'f3288', 'f3289', 'f3290', 'f3291', 'f3292', 'f3293', 'f3294', 'f3295', 'f3296', 'f3297', 'f3298', 'f3299', 'f3300', 'f3301', 'f3302', 'f3303', 'f3304', 'f3305', 'f3306', 'f3307', 'f3308', 'f3309', 'f3310', 'f3311', 'f3312', 'f3313', 'f3314', 'f3315', 'f3316', 'f3317', 'f3318', 'f3319', 'f3320', 'f3321', 'f3322', 'f3323', 'f3324', 'f3325', 'f3326', 'f3327', 'f3328', 'f3329', 'f3330', 'f3331', 'f3332', 'f3333', 'f3334', 'f3335', 'f3336', 'f3337', 'f3338', 'f3339', 'f3340', 'f3341', 'f3342', 'f3343', 'f3344', 'f3345', 'f3346', 'f3347', 'f3348', 'f3349', 'f3350', 'f3351', 'f3352', 'f3353', 'f3354', 'f3355', 'f3356', 'f3357', 'f3358', 'f3359', 'f3360', 'f3361', 'f3362', 'f3363', 'f3364', 'f3365', 'f3366', 'f3367', 'f3368', 'f3369', 'f3370', 'f3371', 'f3372', 'f3373', 'f3374', 'f3375', 'f3376', 'f3377', 'f3378', 'f3379', 'f3380', 'f3381', 'f3382', 'f3383', 'f3384', 'f3385', 'f3386', 'f3387', 'f3388', 'f3389', 'f3390', 'f3391', 'f3392', 'f3393', 'f3394', 'f3395', 'f3396', 'f3397', 'f3398', 'f3399', 'f3400', 'f3401', 'f3402', 'f3403', 'f3404', 'f3405', 'f3406', 'f3407', 'f3408', 'f3409', 'f3410', 'f3411', 'f3412', 'f3413', 'f3414', 'f3415', 'f3416', 'f3417', 'f3418', 'f3419', 'f3420', 'f3421', 'f3422', 'f3423', 'f3424', 'f3425', 'f3426', 'f3427', 'f3428', 'f3429', 'f3430', 'f3431', 'f3432', 'f3433', 'f3434', 'f3435', 'f3436', 'f3437', 'f3438', 'f3439', 'f3440', 'f3441', 'f3442', 'f3443', 'f3444', 'f3445', 'f3446', 'f3447', 'f3448', 'f3449', 'f3450', 'f3451', 'f3452', 'f3453', 'f3454', 'f3455', 'f3456', 'f3457', 'f3458', 'f3459', 'f3460', 'f3461', 'f3462', 'f3463', 'f3464', 'f3465', 'f3466', 'f3467', 'f3468', 'f3469', 'f3470', 'f3471', 'f3472', 'f3473', 'f3474', 'f3475', 'f3476', 'f3477', 'f3478', 'f3479', 'f3480', 'f3481', 'f3482', 'f3483', 'f3484', 'f3485', 'f3486', 'f3487', 'f3488', 'f3489', 'f3490', 'f3491', 'f3492', 'f3493', 'f3494', 'f3495', 'f3496', 'f3497', 'f3498', 'f3499', 'f3500', 'f3501', 'f3502', 'f3503', 'f3504', 'f3505', 'f3506', 'f3507', 'f3508', 'f3509', 'f3510', 'f3511', 'f3512', 'f3513', 'f3514', 'f3515', 'f3516', 'f3517', 'f3518', 'f3519', 'f3520', 'f3521', 'f3522', 'f3523', 'f3524', 'f3525', 'f3526', 'f3527', 'f3528', 'f3529', 'f3530', 'f3531', 'f3532', 'f3533', 'f3534', 'f3535', 'f3536', 'f3537', 'f3538', 'f3539', 'f3540', 'f3541', 'f3542', 'f3543', 'f3544', 'f3545', 'f3546', 'f3547', 'f3548', 'f3549', 'f3550', 'f3551', 'f3552', 'f3553', 'f3554', 'f3555', 'f3556', 'f3557', 'f3558', 'f3559', 'f3560', 'f3561', 'f3562', 'f3563', 'f3564', 'f3565', 'f3566', 'f3567', 'f3568', 'f3569', 'f3570', 'f3571', 'f3572', 'f3573', 'f3574', 'f3575', 'f3576', 'f3577', 'f3578', 'f3579', 'f3580', 'f3581', 'f3582', 'f3583', 'f3584', 'f3585', 'f3586', 'f3587', 'f3588', 'f3589', 'f3590', 'f3591', 'f3592', 'f3593', 'f3594', 'f3595', 'f3596', 'f3597', 'f3598', 'f3599', 'f3600', 'f3601', 'f3602', 'f3603', 'f3604', 'f3605', 'f3606', 'f3607', 'f3608', 'f3609', 'f3610', 'f3611', 'f3612', 'f3613', 'f3614', 'f3615', 'f3616', 'f3617', 'f3618', 'f3619', 'f3620', 'f3621', 'f3622', 'f3623', 'f3624', 'f3625', 'f3626', 'f3627', 'f3628', 'f3629', 'f3630', 'f3631', 'f3632', 'f3633', 'f3634', 'f3635', 'f3636', 'f3637', 'f3638', 'f3639', 'f3640', 'f3641', 'f3642', 'f3643', 'f3644', 'f3645', 'f3646', 'f3647', 'f3648', 'f3649', 'f3650', 'f3651', 'f3652', 'f3653', 'f3654', 'f3655', 'f3656', 'f3657', 'f3658', 'f3659', 'f3660', 'f3661', 'f3662', 'f3663', 'f3664', 'f3665', 'f3666', 'f3667', 'f3668', 'f3669', 'f3670', 'f3671', 'f3672', 'f3673', 'f3674', 'f3675', 'f3676', 'f3677', 'f3678', 'f3679', 'f3680', 'f3681', 'f3682', 'f3683', 'f3684', 'f3685', 'f3686', 'f3687', 'f3688', 'f3689', 'f3690', 'f3691', 'f3692', 'f3693', 'f3694', 'f3695', 'f3696', 'f3697', 'f3698', 'f3699', 'f3700', 'f3701', 'f3702', 'f3703', 'f3704', 'f3705', 'f3706', 'f3707', 'f3708', 'f3709', 'f3710', 'f3711', 'f3712', 'f3713', 'f3714', 'f3715', 'f3716', 'f3717', 'f3718', 'f3719', 'f3720', 'f3721', 'f3722', 'f3723', 'f3724', 'f3725', 'f3726', 'f3727', 'f3728', 'f3729', 'f3730', 'f3731', 'f3732', 'f3733', 'f3734', 'f3735', 'f3736', 'f3737', 'f3738', 'f3739', 'f3740', 'f3741', 'f3742', 'f3743', 'f3744', 'f3745', 'f3746', 'f3747', 'f3748', 'f3749', 'f3750', 'f3751', 'f3752', 'f3753', 'f3754', 'f3755', 'f3756', 'f3757', 'f3758', 'f3759', 'f3760', 'f3761', 'f3762', 'f3763', 'f3764', 'f3765', 'f3766', 'f3767', 'f3768', 'f3769', 'f3770', 'f3771', 'f3772', 'f3773', 'f3774', 'f3775', 'f3776', 'f3777', 'f3778', 'f3779', 'f3780', 'f3781', 'f3782', 'f3783', 'f3784', 'f3785', 'f3786', 'f3787', 'f3788', 'f3789', 'f3790', 'f3791', 'f3792', 'f3793', 'f3794', 'f3795', 'f3796', 'f3797', 'f3798', 'f3799', 'f3800', 'f3801', 'f3802', 'f3803', 'f3804', 'f3805', 'f3806', 'f3807', 'f3808', 'f3809', 'f3810', 'f3811', 'f3812', 'f3813', 'f3814', 'f3815', 'f3816', 'f3817', 'f3818', 'f3819', 'f3820', 'f3821', 'f3822', 'f3823', 'f3824', 'f3825', 'f3826', 'f3827', 'f3828', 'f3829', 'f3830', 'f3831', 'f3832', 'f3833', 'f3834', 'f3835', 'f3836', 'f3837', 'f3838', 'f3839', 'f3840', 'f3841', 'f3842', 'f3843', 'f3844', 'f3845', 'f3846', 'f3847', 'f3848', 'f3849', 'f3850', 'f3851', 'f3852', 'f3853', 'f3854', 'f3855', 'f3856', 'f3857', 'f3858', 'f3859', 'f3860', 'f3861', 'f3862', 'f3863', 'f3864', 'f3865', 'f3866', 'f3867', 'f3868', 'f3869', 'f3870', 'f3871', 'f3872', 'f3873', 'f3874', 'f3875', 'f3876', 'f3877', 'f3878', 'f3879', 'f3880', 'f3881', 'f3882', 'f3883', 'f3884', 'f3885', 'f3886', 'f3887', 'f3888', 'f3889', 'f3890', 'f3891', 'f3892', 'f3893', 'f3894', 'f3895', 'f3896', 'f3897', 'f3898', 'f3899', 'f3900', 'f3901', 'f3902', 'f3903', 'f3904', 'f3905', 'f3906', 'f3907', 'f3908', 'f3909', 'f3910', 'f3911', 'f3912', 'f3913', 'f3914', 'f3915', 'f3916', 'f3917', 'f3918', 'f3919', 'f3920', 'f3921', 'f3922', 'f3923', 'f3924', 'f3925', 'f3926', 'f3927', 'f3928', 'f3929', 'f3930', 'f3931', 'f3932', 'f3933', 'f3934', 'f3935', 'f3936', 'f3937', 'f3938', 'f3939', 'f3940', 'f3941', 'f3942', 'f3943', 'f3944', 'f3945', 'f3946', 'f3947', 'f3948', 'f3949', 'f3950', 'f3951', 'f3952', 'f3953', 'f3954', 'f3955', 'f3956', 'f3957', 'f3958', 'f3959', 'f3960', 'f3961', 'f3962', 'f3963', 'f3964', 'f3965', 'f3966', 'f3967', 'f3968', 'f3969', 'f3970', 'f3971', 'f3972', 'f3973', 'f3974', 'f3975', 'f3976', 'f3977', 'f3978', 'f3979', 'f3980', 'f3981', 'f3982', 'f3983', 'f3984', 'f3985', 'f3986', 'f3987', 'f3988', 'f3989', 'f3990', 'f3991', 'f3992', 'f3993', 'f3994', 'f3995', 'f3996', 'f3997', 'f3998', 'f3999', 'f4000', 'f4001', 'f4002', 'f4003', 'f4004', 'f4005', 'f4006', 'f4007', 'f4008', 'f4009', 'f4010', 'f4011', 'f4012', 'f4013', 'f4014', 'f4015', 'f4016', 'f4017', 'f4018', 'f4019', 'f4020', 'f4021', 'f4022', 'f4023', 'f4024', 'f4025', 'f4026', 'f4027', 'f4028', 'f4029', 'f4030', 'f4031', 'f4032', 'f4033', 'f4034', 'f4035', 'f4036', 'f4037', 'f4038', 'f4039', 'f4040', 'f4041', 'f4042', 'f4043', 'f4044', 'f4045', 'f4046', 'f4047', 'f4048', 'f4049', 'f4050', 'f4051', 'f4052', 'f4053', 'f4054', 'f4055', 'f4056', 'f4057', 'f4058', 'f4059', 'f4060', 'f4061', 'f4062', 'f4063', 'f4064', 'f4065', 'f4066', 'f4067', 'f4068', 'f4069', 'f4070', 'f4071', 'f4072', 'f4073', 'f4074', 'f4075', 'f4076', 'f4077', 'f4078', 'f4079', 'f4080', 'f4081', 'f4082', 'f4083', 'f4084', 'f4085', 'f4086', 'f4087', 'f4088']\ntraining data did not have the following fields: f3949, f3948, f3943, f3942, f3941, f3940, f3947, f3946, f3945, f3944, f4043, f4042, f4041, f4040, f4047, f4046, f4045, f4044, f4049, f4048, f3798, f3799, f3792, f3793, f3790, f3791, f3796, f3797, f3794, f3795, f3888, f3889, f3886, f3887, f3884, f3885, f3882, f3883, f3880, f3881, f3833, f3832, f3831, f3830, f3837, f3836, f3835, f3834, f3839, f3838, f4020, f3909, f3908, f3907, f3906, f3905, f3904, f3903, f3902, f3901, f3900, f3758, f3759, f3756, f3757, f3754, f3755, f3752, f3753, f3750, f3751, f3990, f3991, f3992, f3993, f3994, f3995, f3996, f3997, f3998, f3999, f3877, f3876, f3875, f3874, f3873, f3872, f3871, f3870, f3879, f3878, f4007, f4006, f4005, f4004, f4003, f4002, f4001, f4000, f4009, f4008, f3954, f3955, f3956, f3957, f3950, f3951, f3952, f3953, f3958, f3959, f4058, f4059, f4054, f4055, f4056, f4057, f4050, f4051, f4052, f4053, f3719, f3828, f3829, f3824, f3825, f3826, f3827, f3820, f3821, f3822, f3823, f3918, f3919, f3910, f3911, f3912, f3913, f3914, f3915, f3916, f3917, f3769, f3768, f3763, f3762, f3761, f3760, f3767, f3766, f3765, f3764, f3737, f4088, f4087, f4086, f4085, f4084, f4083, f4082, f4081, f4080, f3969, f3968, f3965, f3964, f3967, f3966, f3961, f3960, f3963, f3962, f4065, f4064, f4067, f4066, f4061, f4060, f4063, f4062, f4069, f4068, f3860, f3861, f3862, f3863, f3864, f3865, f3866, f3867, f3868, f3869, f4010, f4011, f4012, f4013, f4014, f4015, f4016, f4017, f4018, f4019, f3815, f3814, f3817, f3816, f3811, f3810, f3813, f3812, f3819, f3818, f3921, f3920, f3923, f3922, f3925, f3924, f3927, f3926, f3929, f3928, f3745, f3744, f3747, f4029, f4028, f3746, f4021, f3741, f4023, f4022, f4025, f4024, f4027, f4026, f3743, f3742, f3729, f3728, f3727, f3726, f3725, f3724, f3723, f3722, f3721, f3720, f3859, f3858, f3851, f3850, f3853, f3852, f3855, f3854, f3857, f3856, f3738, f3739, f3989, f3978, f3979, f3976, f3977, f3974, f3975, f3972, f3973, f3970, f3971, f4076, f4077, f4074, f4075, f4072, f4073, f4070, f4071, f4078, f4079, f3789, f3788, f3781, f3780, f3783, f3782, f3785, f3784, f3787, f3786, f3899, f3898, f3895, f3894, f3897, f3896, f3891, f3890, f3893, f3892, f3774, f3775, f3776, f3777, f3770, f3771, f3772, f3773, f3778, f3779, f3806, f3807, f3804, f3805, f3802, f3803, f3800, f3801, f3808, f3809, f3932, f3933, f3930, f3931, f3936, f3937, f3934, f3935, f3938, f3939, f4038, f4039, f3749, f3748, f4032, f4033, f4030, f4031, f4036, f4037, f4034, f4035, f3987, f3986, f3985, f3984, f3983, f3982, f3981, f3980, f3730, f3731, f3732, f3733, f3734, f3735, f3736, f3988, f3740, f3848, f3849, f3842, f3843, f3840, f3841, f3846, f3847, f3844, f3845"
     ]
    }
   ],
   "source": [
    "\n",
    "out_df = get_submit_data(param, train_x, train_y, test_df, num_rounds=2000)\n",
    "out_df.to_csv(\"xgb_managerid.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## gen test_data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 quadkey_15_bathrooms  quadkey_15_bedrooms  quadkey_15_price\n",
      "quadkey_15                                                                  \n",
      "021333333001101                   1.0                  0.0            2200.0\n",
      "023010211023323                   1.0                  2.0            3200.0\n",
      "023012311310010                   1.0                  1.0            2425.0\n",
      "023101012323320                   1.0                  2.0            2150.0\n",
      "023130121200020                   3.0                  3.0             500.0\n",
      "tr_sparse(74659, 100)\n",
      "tr_sparse_desc(74659, 100)\n",
      "cloumns: Index([                u'bathrooms',                  u'bedrooms',\n",
      "                        u'latitude',                 u'longitude',\n",
      "                           u'price',                u'diff_price',\n",
      "                  u'diff_bathrooms',             u'diff_bedrooms',\n",
      "                     u'ratio_price',            u'building_price',\n",
      "              u'building_bathrooms',         u'building_bedrooms',\n",
      "              u'diff_mean_of_price',     u'diff_mean_of_bedrooms',\n",
      "          u'diff_mean_of_bathrooms', u'diff_bathrooms_quadkey_15',\n",
      "        u'diff_bedrooms_quadkey_15',     u'diff_price_quadkey_15',\n",
      "          u'ratio_price_quadkey_15', u'diff_bathrooms_quadkey_13',\n",
      "        u'diff_bedrooms_quadkey_13',     u'diff_price_quadkey_13',\n",
      "          u'ratio_price_quadkey_13',             u'price_per_bed',\n",
      "                  u'price_per_bath',            u'price_per_room',\n",
      "         u'building_price_per_room',      u'diff_price_per_rooms',\n",
      "                      u'total_room',                 u'diff_room',\n",
      "                      u'ratio_room',              u'created_year',\n",
      "                   u'created_month',               u'created_day',\n",
      "                    u'created_hour',              u'features_cnt',\n",
      "                      u'photos_cnt',                  u'desc_cnt'],\n",
      "      dtype='object')\n",
      "train_x: (74659, 238)\n",
      "round: 0\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 1, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 3}\n",
      "dataframe: (74659, 3)\n",
      "round: 1\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 2, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 7}\n",
      "dataframe: (74659, 6)\n",
      "round: 2\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 3}\n",
      "dataframe: (74659, 9)\n",
      "round: 3\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 2}\n",
      "dataframe: (74659, 12)\n",
      "round: 4\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 5, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 7}\n",
      "dataframe: (74659, 15)\n",
      "round: 5\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 7}\n",
      "dataframe: (74659, 18)\n",
      "round: 6\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 1, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 6}\n",
      "dataframe: (74659, 21)\n",
      "round: 7\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 3, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 5}\n",
      "dataframe: (74659, 24)\n",
      "round: 8\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 4, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 9}\n",
      "dataframe: (74659, 27)\n",
      "round: 9\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 4, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 8}\n",
      "dataframe: (74659, 30)\n",
      "round: 10\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 1, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 8}\n",
      "dataframe: (74659, 33)\n",
      "round: 11\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 1, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 8}\n",
      "dataframe: (74659, 36)\n",
      "round: 12\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 3, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 7}\n",
      "dataframe: (74659, 39)\n",
      "round: 13\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 5, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 3}\n",
      "dataframe: (74659, 42)\n",
      "round: 14\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 4, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 4}\n",
      "dataframe: (74659, 45)\n",
      "round: 15\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 4, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 8}\n",
      "dataframe: (74659, 48)\n",
      "round: 16\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 6}\n",
      "dataframe: (74659, 51)\n",
      "round: 17\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 2}\n",
      "dataframe: (74659, 54)\n",
      "round: 18\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 3, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 4}\n",
      "dataframe: (74659, 57)\n",
      "round: 19\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 2, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 4}\n",
      "dataframe: (74659, 60)\n",
      "round: 20\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 2, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 7}\n",
      "dataframe: (74659, 63)\n",
      "round: 21\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 2, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 7}\n",
      "dataframe: (74659, 66)\n",
      "round: 22\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 4, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 7}\n",
      "dataframe: (74659, 69)\n",
      "round: 23\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 2, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 7}\n",
      "dataframe: (74659, 72)\n",
      "round: 24\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 10}\n",
      "dataframe: (74659, 75)\n",
      "round: 25\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 2, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 3}\n",
      "dataframe: (74659, 78)\n",
      "round: 26\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 7}\n",
      "dataframe: (74659, 81)\n",
      "round: 27\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "dataframe: (74659, 84)\n",
      "round: 28\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 2, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 7}\n",
      "dataframe: (74659, 87)\n",
      "round: 29\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 1.0, 'min_child_weight': 0, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 2}\n",
      "dataframe: (74659, 90)\n",
      "round: 30\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 3, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 7}\n",
      "dataframe: (74659, 93)\n",
      "round: 31\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 4, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 6}\n",
      "dataframe: (74659, 96)\n",
      "round: 32\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 5, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 2}\n",
      "dataframe: (74659, 99)\n",
      "round: 33\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 4, 'subsample': 0.59999999999999998, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 5}\n",
      "dataframe: (74659, 102)\n",
      "round: 34\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "dataframe: (74659, 105)\n",
      "round: 35\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 5, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 8}\n",
      "dataframe: (74659, 108)\n",
      "round: 36\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 4, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 3}\n",
      "dataframe: (74659, 111)\n",
      "round: 37\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "dataframe: (74659, 114)\n",
      "round: 38\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.10000000000000001, 'min_child_weight': 0, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 3}\n",
      "dataframe: (74659, 117)\n",
      "round: 39\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.80000000000000004, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 6}\n",
      "dataframe: (74659, 120)\n",
      "round: 40\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 5, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 8}\n",
      "dataframe: (74659, 123)\n",
      "round: 41\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 4, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 10}\n",
      "dataframe: (74659, 126)\n",
      "round: 42\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 6}\n",
      "dataframe: (74659, 129)\n",
      "round: 43\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 7}\n",
      "dataframe: (74659, 132)\n",
      "round: 44\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.050000000000000003, 'min_child_weight': 1, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.40000000000000002, 'max_depth': 8}\n",
      "dataframe: (74659, 135)\n",
      "round: 45\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 1, 'subsample': 0.40000000000000002, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 2}\n",
      "dataframe: (74659, 138)\n",
      "round: 46\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 3, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 9}\n",
      "dataframe: (74659, 141)\n",
      "round: 47\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.01, 'min_child_weight': 1, 'subsample': 0.69999999999999996, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.69999999999999996, 'max_depth': 7}\n",
      "dataframe: (74659, 144)\n",
      "round: 48\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 4, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.59999999999999998, 'max_depth': 5}\n",
      "dataframe: (74659, 147)\n",
      "round: 49\n",
      "parma: {'num_class': 3, 'silent': 1, 'eval_metric': 'mlogloss', 'eta': 0.5, 'min_child_weight': 1, 'subsample': 0.5, 'seed': 0, 'objective': 'multi:softprob', 'colsample_bytree': 0.80000000000000004, 'max_depth': 7}\n",
      "dataframe: (74659, 150)\n"
     ]
    }
   ],
   "source": [
    "# get preds by each model\n",
    "mix_model_test_df = pd.DataFrame()\n",
    "test_x = feature_preprocessing(test_df, False)\n",
    "for i in xrange(50):\n",
    "    print 'round: %s' % i\n",
    "    param = {}\n",
    "    # fixed parems\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['seed'] = 0\n",
    "    param['silent'] = 1 \n",
    "    param['num_class'] = 3\n",
    "    \n",
    "    # random\n",
    "    param['eta'] = np.random.choice([0.01, 0.05, 0.1, 0.5, 1], 1)[0]    #[0,1]\n",
    "    param['max_depth'] = np.random.choice([2,3,4,5,6,7,8,9,10], 1)[0]                       #[1,]\n",
    "    param['min_child_weight'] = np.random.choice([0,1,2,3,4,5], 1)[0]                    #[0,]\n",
    "    param['subsample'] = np.random.choice([0.4,0.5,0.6,0.7,0.8], 1)[0]                 #(0,1]\n",
    "    param['colsample_bytree'] = np.random.choice([0.4,0.5,0.6,0.7,0.8], 1)[0]          #(0,1]\n",
    "    print 'parma: %s' % param\n",
    "    preds, model = runXGB(param, train_x, train_y, test_x, num_rounds=200)\n",
    "    preds_df = pd.DataFrame(preds, columns=['pred_high_%s' % i, 'pred_medium_%s' % i, 'pred_low_%s' % i])\n",
    "    \n",
    "    if i == 0:\n",
    "        mix_model_test_df = preds_df\n",
    "    else:\n",
    "        mix_model_test_df = pd.concat([ mix_model_test_df, preds_df], axis = 1)\n",
    "\n",
    "    print 'dataframe: {0}'.format(mix_model_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_model_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(param, mix_model_df, train_y, mix_model_test_df, num_rounds=2000)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df = out_df[[\"listing_id\",\"high\", \"medium\", \"low\" ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv(\"xgb_10_iter_ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.80000000000000004,\n",
       " 'eta': 0.01,\n",
       " 'eval_metric': 'mlogloss',\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 0,\n",
       " 'num_class': 3,\n",
       " 'objective': 'multi:softprob',\n",
       " 'seed': 0,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.80000000000000004}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mix_model_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f7ecff40771d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmix_model_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mix_model_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "mix_model_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_result_from_mixed_model(mixed_model_result, raw_test_df):\n",
    "    mixed_model_result['high'] = mixed_model_result[['pred_high_'+str(i) for i in xrange(10)]].mean(axis=1)\n",
    "    mixed_model_result['medium'] = mixed_model_result[['pred_medium_'+str(i) for i in xrange(10)]].mean(axis=1)\n",
    "    mixed_model_result['low'] = mixed_model_result[['pred_low_'+str(i) for i in xrange(10)]].mean(axis=1)\n",
    "    mixed_model_result[\"listing_id\"] = raw_test_df.listing_id.values\n",
    "    mixed_model_result = mixed_model_result[[\"listing_id\",\"high\", \"medium\", \"low\" ]]\n",
    "    return mixed_model_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = gen_result_from_mixed_model(mix_model_test_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 33)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp['high'] = temp[['pred_high_'+str(i) for i in xrange(10)]].mean(axis=1)\n",
    "temp['medium'] = temp[['pred_medium_'+str(i) for i in xrange(10)]].mean(axis=1)\n",
    "temp['low'] = temp[['pred_low_'+str(i) for i in xrange(10)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp[\"listing_id\"] = test_df.listing_id.values\n",
    "temp = temp[[\"listing_id\",\"high\", \"medium\", \"low\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7142618</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>0.359702</td>\n",
       "      <td>0.567428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7210040</td>\n",
       "      <td>0.301329</td>\n",
       "      <td>0.429328</td>\n",
       "      <td>0.269343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7103890</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.111844</td>\n",
       "      <td>0.877883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7143442</td>\n",
       "      <td>0.045526</td>\n",
       "      <td>0.272457</td>\n",
       "      <td>0.682017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6860601</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.141232</td>\n",
       "      <td>0.848677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id      high    medium       low\n",
       "0     7142618  0.072869  0.359702  0.567428\n",
       "1     7210040  0.301329  0.429328  0.269343\n",
       "2     7103890  0.010274  0.111844  0.877883\n",
       "3     7143442  0.045526  0.272457  0.682017\n",
       "4     6860601  0.010091  0.141232  0.848677"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"xgb_50_iter_mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
